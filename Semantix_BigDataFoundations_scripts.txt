Scripts Curso Semantixa - BigData Foundations 
--------------------------


instalacao docker 
---------------------

(base) heron@acerubuntu:~$ sudo apt-get update
[sudo] password for heron: 

(base) heron@acerubuntu:~$ sudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common

(base) heron@acerubuntu:~$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
OK
(base) heron@acerubuntu:~$ sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
[sudo] password for heron: 
Hit:1 http://dl.google.com/linux/chrome/deb stable InRelease
Get:2 https://download.docker.com/linux/ubuntu focal InRelease [52,1 kB]                                                                      
Hit:3 http://br.archive.ubuntu.com/ubuntu focal InRelease                                                                                     
Get:4 https://download.docker.com/linux/ubuntu focal/stable amd64 Packages [10,7 kB]                                                          
Get:5 http://br.archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]                                                                    
Get:6 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]                                               
Hit:7 http://archive.canonical.com/ubuntu focal InRelease                                                                                     
Get:8 http://br.archive.ubuntu.com/ubuntu focal-backports InRelease [101 kB]                                                                  
Get:9 http://br.archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [1.169 kB]                                    
Hit:10 https://download.sublimetext.com apt/stable/ InRelease
Get:11 http://security.ubuntu.com/ubuntu focal-security/main amd64 DEP-11 Metadata [27,6 kB]
Get:12 http://br.archive.ubuntu.com/ubuntu focal-updates/main amd64 DEP-11 Metadata [283 kB]
Get:13 http://security.ubuntu.com/ubuntu focal-security/universe amd64 DEP-11 Metadata [61,0 kB]
Get:14 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 DEP-11 Metadata [2.468 B]         
Get:15 http://br.archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [848 kB]                 
Get:16 http://br.archive.ubuntu.com/ubuntu focal-updates/universe amd64 DEP-11 Metadata [351 kB]
Get:17 http://br.archive.ubuntu.com/ubuntu focal-updates/universe DEP-11 48x48 Icons [213 kB]
Get:18 http://br.archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 DEP-11 Metadata [944 B]
Get:19 http://br.archive.ubuntu.com/ubuntu focal-backports/universe amd64 DEP-11 Metadata [10,3 kB]
Fetched 3.357 kB in 2s (1.924 kB/s)                                  
Reading package lists... Done
(base) heron@acerubuntu:~$ 
$ sudo apt-get update
[sudo] password for heron: 
Hit:1 https://download.docker.com/linux/ubuntu focal InRelease
Hit:2 http://dl.google.com/linux/chrome/deb stable InRelease                                                                                  
Hit:3 http://br.archive.ubuntu.com/ubuntu focal InRelease                                                                                     
Hit:4 http://br.archive.ubuntu.com/ubuntu focal-updates InRelease                                                                             
Hit:5 http://security.ubuntu.com/ubuntu focal-security InRelease                                                                
Hit:6 http://br.archive.ubuntu.com/ubuntu focal-backports InRelease                                                          
Hit:7 http://archive.canonical.com/ubuntu focal InRelease                                              
Hit:8 https://download.sublimetext.com apt/stable/ InRelease                    
Reading package lists... Done                             
(base) heron@acerubuntu:~$ sudo apt-get install docker-ce docker-ce-cli containerd.io
(base) heron@acerubuntu:~$ sudo usermod -aG docker $(whoami)


instalacao docker compose 
-----------------------------------------------------------

(base) heron@acerubuntu:~$ sudo curl -L "https://github.com/docker/compose/releases/download/1.28.2/dockercompose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

(base) heron@acerubuntu:~$ sudo curl -L "https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose

altera permissao 

(base) heron@acerubuntu:~$ sudo chmod +x /usr/local/bin/docker-compose

Testar instalação

(base) heron@acerubuntu:~$ sudo docker-compose --version


remocao docker compose 
--------------------------------------------------------------

(base) heron@acerubuntu:~$ sudo rm /usr/local/bin/docker-compose
[sudo] password for heron: 

(base) heron@acerubuntu:~$ sudo apt remove docker-compose

(base) heron@acerubuntu:~$ 

(base) heron@acerubuntu:~$ sudo apt-get autoremove

sites de apoio 
----------------------------------------------------------

https://phoenixnap.com/kb/install-docker-compose-on-ubuntu-20-04



-INSTALACAO CLUSTER BIGDATA -AULA 02
-------------------------------------------------------------


(base) heron@acerubuntu:~$ git clone https://github.com/rodrigo-reboucas/docker-bigdata.git

Cloning into 'docker-bigdata'...
remote: Enumerating objects: 1318, done.
remote: Counting objects: 100% (62/62), done.
remote: Compressing objects: 100% (58/58), done.
remote: Total 1318 (delta 34), reused 9 (delta 4), pack-reused 1256
Receiving objects: 100% (1318/1318), 129.13 MiB | 13.08 MiB/s, done.
Resolving deltas: 100% (854/854), done.

(base) heron@acerubuntu:~$ cd docker-bigdata/

(base) heron@acerubuntu:~/docker-bigdata$ ls -ltr
total 372
-rwxrwxr-x  1 heron heron   3443 ago 30 20:31 README.md
drwxrwxr-x 12 heron heron   4096 ago 30 20:31 data
-rw-rw-r--  1 heron heron 343678 ago 30 20:31 ecosystem.jpeg
-rwxrwxr-x  1 heron heron   3778 ago 30 20:31 docker-compose.yml
-rw-rw-r--  1 heron heron   5172 ago 30 20:31 docker-compose-parcial.yml
-rw-rw-r--  1 heron heron   6381 ago 30 20:31 docker-compose-completo.yml
-rw-rw-r--  1 heron heron   6755 ago 30 20:31 docker-compose-completo-windows.yml

(base) heron@acerubuntu:

vai utilizar o arquivo Docker-compose.yml

-- baixar as imagens 

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose pull

(base) heron@acerubuntu:~/docker-bigdata$ docker image ls 

(base) heron@acerubuntu:~/docker-bigdata$ docker image ls
REPOSITORY               TAG       IMAGE ID       CREATED         SIZE
fjardim/jupyter-spark    latest    31051dea1e70   12 months ago   5.03GB
fjardim/datanode         latest    24fb187ebd91   17 months ago   874MB
fjardim/namenode_sqoop   latest    40dc59117765   17 months ago   1.54GB
fjardim/mysql            latest    84164b03fa2e   18 months ago   456MB
fjardim/hive-metastore   latest    7ab9e8f93813   18 months ago   275MB
fjardim/hive             latest    87f5c9f4e2df   3 years ago     1.17GB
fjardim/hbase-master     latest    ce0efeff9785   3 years ago     1.1GB
fjardim/zookeeper        latest    6fe5551964f5   5 years ago     451MB
(base) heron@acerubuntu:~/docker-bigdata$ 


--- Executar os containers 

   (base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d
Creating network "docker-bigdata_default" with the default driver
Creating spark        ... done
Creating database     ... done
Creating zookeeper    ... done
Creating namenode  ... done
Creating datanode     ... done
Creating hbase-master              ... done
Creating hive-metastore-postgresql ... done
Creating hive_metastore            ... done
Creating hive-server               ... done
(base) heron@acerubuntu:~/docker-bigdata$ 


--- listar os containers 

(base) heron@acerubuntu:~/docker-bigdata$ docker container ls
CONTAINER ID   IMAGE                    COMMAND                  CREATED         STATUS                   PORTS                                                                                                                NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   7 minutes ago   Up 7 minutes             0.0.0.0:10000->10000/tcp, :::10000->10000/tcp, 10002/tcp                                                             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   7 minutes ago   Up 7 minutes             10000/tcp, 0.0.0.0:9083->9083/tcp, :::9083->9083/tcp, 10002/tcp                                                      hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   7 minutes ago   Up 7 minutes             5432/tcp                                                                                                             hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   7 minutes ago   Up 7 minutes (healthy)   0.0.0.0:50075->50075/tcp, :::50075->50075/tcp                                                                        datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   7 minutes ago   Up 7 minutes             16000/tcp, 0.0.0.0:16010->16010/tcp, :::16010->16010/tcp                                                             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   7 minutes ago   Up 7 minutes (healthy)   0.0.0.0:50070->50070/tcp, :::50070->50070/tcp                                                                        namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   7 minutes ago   Up 7 minutes             22/tcp, 2888/tcp, 3888/tcp, 0.0.0.0:2181->2181/tcp, :::2181->2181/tcp                                                zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   7 minutes ago   Up 7 minutes             0.0.0.0:4040-4043->4040-4043/tcp, :::4040-4043->4040-4043/tcp, 0.0.0.0:8889->8889/tcp, :::8889->8889/tcp, 8899/tcp   spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   7 minutes ago   Up 7 minutes             33060/tcp, 0.0.0.0:33061->3306/tcp, :::33061->3306/tcp                                                               database
(base) heron@acerubuntu:~/docker-bigdata$ 


--- lista todos os container que estao ativos 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE                    COMMAND                  CREATED          STATUS                    PORTS                                                                                                                NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   15 minutes ago   Up 15 minutes             0.0.0.0:10000->10000/tcp, :::10000->10000/tcp, 10002/tcp                                                             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   15 minutes ago   Up 15 minutes             10000/tcp, 0.0.0.0:9083->9083/tcp, :::9083->9083/tcp, 10002/tcp                                                      hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   15 minutes ago   Up 15 minutes             5432/tcp                                                                                                             hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   15 minutes ago   Up 15 minutes (healthy)   0.0.0.0:50075->50075/tcp, :::50075->50075/tcp                                                                        datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   15 minutes ago   Up 15 minutes             16000/tcp, 0.0.0.0:16010->16010/tcp, :::16010->16010/tcp                                                             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   15 minutes ago   Up 15 minutes (healthy)   0.0.0.0:50070->50070/tcp, :::50070->50070/tcp                                                                        namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   15 minutes ago   Up 15 minutes             22/tcp, 2888/tcp, 3888/tcp, 0.0.0.0:2181->2181/tcp, :::2181->2181/tcp                                                zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   15 minutes ago   Up 15 minutes             0.0.0.0:4040-4043->4040-4043/tcp, :::4040-4043->4040-4043/tcp, 0.0.0.0:8889->8889/tcp, :::8889->8889/tcp, 8899/tcp   spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   15 minutes ago   Up 15 minutes             33060/tcp, 0.0.0.0:33061->3306/tcp, :::33061->3306/tcp                                                               database
(base) heron@acerubuntu:~/docker-bigdata$ 


--- lista todos os containers 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED          STATUS                    PORTS                                                                                                                NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   16 minutes ago   Up 16 minutes             0.0.0.0:10000->10000/tcp, :::10000->10000/tcp, 10002/tcp                                                             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   16 minutes ago   Up 16 minutes             10000/tcp, 0.0.0.0:9083->9083/tcp, :::9083->9083/tcp, 10002/tcp                                                      hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   16 minutes ago   Up 16 minutes             5432/tcp                                                                                                             hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   16 minutes ago   Up 16 minutes (healthy)   0.0.0.0:50075->50075/tcp, :::50075->50075/tcp                                                                        datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   16 minutes ago   Up 16 minutes             16000/tcp, 0.0.0.0:16010->16010/tcp, :::16010->16010/tcp                                                             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   16 minutes ago   Up 16 minutes (healthy)   0.0.0.0:50070->50070/tcp, :::50070->50070/tcp                                                                        namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   16 minutes ago   Up 16 minutes             22/tcp, 2888/tcp, 3888/tcp, 0.0.0.0:2181->2181/tcp, :::2181->2181/tcp                                                zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   16 minutes ago   Up 16 minutes             0.0.0.0:4040-4043->4040-4043/tcp, :::4040-4043->4040-4043/tcp, 0.0.0.0:8889->8889/tcp, :::8889->8889/tcp, 8899/tcp   spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   16 minutes ago   Up 16 minutes             33060/tcp, 0.0.0.0:33061->3306/tcp, :::33061->3306/tcp                                                               database
(base) heron@acerubuntu:~/docker-bigdata$ 


--- Visualizar os logs 

--- visualizar os logs de todos os containers 

(base) heron@acerubuntu:~/docker-bigdata$ 
(base) heron@acerubuntu:~/docker-bigdata$ docker-compose logs
Attaching to hive-server, hive_metastore, hive-metastore-postgresql, datanode, hbase-master, namenode, zookeeper, spark, database
database                     | 2021-08-31 00:21:32+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 5.7.29-1debian10 started.
database                     | 2021-08-31 00:21:32+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'
database                     | 2021-08-31 00:21:32+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 5.7.29-1debian10 started.
database                     | 2021-08-31T00:21:32.794562Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).
database                     | 2021-08-31T00:21:32.796465Z 0 [Note] mysqld (mysqld 5.7.29) starting as process 1 ...
database                     | 2021-08-31T00:21:32.800349Z 0 [Note] InnoDB: PUNCH HOLE support available
database                     | 2021-08-31T00:21:32.800377Z 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
database                     | 2021-08-31T00:21:32.800383Z 0 [Note] InnoDB: Uses event mutexes
database                     | 2021-08-31T00:21:32.800388Z 0 [Note] InnoDB: GCC builtin __atomic_thread_fence() is used for memory barrier
database                     | 2021-08-31T00:21:32.800393Z 0 [Note] InnoDB: Compressed tables use zlib 1.2.11
database                     | 2021-08-31T00:21:32.800740Z 0 [Note] InnoDB: Number of pools: 1
database                     | 2021-08-31T00:21:32.800888Z 0 [Note] InnoDB: Using CPU crc32 instructions
database                     | 2021-08-31T00:21:32.802454Z 0 [Note] InnoDB: Initializing buffer pool, total size = 128M, instances = 1, chunk size = 128M
database                     | 2021-08-31T00:21:32.816693Z 0 [Note] InnoDB: Completed initialization of buffer pool
database                     | 2021-08-31T00:21:32.818889Z 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority().
database                     | 2021-08-31T00:21:32.830780Z 0 [Note] InnoDB: Highest supported file format is Barracuda.
database                     | 2021-08-31T00:21:32.887552Z 0 [Note] InnoDB: Creating shared tablespace for temporary tables
database                     | 2021-08-31T00:21:32.887609Z 0 [Note] InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ...
database                     | 2021-08-31T00:21:33.097193Z 0 [Note] InnoDB: File './ibtmp1' size is now 12 MB.
database                     | 2021-08-31T00:21:33.098071Z 0 [Note] InnoDB: 96 redo rollback segment(s) found. 96 redo rollback segment(s) are active.
database                     | 2021-08-31T00:21:33.098081Z 0 [Note] InnoDB: 32 non-redo rollback segment(s) are active.
database                     | 2021-08-31T00:21:33.098434Z 0 [Note] InnoDB: 5.7.29 started; log sequence number 155834360
database                     | 2021-08-31T00:21:33.098516Z 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool
database                     | 2021-08-31T00:21:33.098690Z 0 [Note] Plugin 'FEDERATED' is disabled.
database                     | 2021-08-31T00:21:33.101279Z 0 [Note] InnoDB: Buffer pool(s) load completed at 210831  0:21:33
database                     | 2021-08-31T00:21:33.104878Z 0 [Note] Found ca.pem, server-cert.pem and server-key.pem in data directory. Trying to enable SSL support using them.
database                     | 2021-08-31T00:21:33.104893Z 0 [Note] Skipping generation of SSL certificates as certificate files are present in data directory.
database                     | 2021-08-31T00:21:33.105588Z 0 [Warning] CA certificate ca.pem is self signed.
database                     | 2021-08-31T00:21:33.105616Z 0 [Note] Skipping generation of RSA key pair as key files are present in data directory.
database                     | 2021-08-31T00:21:33.106122Z 0 [Note] Server hostname (bind-address): '*'; port: 3306
database                     | 2021-08-31T00:21:33.106160Z 0 [Note] IPv6 is available.
database                     | 2021-08-31T00:21:33.106175Z 0 [Note]   - '::' resolves to '::';
database                     | 2021-08-31T00:21:33.106194Z 0 [Note] Server socket created on IP: '::'.
database                     | 2021-08-31T00:21:33.107638Z 0 [Warning] Insecure configuration for --pid-file: Location '/var/run/mysqld' in the path is accessible to all OS users. Consider choosing a different directory.
database                     | 2021-08-31T00:21:33.108921Z 0 [Warning] 'user' entry 'bigdata@localhost.localdomain' ignored in --skip-name-resolve mode.
database                     | 2021-08-31T00:21:33.118936Z 0 [Note] Event Scheduler: Loaded 0 events
database                     | 2021-08-31T00:21:33.119037Z 0 [Note] Execution of init_file '/data/application/init.sql' started.
database                     | 2021-08-31T00:21:33.119153Z 1 [ERROR] 1105  Bootstrap file error, return code (1). Nearest query: ''
database                     | 2021-08-31T00:21:33.119197Z 0 [Note] Execution of init_file '/data/application/init.sql' ended.
database                     | 2021-08-31T00:21:33.119249Z 0 [Note] mysqld: ready for connections.
database                     | Version: '5.7.29'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server (GPL)
datanode                     | Configuring core
datanode                     |  - Setting hadoop.proxyuser.hue.hosts=*
datanode                     |  - Setting fs.defaultFS=hdfs://namenode:8020
datanode                     |  - Setting hadoop.proxyuser.hue.groups=*
datanode                     |  - Setting hadoop.http.staticuser.user=root
datanode                     | Configuring hdfs
datanode                     |  - Setting dfs.datanode.data.dir=file:///hadoop/dfs/data
datanode                     |  - Setting dfs.permissions.enabled=false
datanode                     |  - Setting dfs.webhdfs.enabled=true
datanode                     | Configuring yarn
datanode                     |  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate
datanode                     |  - Setting yarn.timeline-service.generic-application-history.enabled=true
datanode                     |  - Setting yarn.resourcemanager.recovery.enabled=true
datanode                     |  - Setting yarn.timeline-service.enabled=true
datanode                     |  - Setting yarn.log-aggregation-enable=true
datanode                     |  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
datanode                     |  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true
datanode                     |  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs
datanode                     |  - Setting yarn.resourcemanager.resource.tracker.address=resourcemanager:8031
datanode                     |  - Setting yarn.resourcemanager.hostname=resourcemanager
datanode                     |  - Setting yarn.timeline-service.hostname=historyserver
datanode                     |  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/
datanode                     |  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030
datanode                     |  - Setting yarn.resourcemanager.address=resourcemanager:8032
datanode                     | Configuring httpfs
datanode                     | Configuring kms
datanode                     | Configuring mapred
datanode                     | Configuring for multihomed network
datanode                     | [1/100] check for namenode:50070...
datanode                     | [1/100] namenode:50070 is not available yet
datanode                     | [1/100] try in 5s once again ...
datanode                     | [2/100] namenode:50070 is available.
datanode                     | 21/08/31 00:21:38 INFO datanode.DataNode: STARTUP_MSG: 
datanode                     | /************************************************************
datanode                     | STARTUP_MSG: Starting DataNode
datanode                     | STARTUP_MSG:   host = datanode/172.18.0.7
datanode                     | STARTUP_MSG:   args = []
datanode                     | STARTUP_MSG:   version = 2.7.4
datanode                     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-2.7.4/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hadoop-annotations-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hadoop-auth-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-nfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-common-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-api-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-client-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-registry-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.4.jar:/contrib/capacity-scheduler/*.jar
datanode                     | STARTUP_MSG:   build = https://shv@git-wip-us.apache.org/repos/asf/hadoop.git -r cd915e1e8d9d0131462a0b7301586c175728a282; compiled by 'kshvachk' on 2017-08-01T00:29Z
datanode                     | STARTUP_MSG:   java = 1.8.0_131
datanode                     | ************************************************************/
datanode                     | 21/08/31 00:21:38 INFO datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
datanode                     | 21/08/31 00:21:39 INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
datanode                     | 21/08/31 00:21:39 INFO impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
datanode                     | 21/08/31 00:21:39 INFO impl.MetricsSystemImpl: DataNode metrics system started
datanode                     | 21/08/31 00:21:39 INFO datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: Configured hostname is datanode
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: Starting DataNode with maxLockedMemory = 0
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: Opened streaming server at /0.0.0.0:50010
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: Balancing bandwith is 1048576 bytes/s
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: Number threads for balancing is 5
datanode                     | 21/08/31 00:21:39 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
datanode                     | 21/08/31 00:21:39 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
datanode                     | 21/08/31 00:21:39 INFO http.HttpRequestLog: Http request log for http.requests.datanode is not defined
datanode                     | 21/08/31 00:21:39 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
datanode                     | 21/08/31 00:21:39 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
datanode                     | 21/08/31 00:21:39 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
datanode                     | 21/08/31 00:21:39 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
datanode                     | 21/08/31 00:21:39 INFO http.HttpServer2: Jetty bound to port 43537
datanode                     | 21/08/31 00:21:39 INFO mortbay.log: jetty-6.1.26
datanode                     | 21/08/31 00:21:39 INFO mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:43537
datanode                     | 21/08/31 00:21:39 INFO web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:50075
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: dnUserName = root
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: supergroup = supergroup
datanode                     | 21/08/31 00:21:39 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
datanode                     | 21/08/31 00:21:39 INFO ipc.Server: Starting Socket Reader #1 for port 50020
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: Opened IPC server at /0.0.0.0:50020
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: Refresh request received for nameservices: null
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: Starting BPOfferServices for nameservices: <default>
datanode                     | 21/08/31 00:21:39 INFO datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to namenode/172.18.0.5:8020 starting to offer service
datanode                     | 21/08/31 00:21:39 INFO ipc.Server: IPC Server Responder: starting
datanode                     | 21/08/31 00:21:39 INFO ipc.Server: IPC Server listener on 50020: starting
datanode                     | 21/08/31 00:21:39 INFO common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
datanode                     | 21/08/31 00:21:39 INFO common.Storage: Lock on /hadoop/dfs/data/in_use.lock acquired by nodename 224@datanode
datanode                     | 21/08/31 00:21:39 INFO common.Storage: Storage directory /hadoop/dfs/data is not formatted for namespace 1845641953. Formatting...
datanode                     | 21/08/31 00:21:39 INFO common.Storage: Generated new storageID DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf for directory /hadoop/dfs/data
datanode                     | 21/08/31 00:21:39 INFO common.Storage: Analyzing storage directories for bpid BP-730104245-172.18.0.5-1630369293664
datanode                     | 21/08/31 00:21:39 INFO common.Storage: Locking is disabled for /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664
datanode                     | 21/08/31 00:21:39 INFO common.Storage: Block pool storage directory /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664 is not formatted for BP-730104245-172.18.0.5-1630369293664. Formatting ...
datanode                     | 21/08/31 00:21:39 INFO common.Storage: Formatting block pool BP-730104245-172.18.0.5-1630369293664 directory /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current
datanode                     | 21/08/31 00:21:40 INFO datanode.DataNode: Setting up storage: nsid=1845641953;bpid=BP-730104245-172.18.0.5-1630369293664;lv=-56;nsInfo=lv=-63;cid=CID-3ceaab1c-201a-45a6-9683-a461d7f02c68;nsid=1845641953;c=0;bpid=BP-730104245-172.18.0.5-1630369293664;dnuuid=null
datanode                     | 21/08/31 00:21:40 INFO datanode.DataNode: Generated and persisted new Datanode UUID d96ad8f4-e251-4ce3-b385-1310f3797c39
datanode                     | 21/08/31 00:21:40 INFO impl.FsDatasetImpl: Added new volume: DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf
datanode                     | 21/08/31 00:21:40 INFO impl.FsDatasetImpl: Added volume - /hadoop/dfs/data/current, StorageType: DISK
datanode                     | 21/08/31 00:21:40 INFO impl.FsDatasetImpl: Registered FSDatasetState MBean
datanode                     | 21/08/31 00:21:40 INFO impl.FsDatasetImpl: Adding block pool BP-730104245-172.18.0.5-1630369293664
datanode                     | 21/08/31 00:21:40 INFO impl.FsDatasetImpl: Scanning block pool BP-730104245-172.18.0.5-1630369293664 on volume /hadoop/dfs/data/current...
datanode                     | 21/08/31 00:21:40 INFO impl.FsDatasetImpl: Time taken to scan block pool BP-730104245-172.18.0.5-1630369293664 on /hadoop/dfs/data/current: 6ms
datanode                     | 21/08/31 00:21:40 INFO impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-730104245-172.18.0.5-1630369293664: 7ms
datanode                     | 21/08/31 00:21:40 INFO impl.FsDatasetImpl: Adding replicas to map for block pool BP-730104245-172.18.0.5-1630369293664 on volume /hadoop/dfs/data/current...
datanode                     | 21/08/31 00:21:40 INFO impl.FsDatasetImpl: Time to add replicas to map for block pool BP-730104245-172.18.0.5-1630369293664 on volume /hadoop/dfs/data/current: 0ms
datanode                     | 21/08/31 00:21:40 INFO impl.FsDatasetImpl: Total time to add all replicas to map: 0ms
datanode                     | 21/08/31 00:21:40 INFO datanode.VolumeScanner: Now scanning bpid BP-730104245-172.18.0.5-1630369293664 on volume /hadoop/dfs/data
datanode                     | 21/08/31 00:21:40 ERROR datanode.DirectoryScanner: dfs.datanode.directoryscan.throttle.limit.ms.per.sec set to value below 1 ms/sec. Assuming default value of 1000
datanode                     | 21/08/31 00:21:40 INFO datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1630383397290ms with interval of 21600000ms
datanode                     | 21/08/31 00:21:40 INFO datanode.DataNode: Block pool BP-730104245-172.18.0.5-1630369293664 (Datanode Uuid null) service to namenode/172.18.0.5:8020 beginning handshake with NN
datanode                     | 21/08/31 00:21:40 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf): finished scanning block pool BP-730104245-172.18.0.5-1630369293664
datanode                     | 21/08/31 00:21:40 INFO datanode.VolumeScanner: VolumeScanner(/hadoop/dfs/data, DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf): no suitable block pools found to scan.  Waiting 1814399980 ms.
datanode                     | 21/08/31 00:21:40 INFO datanode.DataNode: Block pool Block pool BP-730104245-172.18.0.5-1630369293664 (Datanode Uuid null) service to namenode/172.18.0.5:8020 successfully registered with NN
datanode                     | 21/08/31 00:21:40 INFO datanode.DataNode: For namenode namenode/172.18.0.5:8020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
datanode                     | 21/08/31 00:21:40 INFO datanode.DataNode: Namenode Block pool BP-730104245-172.18.0.5-1630369293664 (Datanode Uuid d96ad8f4-e251-4ce3-b385-1310f3797c39) service to namenode/172.18.0.5:8020 trying to claim ACTIVE state with txid=1
datanode                     | 21/08/31 00:21:40 INFO datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-730104245-172.18.0.5-1630369293664 (Datanode Uuid d96ad8f4-e251-4ce3-b385-1310f3797c39) service to namenode/172.18.0.5:8020
datanode                     | 21/08/31 00:21:40 INFO datanode.DataNode: Successfully sent block report 0xb1b301213f8,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 27 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
datanode                     | 21/08/31 00:21:40 INFO datanode.DataNode: Got finalize command for block pool BP-730104245-172.18.0.5-1630369293664
datanode                     | 21/08/31 00:21:41 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741825_1001 src: /172.18.0.6:38156 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:41 INFO DataNode.clienttrace: src: /172.18.0.6:38156, dest: /172.18.0.7:50010, bytes: 7, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741825_1001, duration: 25394480
datanode                     | 21/08/31 00:21:41 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741825_1001, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:21:41 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741826_1002 src: /172.18.0.6:38158 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:41 INFO DataNode.clienttrace: src: /172.18.0.6:38158, dest: /172.18.0.7:50010, bytes: 42, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741826_1002, duration: 3240223
datanode                     | 21/08/31 00:21:41 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741826_1002, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:21:42 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741827_1003 src: /172.18.0.6:38162 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:42 INFO DataNode.clienttrace: src: /172.18.0.6:38162, dest: /172.18.0.7:50010, bytes: 32, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741827_1003, duration: 1342411
datanode                     | 21/08/31 00:21:42 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741827_1003, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:21:42 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741828_1004 src: /172.18.0.6:38164 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:42 INFO DataNode.clienttrace: src: /172.18.0.6:38164, dest: /172.18.0.7:50010, bytes: 398, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741828_1004, duration: 5974690
datanode                     | 21/08/31 00:21:42 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741828_1004, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:21:47 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741829_1005 src: /172.18.0.6:38176 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:50 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741830_1006 src: /172.18.0.6:38184 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:50 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741831_1007 src: /172.18.0.6:38186 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:50 INFO DataNode.clienttrace: src: /172.18.0.6:38184, dest: /172.18.0.7:50010, bytes: 265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741830_1006, duration: 397486655
datanode                     | 21/08/31 00:21:50 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741830_1006, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:21:50 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741832_1008 src: /172.18.0.6:38190 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:51 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741833_1009 src: /172.18.0.6:38192 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:51 INFO DataNode.clienttrace: src: /172.18.0.6:38192, dest: /172.18.0.7:50010, bytes: 312, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741833_1009, duration: 5172651
datanode                     | 21/08/31 00:21:51 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741833_1009, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:21:51 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741834_1010 src: /172.18.0.6:38194 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:51 INFO DataNode.clienttrace: src: /172.18.0.6:38194, dest: /172.18.0.7:50010, bytes: 42, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741834_1010, duration: 4887462
datanode                     | 21/08/31 00:21:51 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741834_1010, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:21:52 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741835_1011 src: /172.18.0.6:38196 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:52 INFO DataNode.clienttrace: src: /172.18.0.6:38186, dest: /172.18.0.7:50010, bytes: 270, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741831_1007, duration: 1903324894
datanode                     | 21/08/31 00:21:52 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741831_1007, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:21:53 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741836_1012 src: /172.18.0.6:38200 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:53 INFO DataNode.clienttrace: src: /172.18.0.6:38176, dest: /172.18.0.7:50010, bytes: 370, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741829_1005, duration: 5503980624
datanode                     | 21/08/31 00:21:53 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741829_1005, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:21:53 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741837_1013 src: /172.18.0.6:38202 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:21:53 INFO DataNode.clienttrace: src: /172.18.0.6:38196, dest: /172.18.0.7:50010, bytes: 617, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741835_1011, duration: 904262301
datanode                     | 21/08/31 00:21:53 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741835_1011, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:22:14 INFO DataNode.clienttrace: src: /172.18.0.6:38190, dest: /172.18.0.7:50010, bytes: 3335, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741832_1008, duration: 23675749170
datanode                     | 21/08/31 00:22:14 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741832_1008, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:22:16 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741832_1008 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741832 for deletion
datanode                     | 21/08/31 00:22:16 INFO impl.FsDatasetAsyncDiskService: Deleted BP-730104245-172.18.0.5-1630369293664 blk_1073741832_1008 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741832
datanode                     | 21/08/31 00:28:30 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741838_1014 src: /172.18.0.6:38352 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:28:30 INFO DataNode.clienttrace: src: /172.18.0.6:38202, dest: /172.18.0.7:50010, bytes: 231, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741837_1013, duration: 397551760446
datanode                     | 21/08/31 00:28:30 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741837_1013, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:28:30 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741839_1015 src: /172.18.0.6:38354 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:28:30 INFO DataNode.clienttrace: src: /172.18.0.6:38354, dest: /172.18.0.7:50010, bytes: 5399, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741839_1015, duration: 1774291
datanode                     | 21/08/31 00:28:30 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741839_1015, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:28:30 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741840_1016 src: /172.18.0.6:38358 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:28:30 INFO DataNode.clienttrace: src: /172.18.0.6:38352, dest: /172.18.0.7:50010, bytes: 265, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741838_1014, duration: 309580888
datanode                     | 21/08/31 00:28:30 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741838_1014, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:31:14 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741841_1017 src: /172.18.0.6:38410 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:31:14 INFO DataNode.clienttrace: src: /172.18.0.6:38200, dest: /172.18.0.7:50010, bytes: 548, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741836_1012, duration: 561869846568
datanode                     | 21/08/31 00:31:14 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741836_1012, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:31:14 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741842_1018 src: /172.18.0.6:38412 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:31:14 INFO DataNode.clienttrace: src: /172.18.0.6:38412, dest: /172.18.0.7:50010, bytes: 4963, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741842_1018, duration: 4832760
datanode                     | 21/08/31 00:31:14 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741842_1018, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:31:15 INFO datanode.DataNode: Receiving BP-730104245-172.18.0.5-1630369293664:blk_1073741843_1019 src: /172.18.0.6:38416 dest: /172.18.0.7:50010
datanode                     | 21/08/31 00:31:15 INFO DataNode.clienttrace: src: /172.18.0.6:38410, dest: /172.18.0.7:50010, bytes: 370, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1336819110_1, offset: 0, srvID: d96ad8f4-e251-4ce3-b385-1310f3797c39, blockid: BP-730104245-172.18.0.5-1630369293664:blk_1073741841_1017, duration: 298059052
datanode                     | 21/08/31 00:31:15 INFO datanode.DataNode: PacketResponder: BP-730104245-172.18.0.5-1630369293664:blk_1073741841_1017, type=LAST_IN_PIPELINE, downstreams=0:[] terminating
datanode                     | 21/08/31 00:32:46 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
datanode                     | 21/08/31 00:32:46 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
datanode                     | 21/08/31 00:32:46 INFO impl.FsDatasetAsyncDiskService: Deleted BP-730104245-172.18.0.5-1630369293664 blk_1073741829_1005 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741829
datanode                     | 21/08/31 00:32:46 INFO impl.FsDatasetAsyncDiskService: Deleted BP-730104245-172.18.0.5-1630369293664 blk_1073741830_1006 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741830
datanode                     | 21/08/31 00:38:46 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741831 for deletion
datanode                     | 21/08/31 00:38:46 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741835_1011 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
datanode                     | 21/08/31 00:38:46 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741837_1013 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
datanode                     | 21/08/31 00:38:46 INFO impl.FsDatasetAsyncDiskService: Deleted BP-730104245-172.18.0.5-1630369293664 blk_1073741831_1007 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741831
datanode                     | 21/08/31 00:38:46 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741838_1014 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
datanode                     | 21/08/31 00:38:46 INFO impl.FsDatasetAsyncDiskService: Deleted BP-730104245-172.18.0.5-1630369293664 blk_1073741835_1011 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741835
datanode                     | 21/08/31 00:38:46 INFO impl.FsDatasetAsyncDiskService: Deleted BP-730104245-172.18.0.5-1630369293664 blk_1073741837_1013 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741837
datanode                     | 21/08/31 00:38:46 INFO impl.FsDatasetAsyncDiskService: Deleted BP-730104245-172.18.0.5-1630369293664 blk_1073741838_1014 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741838
datanode                     | 21/08/31 00:41:46 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741841_1017 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
datanode                     | 21/08/31 00:41:46 INFO impl.FsDatasetAsyncDiskService: Scheduling blk_1073741836_1012 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
datanode                     | 21/08/31 00:41:46 INFO impl.FsDatasetAsyncDiskService: Deleted BP-730104245-172.18.0.5-1630369293664 blk_1073741841_1017 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741841
datanode                     | 21/08/31 00:41:46 INFO impl.FsDatasetAsyncDiskService: Deleted BP-730104245-172.18.0.5-1630369293664 blk_1073741836_1012 file /hadoop/dfs/data/current/BP-730104245-172.18.0.5-1630369293664/current/finalized/subdir0/subdir0/blk_1073741836
hive-server                  | Configuring core
hive-server                  |  - Setting hadoop.proxyuser.hue.hosts=*
hive-server                  |  - Setting fs.defaultFS=hdfs://namenode:8020
hive-server                  |  - Setting hadoop.proxyuser.hue.groups=*
hive-server                  |  - Setting hadoop.http.staticuser.user=root
hive-server                  | Configuring hdfs
hive-server                  |  - Setting dfs.permissions.enabled=false
hive-server                  |  - Setting dfs.webhdfs.enabled=true
hive-server                  | Configuring yarn
hive-server                  |  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate
hive-server                  |  - Setting yarn.timeline-service.generic-application-history.enabled=true
hive-server                  |  - Setting yarn.resourcemanager.recovery.enabled=true
hive-server                  |  - Setting yarn.timeline-service.enabled=true
hive-server                  |  - Setting yarn.log-aggregation-enable=true
hive-server                  |  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
hive-server                  |  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true
hive-server                  |  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs
hive-server                  |  - Setting yarn.resourcemanager.resource.tracker.address=resourcemanager:8031
hive-server                  |  - Setting yarn.resourcemanager.hostname=resourcemanager
hive-server                  |  - Setting yarn.timeline-service.hostname=historyserver
hive-server                  |  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/
hive-server                  |  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030
hive-server                  |  - Setting yarn.resourcemanager.address=resourcemanager:8032
hive-server                  | Configuring httpfs
hive-server                  | Configuring kms
hive-server                  | Configuring mapred
hive-server                  | Configuring hive
hive-server                  |  - Setting hive.metastore.uris=thrift://hive-metastore:9083
hive-server                  |  - Setting datanucleus.autoCreateSchema=false
hive-server                  |  - Setting javax.jdo.option.ConnectionURL=jdbc:postgresql://hive-metastore-postgresql/metastore
hive-server                  |  - Setting javax.jdo.option.ConnectionDriverName=org.postgresql.Driver
hive-server                  |  - Setting javax.jdo.option.ConnectionPassword=hive
hive-server                  |  - Setting javax.jdo.option.ConnectionUserName=hive
hive-server                  | Configuring for multihomed network
hive-server                  | [1/100] check for hive-metastore:9083...
hive-server                  | [1/100] hive-metastore:9083 is not available yet
hive-server                  | [1/100] try in 5s once again ...
hive-server                  | [2/100] check for hive-metastore:9083...
hive-server                  | [2/100] hive-metastore:9083 is not available yet
hive-server                  | [2/100] try in 5s once again ...
hive-server                  | [3/100] check for hive-metastore:9083...
hive-server                  | [3/100] hive-metastore:9083 is not available yet
hive-server                  | [3/100] try in 5s once again ...
hive-server                  | [4/100] check for hive-metastore:9083...
hive-server                  | [4/100] hive-metastore:9083 is not available yet
hive-server                  | [4/100] try in 5s once again ...
hive-server                  | [5/100] check for hive-metastore:9083...
hive-server                  | [5/100] hive-metastore:9083 is not available yet
hive-server                  | [5/100] try in 5s once again ...
hive-server                  | [6/100] check for hive-metastore:9083...
hive-server                  | [6/100] hive-metastore:9083 is not available yet
hive-server                  | [6/100] try in 5s once again ...
hive-server                  | [7/100] hive-metastore:9083 is available.
hive-server                  | 2021-08-31 00:22:09: Starting HiveServer2
hive-server                  | SLF4J: Class path contains multiple SLF4J bindings.
hive-server                  | SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
hive-server                  | SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
hive-server                  | SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
hive-server                  | SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
hbase-master                 | Configuring hbase
hbase-master                 |  - Setting hbase.master.info.port=16010
hbase-master                 |  - Setting DIR=/etc/hbase
hbase-master                 |  - Setting hbase.cluster.distributed=false
hbase-master                 |  - Setting hbase.master.port=16000
hbase-master                 |  - Setting hbase.zookeeper.property.dataDir=/zookeeper-data
hbase-master                 |  - Setting hbase.zookeeper.property.clientPort=2181
hbase-master                 |  - Setting hbase.zookeeper.leaderport=3888
hbase-master                 |  - Setting hbase.zookeeper.quorum=zookeeper
hbase-master                 |  - Setting hbase.regionserver.port=16020
hbase-master                 |  - Setting hbase.regionserver.info.port=16030
hbase-master                 |  - Setting hbase.zookeeper.peerport=2888
hbase-master                 |  - Setting hbase.rootdir=hdfs://namenode:8020/hbase
hbase-master                 | [1/100] check for namenode:50070...
hbase-master                 | [1/100] namenode:50070 is not available yet
hbase-master                 | [1/100] try in 5s once again ...
hbase-master                 | [2/100] namenode:50070 is available.
hbase-master                 | OpenJDK 64-Bit Server VM warning: ignoring option PermSize=128m; support was removed in 8.0
hbase-master                 | OpenJDK 64-Bit Server VM warning: ignoring option MaxPermSize=128m; support was removed in 8.0
hbase-master                 | 2021-08-31 00:21:38,556 INFO  [main] util.VersionInfo: HBase 1.2.6
hbase-master                 | 2021-08-31 00:21:38,557 INFO  [main] util.VersionInfo: Source code repository file:///home/busbey/projects/hbase/hbase-assembly/target/hbase-1.2.6 revision=Unknown
hbase-master                 | 2021-08-31 00:21:38,557 INFO  [main] util.VersionInfo: Compiled by busbey on Mon May 29 02:25:32 CDT 2017
hbase-master                 | 2021-08-31 00:21:38,557 INFO  [main] util.VersionInfo: From source with checksum 7e8ce83a648e252758e9dae1fbe779c9
hbase-master                 | 2021-08-31 00:21:38,768 INFO  [main] master.HMasterCommandLine: Starting a zookeeper cluster
hbase-master                 | 2021-08-31 00:21:38,786 INFO  [main] server.ZooKeeperServer: Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
hbase-master                 | 2021-08-31 00:21:38,786 INFO  [main] server.ZooKeeperServer: Server environment:host.name=hbase-master
hbase-master                 | 2021-08-31 00:21:38,786 INFO  [main] server.ZooKeeperServer: Server environment:java.version=1.8.0_141
hbase-master                 | 2021-08-31 00:21:38,786 INFO  [main] server.ZooKeeperServer: Server environment:java.vendor=Oracle Corporation
hbase-master                 | 2021-08-31 00:21:38,786 INFO  [main] server.ZooKeeperServer: Server environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
hbase-master                 | 2021-08-31 00:21:38,786 INFO  [main] server.ZooKeeperServer: Server environment:java.class.path=/etc/hbase:/docker-java-home/lib/tools.jar:/opt/hbase-1.2.6/bin/..:/opt/hbase-1.2.6/bin/../lib/activation-1.1.jar:/opt/hbase-1.2.6/bin/../lib/aopalliance-1.0.jar:/opt/hbase-1.2.6/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase-1.2.6/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase-1.2.6/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase-1.2.6/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase-1.2.6/bin/../lib/asm-3.1.jar:/opt/hbase-1.2.6/bin/../lib/avro-1.7.4.jar:/opt/hbase-1.2.6/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase-1.2.6/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase-1.2.6/bin/../lib/commons-cli-1.2.jar:/opt/hbase-1.2.6/bin/../lib/commons-codec-1.9.jar:/opt/hbase-1.2.6/bin/../lib/commons-collections-3.2.2.jar:/opt/hbase-1.2.6/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase-1.2.6/bin/../lib/commons-configuration-1.6.jar:/opt/hbase-1.2.6/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase-1.2.6/bin/../lib/commons-digester-1.8.jar:/opt/hbase-1.2.6/bin/../lib/commons-el-1.0.jar:/opt/hbase-1.2.6/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase-1.2.6/bin/../lib/commons-io-2.4.jar:/opt/hbase-1.2.6/bin/../lib/commons-lang-2.6.jar:/opt/hbase-1.2.6/bin/../lib/commons-logging-1.2.jar:/opt/hbase-1.2.6/bin/../lib/commons-math-2.2.jar:/opt/hbase-1.2.6/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase-1.2.6/bin/../lib/commons-net-3.1.jar:/opt/hbase-1.2.6/bin/../lib/disruptor-3.3.0.jar:/opt/hbase-1.2.6/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase-1.2.6/bin/../lib/guava-12.0.1.jar:/opt/hbase-1.2.6/bin/../lib/guice-3.0.jar:/opt/hbase-1.2.6/bin/../lib/guice-servlet-3.0.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hbase-annotations-1.2.6-tests.jar:/opt/hbase-1.2.6/bin/../lib/hbase-annotations-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-client-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-common-1.2.6-tests.jar:/opt/hbase-1.2.6/bin/../lib/hbase-common-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-examples-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-external-blockcache-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-hadoop-compat-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-hadoop2-compat-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-it-1.2.6-tests.jar:/opt/hbase-1.2.6/bin/../lib/hbase-it-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-prefix-tree-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-procedure-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-protocol-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-resource-bundle-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-rest-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-server-1.2.6-tests.jar:/opt/hbase-1.2.6/bin/../lib/hbase-server-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-shell-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-thrift-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase-1.2.6/bin/../lib/httpclient-4.2.5.jar:/opt/hbase-1.2.6/bin/../lib/httpcore-4.4.1.jar:/opt/hbase-1.2.6/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase-1.2.6/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase-1.2.6/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase-1.2.6/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase-1.2.6/bin/../lib/jamon-runtime-2.4.1.jar:/opt/hbase-1.2.6/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase-1.2.6/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase-1.2.6/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase-1.2.6/bin/../lib/javax.inject-1.jar:/opt/hbase-1.2.6/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase-1.2.6/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase-1.2.6/bin/../lib/jcodings-1.0.8.jar:/opt/hbase-1.2.6/bin/../lib/jersey-client-1.9.jar:/opt/hbase-1.2.6/bin/../lib/jersey-core-1.9.jar:/opt/hbase-1.2.6/bin/../lib/jersey-guice-1.9.jar:/opt/hbase-1.2.6/bin/../lib/jersey-json-1.9.jar:/opt/hbase-1.2.6/bin/../lib/jersey-server-1.9.jar:/opt/hbase-1.2.6/bin/../lib/jets3t-0.9.0.jar:/opt/hbase-1.2.6/bin/../lib/jettison-1.3.3.jar:/opt/hbase-1.2.6/bin/../lib/jetty-6.1.26.jar:/opt/hbase-1.2.6/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase-1.2.6/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase-1.2.6/bin/../lib/joni-2.1.2.jar:/opt/hbase-1.2.6/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase-1.2.6/bin/../lib/jsch-0.1.42.jar:/opt/hbase-1.2.6/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase-1.2.6/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase-1.2.6/bin/../lib/junit-4.12.jar:/opt/hbase-1.2.6/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase-1.2.6/bin/../lib/libthrift-0.9.3.jar:/opt/hbase-1.2.6/bin/../lib/log4j-1.2.17.jar:/opt/hbase-1.2.6/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase-1.2.6/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase-1.2.6/bin/../lib/paranamer-2.3.jar:/opt/hbase-1.2.6/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase-1.2.6/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase-1.2.6/bin/../lib/servlet-api-2.5.jar:/opt/hbase-1.2.6/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase-1.2.6/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase-1.2.6/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase-1.2.6/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase-1.2.6/bin/../lib/xmlenc-0.52.jar:/opt/hbase-1.2.6/bin/../lib/xz-1.0.jar:/opt/hbase-1.2.6/bin/../lib/zookeeper-3.4.6.jar:
hbase-master                 | 2021-08-31 00:21:38,787 INFO  [main] server.ZooKeeperServer: Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
hbase-master                 | 2021-08-31 00:21:38,787 INFO  [main] server.ZooKeeperServer: Server environment:java.io.tmpdir=/tmp
hbase-master                 | 2021-08-31 00:21:38,787 INFO  [main] server.ZooKeeperServer: Server environment:java.compiler=<NA>
hbase-master                 | 2021-08-31 00:21:38,787 INFO  [main] server.ZooKeeperServer: Server environment:os.name=Linux
hbase-master                 | 2021-08-31 00:21:38,787 INFO  [main] server.ZooKeeperServer: Server environment:os.arch=amd64
hbase-master                 | 2021-08-31 00:21:38,787 INFO  [main] server.ZooKeeperServer: Server environment:os.version=5.11.0-27-generic
hbase-master                 | 2021-08-31 00:21:38,787 INFO  [main] server.ZooKeeperServer: Server environment:user.name=root
hbase-master                 | 2021-08-31 00:21:38,787 INFO  [main] server.ZooKeeperServer: Server environment:user.home=/root
hbase-master                 | 2021-08-31 00:21:38,787 INFO  [main] server.ZooKeeperServer: Server environment:user.dir=/
hbase-master                 | 2021-08-31 00:21:38,800 INFO  [main] server.ZooKeeperServer: Created server with tickTime 2000 minSessionTimeout 4000 maxSessionTimeout 40000 datadir /zookeeper-data/zookeeper_0/version-2 snapdir /zookeeper-data/zookeeper_0/version-2
hbase-master                 | 2021-08-31 00:21:38,813 INFO  [main] server.NIOServerCnxnFactory: binding to port 0.0.0.0/0.0.0.0:2181
hbase-master                 | 2021-08-31 00:21:38,885 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxnFactory: Accepted socket connection from /127.0.0.1:51698
hbase-master                 | 2021-08-31 00:21:38,889 INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181] server.NIOServerCnxn: Processing stat command from /127.0.0.1:51698
hbase-master                 | 2021-08-31 00:21:38,890 INFO  [Thread-2] server.NIOServerCnxn: Stat command output
hbase-master                 | 2021-08-31 00:21:38,891 INFO  [Thread-2] server.NIOServerCnxn: Closed socket connection for client /127.0.0.1:51698 (no session established for client)
hbase-master                 | 2021-08-31 00:21:38,891 INFO  [main] zookeeper.MiniZooKeeperCluster: Started MiniZooKeeperCluster and ran successful 'stat' on client port=2181
hbase-master                 | 2021-08-31 00:21:38,891 INFO  [main] master.HMasterCommandLine: Starting up instance of localHBaseCluster; master=1, regionserversCount=1
hbase-master                 | 2021-08-31 00:21:39,003 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
hbase-master                 | 2021-08-31 00:21:39,134 INFO  [main] regionserver.RSRpcServices: master/hbase-master/172.18.0.6:0 server-side HConnection retries=350
hbase-master                 | 2021-08-31 00:21:39,239 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
hbase-master                 | 2021-08-31 00:21:39,248 INFO  [main] ipc.RpcServer: master/hbase-master/172.18.0.6:0: started 10 reader(s) listening on port=45735
hbase-master                 | 2021-08-31 00:21:39,648 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
hbase-master                 | 2021-08-31 00:21:39,760 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=master:45735 connecting to ZooKeeper ensemble=zookeeper:2181
hbase-master                 | 2021-08-31 00:21:39,762 INFO  [main] zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
hbase-master                 | 2021-08-31 00:21:39,762 INFO  [main] zookeeper.ZooKeeper: Client environment:host.name=hbase-master
hbase-master                 | 2021-08-31 00:21:39,762 INFO  [main] zookeeper.ZooKeeper: Client environment:java.version=1.8.0_141
hbase-master                 | 2021-08-31 00:21:39,762 INFO  [main] zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
hbase-master                 | 2021-08-31 00:21:39,762 INFO  [main] zookeeper.ZooKeeper: Client environment:java.home=/usr/lib/jvm/java-8-openjdk-amd64/jre
hbase-master                 | 2021-08-31 00:21:39,762 INFO  [main] zookeeper.ZooKeeper: Client environment:java.class.path=/etc/hbase:/docker-java-home/lib/tools.jar:/opt/hbase-1.2.6/bin/..:/opt/hbase-1.2.6/bin/../lib/activation-1.1.jar:/opt/hbase-1.2.6/bin/../lib/aopalliance-1.0.jar:/opt/hbase-1.2.6/bin/../lib/apacheds-i18n-2.0.0-M15.jar:/opt/hbase-1.2.6/bin/../lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hbase-1.2.6/bin/../lib/api-asn1-api-1.0.0-M20.jar:/opt/hbase-1.2.6/bin/../lib/api-util-1.0.0-M20.jar:/opt/hbase-1.2.6/bin/../lib/asm-3.1.jar:/opt/hbase-1.2.6/bin/../lib/avro-1.7.4.jar:/opt/hbase-1.2.6/bin/../lib/commons-beanutils-1.7.0.jar:/opt/hbase-1.2.6/bin/../lib/commons-beanutils-core-1.8.0.jar:/opt/hbase-1.2.6/bin/../lib/commons-cli-1.2.jar:/opt/hbase-1.2.6/bin/../lib/commons-codec-1.9.jar:/opt/hbase-1.2.6/bin/../lib/commons-collections-3.2.2.jar:/opt/hbase-1.2.6/bin/../lib/commons-compress-1.4.1.jar:/opt/hbase-1.2.6/bin/../lib/commons-configuration-1.6.jar:/opt/hbase-1.2.6/bin/../lib/commons-daemon-1.0.13.jar:/opt/hbase-1.2.6/bin/../lib/commons-digester-1.8.jar:/opt/hbase-1.2.6/bin/../lib/commons-el-1.0.jar:/opt/hbase-1.2.6/bin/../lib/commons-httpclient-3.1.jar:/opt/hbase-1.2.6/bin/../lib/commons-io-2.4.jar:/opt/hbase-1.2.6/bin/../lib/commons-lang-2.6.jar:/opt/hbase-1.2.6/bin/../lib/commons-logging-1.2.jar:/opt/hbase-1.2.6/bin/../lib/commons-math-2.2.jar:/opt/hbase-1.2.6/bin/../lib/commons-math3-3.1.1.jar:/opt/hbase-1.2.6/bin/../lib/commons-net-3.1.jar:/opt/hbase-1.2.6/bin/../lib/disruptor-3.3.0.jar:/opt/hbase-1.2.6/bin/../lib/findbugs-annotations-1.3.9-1.jar:/opt/hbase-1.2.6/bin/../lib/guava-12.0.1.jar:/opt/hbase-1.2.6/bin/../lib/guice-3.0.jar:/opt/hbase-1.2.6/bin/../lib/guice-servlet-3.0.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-annotations-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-auth-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-client-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-common-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-hdfs-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-mapreduce-client-app-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-mapreduce-client-common-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-mapreduce-client-core-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-mapreduce-client-jobclient-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-mapreduce-client-shuffle-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-yarn-api-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-yarn-client-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-yarn-common-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hadoop-yarn-server-common-2.5.1.jar:/opt/hbase-1.2.6/bin/../lib/hbase-annotations-1.2.6-tests.jar:/opt/hbase-1.2.6/bin/../lib/hbase-annotations-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-client-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-common-1.2.6-tests.jar:/opt/hbase-1.2.6/bin/../lib/hbase-common-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-examples-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-external-blockcache-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-hadoop-compat-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-hadoop2-compat-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-it-1.2.6-tests.jar:/opt/hbase-1.2.6/bin/../lib/hbase-it-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-prefix-tree-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-procedure-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-protocol-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-resource-bundle-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-rest-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-server-1.2.6-tests.jar:/opt/hbase-1.2.6/bin/../lib/hbase-server-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-shell-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/hbase-thrift-1.2.6.jar:/opt/hbase-1.2.6/bin/../lib/htrace-core-3.1.0-incubating.jar:/opt/hbase-1.2.6/bin/../lib/httpclient-4.2.5.jar:/opt/hbase-1.2.6/bin/../lib/httpcore-4.4.1.jar:/opt/hbase-1.2.6/bin/../lib/jackson-core-asl-1.9.13.jar:/opt/hbase-1.2.6/bin/../lib/jackson-jaxrs-1.9.13.jar:/opt/hbase-1.2.6/bin/../lib/jackson-mapper-asl-1.9.13.jar:/opt/hbase-1.2.6/bin/../lib/jackson-xc-1.9.13.jar:/opt/hbase-1.2.6/bin/../lib/jamon-runtime-2.4.1.jar:/opt/hbase-1.2.6/bin/../lib/jasper-compiler-5.5.23.jar:/opt/hbase-1.2.6/bin/../lib/jasper-runtime-5.5.23.jar:/opt/hbase-1.2.6/bin/../lib/java-xmlbuilder-0.4.jar:/opt/hbase-1.2.6/bin/../lib/javax.inject-1.jar:/opt/hbase-1.2.6/bin/../lib/jaxb-api-2.2.2.jar:/opt/hbase-1.2.6/bin/../lib/jaxb-impl-2.2.3-1.jar:/opt/hbase-1.2.6/bin/../lib/jcodings-1.0.8.jar:/opt/hbase-1.2.6/bin/../lib/jersey-client-1.9.jar:/opt/hbase-1.2.6/bin/../lib/jersey-core-1.9.jar:/opt/hbase-1.2.6/bin/../lib/jersey-guice-1.9.jar:/opt/hbase-1.2.6/bin/../lib/jersey-json-1.9.jar:/opt/hbase-1.2.6/bin/../lib/jersey-server-1.9.jar:/opt/hbase-1.2.6/bin/../lib/jets3t-0.9.0.jar:/opt/hbase-1.2.6/bin/../lib/jettison-1.3.3.jar:/opt/hbase-1.2.6/bin/../lib/jetty-6.1.26.jar:/opt/hbase-1.2.6/bin/../lib/jetty-sslengine-6.1.26.jar:/opt/hbase-1.2.6/bin/../lib/jetty-util-6.1.26.jar:/opt/hbase-1.2.6/bin/../lib/joni-2.1.2.jar:/opt/hbase-1.2.6/bin/../lib/jruby-complete-1.6.8.jar:/opt/hbase-1.2.6/bin/../lib/jsch-0.1.42.jar:/opt/hbase-1.2.6/bin/../lib/jsp-2.1-6.1.14.jar:/opt/hbase-1.2.6/bin/../lib/jsp-api-2.1-6.1.14.jar:/opt/hbase-1.2.6/bin/../lib/junit-4.12.jar:/opt/hbase-1.2.6/bin/../lib/leveldbjni-all-1.8.jar:/opt/hbase-1.2.6/bin/../lib/libthrift-0.9.3.jar:/opt/hbase-1.2.6/bin/../lib/log4j-1.2.17.jar:/opt/hbase-1.2.6/bin/../lib/metrics-core-2.2.0.jar:/opt/hbase-1.2.6/bin/../lib/netty-all-4.0.23.Final.jar:/opt/hbase-1.2.6/bin/../lib/paranamer-2.3.jar:/opt/hbase-1.2.6/bin/../lib/protobuf-java-2.5.0.jar:/opt/hbase-1.2.6/bin/../lib/servlet-api-2.5-6.1.14.jar:/opt/hbase-1.2.6/bin/../lib/servlet-api-2.5.jar:/opt/hbase-1.2.6/bin/../lib/slf4j-api-1.7.7.jar:/opt/hbase-1.2.6/bin/../lib/slf4j-log4j12-1.7.5.jar:/opt/hbase-1.2.6/bin/../lib/snappy-java-1.0.4.1.jar:/opt/hbase-1.2.6/bin/../lib/spymemcached-2.11.6.jar:/opt/hbase-1.2.6/bin/../lib/xmlenc-0.52.jar:/opt/hbase-1.2.6/bin/../lib/xz-1.0.jar:/opt/hbase-1.2.6/bin/../lib/zookeeper-3.4.6.jar:
hbase-master                 | 2021-08-31 00:21:39,762 INFO  [main] zookeeper.ZooKeeper: Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
hbase-master                 | 2021-08-31 00:21:39,763 INFO  [main] zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/tmp
hbase-master                 | 2021-08-31 00:21:39,763 INFO  [main] zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
hbase-master                 | 2021-08-31 00:21:39,763 INFO  [main] zookeeper.ZooKeeper: Client environment:os.name=Linux
hbase-master                 | 2021-08-31 00:21:39,763 INFO  [main] zookeeper.ZooKeeper: Client environment:os.arch=amd64
hbase-master                 | 2021-08-31 00:21:39,763 INFO  [main] zookeeper.ZooKeeper: Client environment:os.version=5.11.0-27-generic
hbase-master                 | 2021-08-31 00:21:39,763 INFO  [main] zookeeper.ZooKeeper: Client environment:user.name=root
hbase-master                 | 2021-08-31 00:21:39,763 INFO  [main] zookeeper.ZooKeeper: Client environment:user.home=/root
hbase-master                 | 2021-08-31 00:21:39,763 INFO  [main] zookeeper.ZooKeeper: Client environment:user.dir=/
hbase-master                 | 2021-08-31 00:21:39,763 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=zookeeper:2181 sessionTimeout=10000 watcher=master:457350x0, quorum=zookeeper:2181, baseZNode=/hbase
hbase-master                 | 2021-08-31 00:21:39,771 INFO  [main-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Opening socket connection to server zookeeper.docker-bigdata_default/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
hbase-master                 | 2021-08-31 00:21:39,771 INFO  [main-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Socket connection established to zookeeper.docker-bigdata_default/172.18.0.4:2181, initiating session
hbase-master                 | 2021-08-31 00:21:39,912 INFO  [main-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Session establishment complete on server zookeeper.docker-bigdata_default/172.18.0.4:2181, sessionid = 0x17b9995221e0000, negotiated timeout = 10000
hbase-master                 | 2021-08-31 00:21:40,404 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
hbase-master                 | 2021-08-31 00:21:40,404 INFO  [RpcServer.listener,port=45735] ipc.RpcServer: RpcServer.listener,port=45735: starting
hbase-master                 | 2021-08-31 00:21:40,441 INFO  [main] mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
hbase-master                 | 2021-08-31 00:21:40,443 INFO  [main] http.HttpRequestLog: Http request log for http.requests.master is not defined
hbase-master                 | 2021-08-31 00:21:40,448 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
hbase-master                 | 2021-08-31 00:21:40,449 INFO  [main] http.HttpServer: Added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.ClickjackingPreventionFilter)
hbase-master                 | 2021-08-31 00:21:40,450 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context master
hbase-master                 | 2021-08-31 00:21:40,450 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
hbase-master                 | 2021-08-31 00:21:40,450 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
hbase-master                 | 2021-08-31 00:21:40,457 INFO  [main] http.HttpServer: Jetty bound to port 16010
hbase-master                 | 2021-08-31 00:21:40,457 INFO  [main] mortbay.log: jetty-6.1.26
hbase-master                 | 2021-08-31 00:21:40,623 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:16010
hbase-master                 | 2021-08-31 00:21:40,625 INFO  [main] master.HMaster: hbase.rootdir=hdfs://namenode:8020/hbase, hbase.cluster.distributed=false
hbase-master                 | 2021-08-31 00:21:40,631 INFO  [main] master.HMaster: Adding backup master ZNode /hbase/backup-masters/hbase-master,45735,1630369299333
hbase-master                 | 2021-08-31 00:21:40,702 INFO  [main] regionserver.RSRpcServices: regionserver/hbase-master/172.18.0.6:0 server-side HConnection retries=350
hbase-master                 | 2021-08-31 00:21:40,702 INFO  [main] ipc.SimpleRpcScheduler: Using deadline as user call queue, count=3
hbase-master                 | 2021-08-31 00:21:40,708 INFO  [main] ipc.RpcServer: regionserver/hbase-master/172.18.0.6:0: started 10 reader(s) listening on port=36661
hbase-master                 | 2021-08-31 00:21:40,710 INFO  [main] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
hbase-master                 | 2021-08-31 00:21:40,712 INFO  [main] zookeeper.RecoverableZooKeeper: Process identifier=regionserver:36661 connecting to ZooKeeper ensemble=zookeeper:2181
hbase-master                 | 2021-08-31 00:21:40,712 INFO  [main] zookeeper.ZooKeeper: Initiating client connection, connectString=zookeeper:2181 sessionTimeout=10000 watcher=regionserver:366610x0, quorum=zookeeper:2181, baseZNode=/hbase
hbase-master                 | 2021-08-31 00:21:40,713 INFO  [main-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Opening socket connection to server zookeeper.docker-bigdata_default/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
hbase-master                 | 2021-08-31 00:21:40,713 INFO  [main-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Socket connection established to zookeeper.docker-bigdata_default/172.18.0.4:2181, initiating session
hbase-master                 | 2021-08-31 00:21:40,788 INFO  [main-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Session establishment complete on server zookeeper.docker-bigdata_default/172.18.0.4:2181, sessionid = 0x17b9995221e0001, negotiated timeout = 10000
hbase-master                 | 2021-08-31 00:21:40,790 INFO  [hbase-master:45735.activeMasterManager] master.ActiveMasterManager: Deleting ZNode for /hbase/backup-masters/hbase-master,45735,1630369299333 from backup master directory
hbase-master                 | 2021-08-31 00:21:40,791 INFO  [RpcServer.responder] ipc.RpcServer: RpcServer.responder: starting
hbase-master                 | 2021-08-31 00:21:40,791 INFO  [RpcServer.listener,port=36661] ipc.RpcServer: RpcServer.listener,port=36661: starting
hbase-master                 | 2021-08-31 00:21:40,795 INFO  [main] http.HttpRequestLog: Http request log for http.requests.regionserver is not defined
hbase-master                 | 2021-08-31 00:21:40,795 INFO  [main] http.HttpServer: Added global filter 'safety' (class=org.apache.hadoop.hbase.http.HttpServer$QuotingInputFilter)
hbase-master                 | 2021-08-31 00:21:40,795 INFO  [main] http.HttpServer: Added global filter 'clickjackingprevention' (class=org.apache.hadoop.hbase.http.ClickjackingPreventionFilter)
hbase-master                 | 2021-08-31 00:21:40,796 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context regionserver
hbase-master                 | 2021-08-31 00:21:40,796 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
hbase-master                 | 2021-08-31 00:21:40,796 INFO  [main] http.HttpServer: Added filter static_user_filter (class=org.apache.hadoop.hbase.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
hbase-master                 | 2021-08-31 00:21:40,798 INFO  [main] http.HttpServer: Jetty bound to port 44225
hbase-master                 | 2021-08-31 00:21:40,798 INFO  [main] mortbay.log: jetty-6.1.26
hbase-master                 | 2021-08-31 00:21:40,838 WARN  [hbase-master:45735.activeMasterManager] hbase.ZNodeClearer: Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
hbase-master                 | 2021-08-31 00:21:40,838 INFO  [hbase-master:45735.activeMasterManager] master.ActiveMasterManager: Registered Active Master=hbase-master,45735,1630369299333
hbase-master                 | 2021-08-31 00:21:40,851 INFO  [main] mortbay.log: Started SelectChannelConnector@0.0.0.0:44225
hbase-master                 | 2021-08-31 00:21:40,884 INFO  [M:0;hbase-master:45735] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x6639a754 connecting to ZooKeeper ensemble=zookeeper:2181
hbase-master                 | 2021-08-31 00:21:40,884 INFO  [RS:0;hbase-master:36661] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x146ad5da connecting to ZooKeeper ensemble=zookeeper:2181
hbase-master                 | 2021-08-31 00:21:40,884 INFO  [M:0;hbase-master:45735] zookeeper.ZooKeeper: Initiating client connection, connectString=zookeeper:2181 sessionTimeout=10000 watcher=hconnection-0x6639a7540x0, quorum=zookeeper:2181, baseZNode=/hbase
hbase-master                 | 2021-08-31 00:21:40,884 INFO  [RS:0;hbase-master:36661] zookeeper.ZooKeeper: Initiating client connection, connectString=zookeeper:2181 sessionTimeout=10000 watcher=hconnection-0x146ad5da0x0, quorum=zookeeper:2181, baseZNode=/hbase
hbase-master                 | 2021-08-31 00:21:40,885 INFO  [M:0;hbase-master:45735-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Opening socket connection to server zookeeper.docker-bigdata_default/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
hbase-master                 | 2021-08-31 00:21:40,885 INFO  [RS:0;hbase-master:36661-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Opening socket connection to server zookeeper.docker-bigdata_default/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
hbase-master                 | 2021-08-31 00:21:40,885 INFO  [M:0;hbase-master:45735-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Socket connection established to zookeeper.docker-bigdata_default/172.18.0.4:2181, initiating session
hbase-master                 | 2021-08-31 00:21:40,885 INFO  [RS:0;hbase-master:36661-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Socket connection established to zookeeper.docker-bigdata_default/172.18.0.4:2181, initiating session
hbase-master                 | 2021-08-31 00:21:40,935 INFO  [M:0;hbase-master:45735-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Session establishment complete on server zookeeper.docker-bigdata_default/172.18.0.4:2181, sessionid = 0x17b9995221e0002, negotiated timeout = 10000
hbase-master                 | 2021-08-31 00:21:40,985 INFO  [RS:0;hbase-master:36661-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Session establishment complete on server zookeeper.docker-bigdata_default/172.18.0.4:2181, sessionid = 0x17b9995221e0003, negotiated timeout = 10000
hbase-master                 | 2021-08-31 00:21:40,986 INFO  [M:0;hbase-master:45735] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
hbase-master                 | 2021-08-31 00:21:40,986 INFO  [RS:0;hbase-master:36661] client.ZooKeeperRegistry: ClusterId read in ZooKeeper is null
hbase-master                 | 2021-08-31 00:21:41,865 INFO  [hbase-master:45735.activeMasterManager] util.FSUtils: Created version file at hdfs://namenode:8020/hbase with version=8
hbase-master                 | 2021-08-31 00:21:42,154 INFO  [hbase-master:45735.activeMasterManager] master.MasterFileSystem: BOOTSTRAP: creating hbase:meta region
hbase-master                 | 2021-08-31 00:21:42,155 INFO  [hbase-master:45735.activeMasterManager] regionserver.HRegion: creating HRegion hbase:meta HTD == 'hbase:meta', {TABLE_ATTRIBUTES => {IS_META => 'true', coprocessor$1 => '|org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint|536870911|'}, {NAME => 'info', BLOOMFILTER => 'NONE', VERSIONS => '10', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', CACHE_DATA_IN_L1 => 'true', MIN_VERSIONS => '0', BLOCKCACHE => 'false', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = hdfs://namenode:8020/hbase Table name == hbase:meta
hbase-master                 | 2021-08-31 00:21:42,395 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: Allocating LruBlockCache size=1.52 GB, blockSize=64 KB
hbase-master                 | 2021-08-31 00:21:42,402 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: Created cacheConfig for info: blockCache=LruBlockCache{blockCount=0, currentSize=1669592, freeSize=1625222312, maxSize=1626891904, heapSize=1669592, minSize=1545547264, minFactor=0.95, multiSize=772773632, multiFactor=0.5, singleSize=386386816, singleFactor=0.25}, cacheDataOnRead=false, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
hbase-master                 | 2021-08-31 00:21:42,406 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000
hbase-master                 | 2021-08-31 00:21:42,576 INFO  [hbase-master:45735.activeMasterManager] regionserver.HRegion: Onlined 1588230740; next sequenceid=2
hbase-master                 | 2021-08-31 00:21:42,577 INFO  [StoreCloserThread-hbase:meta,,1.1588230740-1] regionserver.HStore: Closed info
hbase-master                 | 2021-08-31 00:21:42,578 INFO  [hbase-master:45735.activeMasterManager] regionserver.HRegion: Closed hbase:meta,,1.1588230740
hbase-master                 | 2021-08-31 00:21:42,997 INFO  [hbase-master:45735.activeMasterManager] fs.HFileSystem: Added intercepting call to namenode#getBlockLocations so can do block reordering using class org.apache.hadoop.hbase.fs.HFileSystem$ReorderWALBlocks
hbase-master                 | 2021-08-31 00:21:43,019 INFO  [hbase-master:45735.activeMasterManager] coordination.SplitLogManagerCoordination: Found 0 orphan tasks and 0 rescan nodes
hbase-master                 | 2021-08-31 00:21:43,110 INFO  [hbase-master:45735.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x3c162044 connecting to ZooKeeper ensemble=zookeeper:2181
hbase-master                 | 2021-08-31 00:21:43,110 INFO  [hbase-master:45735.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=zookeeper:2181 sessionTimeout=10000 watcher=hconnection-0x3c1620440x0, quorum=zookeeper:2181, baseZNode=/hbase
hive_metastore               | Configuring core
hive_metastore               |  - Setting hadoop.proxyuser.hue.hosts=*
hive_metastore               |  - Setting fs.defaultFS=hdfs://namenode:8020
hive_metastore               |  - Setting hadoop.proxyuser.hue.groups=*
hive_metastore               |  - Setting hadoop.http.staticuser.user=root
hive_metastore               | Configuring hdfs
hive_metastore               |  - Setting dfs.permissions.enabled=false
hive_metastore               |  - Setting dfs.webhdfs.enabled=true
hive_metastore               | Configuring yarn
hive_metastore               |  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate
hive_metastore               |  - Setting yarn.timeline-service.generic-application-history.enabled=true
hive_metastore               |  - Setting yarn.resourcemanager.recovery.enabled=true
hive_metastore               |  - Setting yarn.timeline-service.enabled=true
hive_metastore               |  - Setting yarn.log-aggregation-enable=true
hive_metastore               |  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
hive_metastore               |  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true
hive_metastore               |  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs
hive_metastore               |  - Setting yarn.resourcemanager.resource.tracker.address=resourcemanager:8031
hive_metastore               |  - Setting yarn.resourcemanager.hostname=resourcemanager
hive_metastore               |  - Setting yarn.timeline-service.hostname=historyserver
hive_metastore               |  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/
hive_metastore               |  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030
hive_metastore               |  - Setting yarn.resourcemanager.address=resourcemanager:8032
hive_metastore               | Configuring httpfs
hive_metastore               | Configuring kms
hive_metastore               | Configuring mapred
hive_metastore               | Configuring hive
hive_metastore               |  - Setting hive.metastore.uris=thrift://hive-metastore:9083
hive_metastore               |  - Setting datanucleus.autoCreateSchema=false
hive_metastore               |  - Setting javax.jdo.option.ConnectionURL=jdbc:postgresql://hive-metastore-postgresql/metastore
hive_metastore               |  - Setting javax.jdo.option.ConnectionDriverName=org.postgresql.Driver
hive_metastore               |  - Setting javax.jdo.option.ConnectionPassword=hive
hive_metastore               |  - Setting javax.jdo.option.ConnectionUserName=hive
hive_metastore               | Configuring for multihomed network
hive_metastore               | [1/100] check for namenode:50070...
hive_metastore               | [1/100] namenode:50070 is not available yet
hive_metastore               | [1/100] try in 5s once again ...
hive_metastore               | [2/100] namenode:50070 is available.
hive_metastore               | [1/100] check for datanode:50075...
hive_metastore               | [1/100] datanode:50075 is not available yet
hive_metastore               | [1/100] try in 5s once again ...
hive_metastore               | [2/100] datanode:50075 is available.
hive_metastore               | [1/100] check for hive-metastore-postgresql:5432...
hive_metastore               | [1/100] hive-metastore-postgresql:5432 is not available yet
hive_metastore               | [1/100] try in 5s once again ...
hive_metastore               | [2/100] check for hive-metastore-postgresql:5432...
hive_metastore               | [2/100] hive-metastore-postgresql:5432 is not available yet
hive_metastore               | [2/100] try in 5s once again ...
hive_metastore               | [3/100] check for hive-metastore-postgresql:5432...
hive_metastore               | [3/100] hive-metastore-postgresql:5432 is not available yet
hive_metastore               | [3/100] try in 5s once again ...
hive_metastore               | [4/100] hive-metastore-postgresql:5432 is available.
hive_metastore               | 2021-08-31 00:21:59: Starting Hive Metastore Server
hive_metastore               | /opt/hive/bin/ext/metastore.sh: line 29: export: ` -Dproc_metastore  -Dlog4j.configurationFile=hive-log4j2.properties  -Djava.util.logging.config.file=/opt/hive/conf/parquet-logging.properties  ': not a valid identifier
hive_metastore               | SLF4J: Class path contains multiple SLF4J bindings.
hive_metastore               | SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
hive_metastore               | SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
hive_metastore               | SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
hive_metastore               | SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
hive_metastore               | 2021-08-31T00:21:59,946 INFO [main] org.apache.hadoop.hive.conf.HiveConf - Found configuration file file:/opt/hive/conf/hive-site.xml
hive_metastore               | 2021-08-31T00:22:01,058 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - STARTUP_MSG: 
hive_metastore               | /************************************************************
hive_metastore               | STARTUP_MSG: Starting HiveMetaStore
hive_metastore               | STARTUP_MSG:   host = hive_metastore/172.18.0.9
hive_metastore               | STARTUP_MSG:   args = []
hive_metastore               | STARTUP_MSG:   version = 2.3.2
hbase-master                 | 2021-08-31 00:21:43,113 INFO  [hbase-master:45735.activeMasterManager-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Opening socket connection to server zookeeper.docker-bigdata_default/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
hbase-master                 | 2021-08-31 00:21:43,114 INFO  [hbase-master:45735.activeMasterManager-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Socket connection established to zookeeper.docker-bigdata_default/172.18.0.4:2181, initiating session
hbase-master                 | 2021-08-31 00:21:43,144 INFO  [hbase-master:45735.activeMasterManager-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Session establishment complete on server zookeeper.docker-bigdata_default/172.18.0.4:2181, sessionid = 0x17b9995221e0004, negotiated timeout = 10000
hbase-master                 | 2021-08-31 00:21:43,170 INFO  [hbase-master:45735.activeMasterManager] balancer.StochasticLoadBalancer: loading config
hbase-master                 | 2021-08-31 00:21:43,271 INFO  [hbase-master:45735.activeMasterManager] master.HMaster: Server active/primary master=hbase-master,45735,1630369299333, sessionid=0x17b9995221e0000, setting cluster-up flag (Was=false)
hbase-master                 | 2021-08-31 00:21:43,276 INFO  [M:0;hbase-master:45735] regionserver.HRegionServer: ClusterId : 0e49b99d-94a7-452e-a1c6-2204fc967360
hbase-master                 | 2021-08-31 00:21:43,277 INFO  [RS:0;hbase-master:36661] regionserver.HRegionServer: ClusterId : 0e49b99d-94a7-452e-a1c6-2204fc967360
hbase-master                 | 2021-08-31 00:21:43,783 INFO  [hbase-master:45735.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/flush-table-proc/acquired /hbase/flush-table-proc/reached /hbase/flush-table-proc/abort
hbase-master                 | 2021-08-31 00:21:44,081 INFO  [hbase-master:45735.activeMasterManager] procedure.ZKProcedureUtil: Clearing all procedure znodes: /hbase/online-snapshot/acquired /hbase/online-snapshot/reached /hbase/online-snapshot/abort
hbase-master                 | 2021-08-31 00:21:44,089 INFO  [RS:0;hbase-master:36661] regionserver.MemStoreFlusher: globalMemStoreLimit=1.5 G, globalMemStoreLimitLowMark=1.4 G, maxHeap=3.8 G
hbase-master                 | 2021-08-31 00:21:44,093 INFO  [RS:0;hbase-master:36661] regionserver.HRegionServer: CompactionChecker runs every 10sec
hbase-master                 | 2021-08-31 00:21:44,100 INFO  [hbase-master:45735.activeMasterManager] master.MasterCoprocessorHost: System coprocessor loading is enabled
hbase-master                 | 2021-08-31 00:21:44,109 INFO  [hbase-master:45735.activeMasterManager] procedure2.ProcedureExecutor: Starting procedure executor threads=13
hbase-master                 | 2021-08-31 00:21:44,109 INFO  [hbase-master:45735.activeMasterManager] wal.WALProcedureStore: Starting WAL Procedure Store lease recovery
hbase-master                 | 2021-08-31 00:21:44,110 WARN  [hbase-master:45735.activeMasterManager] wal.WALProcedureStore: Log directory not found: File hdfs://namenode:8020/hbase/MasterProcWALs does not exist.
hbase-master                 | 2021-08-31 00:21:44,131 INFO  [RS:0;hbase-master:36661] regionserver.RegionServerCoprocessorHost: System coprocessor loading is enabled
hbase-master                 | 2021-08-31 00:21:44,131 INFO  [RS:0;hbase-master:36661] regionserver.RegionServerCoprocessorHost: Table coprocessor loading is enabled
hbase-master                 | 2021-08-31 00:21:44,132 INFO  [RS:0;hbase-master:36661] regionserver.HRegionServer: reportForDuty to master=hbase-master,45735,1630369299333 with port=36661, startcode=1630369300709
hbase-master                 | 2021-08-31 00:21:44,154 INFO  [hbase-master:45735.activeMasterManager] wal.WALProcedureStore: Lease acquired for flushLogId: 1
hbase-master                 | 2021-08-31 00:21:44,158 INFO  [hbase-master:45735.activeMasterManager] zookeeper.RecoverableZooKeeper: Process identifier=replicationLogCleaner connecting to ZooKeeper ensemble=zookeeper:2181
hbase-master                 | 2021-08-31 00:21:44,158 INFO  [hbase-master:45735.activeMasterManager] zookeeper.ZooKeeper: Initiating client connection, connectString=zookeeper:2181 sessionTimeout=10000 watcher=replicationLogCleaner0x0, quorum=zookeeper:2181, baseZNode=/hbase
hbase-master                 | 2021-08-31 00:21:44,160 INFO  [hbase-master:45735.activeMasterManager-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Opening socket connection to server zookeeper.docker-bigdata_default/172.18.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
hbase-master                 | 2021-08-31 00:21:44,160 INFO  [hbase-master:45735.activeMasterManager-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Socket connection established to zookeeper.docker-bigdata_default/172.18.0.4:2181, initiating session
hbase-master                 | 2021-08-31 00:21:44,203 INFO  [hbase-master:45735.activeMasterManager-SendThread(zookeeper.docker-bigdata_default:2181)] zookeeper.ClientCnxn: Session establishment complete on server zookeeper.docker-bigdata_default/172.18.0.4:2181, sessionid = 0x17b9995221e0005, negotiated timeout = 10000
hbase-master                 | 2021-08-31 00:21:44,215 WARN  [RS:0;hbase-master:36661] regionserver.HRegionServer: reportForDuty failed; sleeping and then retrying.
hbase-master                 | 2021-08-31 00:21:44,366 INFO  [hbase-master:45735.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 0 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
hbase-master                 | 2021-08-31 00:21:45,872 INFO  [hbase-master:45735.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 0, slept for 1506 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
hbase-master                 | 2021-08-31 00:21:47,218 INFO  [RS:0;hbase-master:36661] regionserver.HRegionServer: reportForDuty to master=hbase-master,45735,1630369299333 with port=36661, startcode=1630369300709
hbase-master                 | 2021-08-31 00:21:47,227 INFO  [B.defaultRpcServer.handler=4,queue=1,port=45735] master.ServerManager: Registering server=hbase-master,36661,1630369300709
hbase-master                 | 2021-08-31 00:21:47,227 INFO  [hbase-master:45735.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 2861 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
hbase-master                 | 2021-08-31 00:21:47,230 WARN  [RS:0;hbase-master:36661] hbase.ZNodeClearer: Environment variable HBASE_ZNODE_FILE not set; znodes will not be cleared on crash by start scripts (Longer MTTR!)
hbase-master                 | 2021-08-31 00:21:47,231 INFO  [RS:0;hbase-master:36661] hfile.CacheConfig: Created cacheConfig: blockCache=LruBlockCache{blockCount=0, currentSize=1669592, freeSize=1625222312, maxSize=1626891904, heapSize=1669592, minSize=1545547264, minFactor=0.95, multiSize=772773632, multiFactor=0.5, singleSize=386386816, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
hbase-master                 | 2021-08-31 00:21:47,388 INFO  [RS:0;hbase-master:36661] wal.WALFactory: Instantiating WALProvider of type class org.apache.hadoop.hbase.wal.DefaultWALProvider
hbase-master                 | 2021-08-31 00:21:47,447 INFO  [RS:0;hbase-master:36661] wal.FSHLog: WAL configuration: blocksize=128 MB, rollsize=121.60 MB, prefix=hbase-master%2C36661%2C1630369300709.default, suffix=, logDir=hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709, archiveDir=hdfs://namenode:8020/hbase/oldWALs
hbase-master                 | 2021-08-31 00:21:47,665 INFO  [RS:0;hbase-master:36661] wal.FSHLog: Slow sync cost: 160 ms, current pipeline: []
hbase-master                 | 2021-08-31 00:21:47,666 INFO  [RS:0;hbase-master:36661] wal.FSHLog: New WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369307448
hbase-master                 | 2021-08-31 00:21:47,689 INFO  [RS:0;hbase-master:36661] regionserver.MetricsRegionServerWrapperImpl: Computing regionserver metrics every 5000 milliseconds
hbase-master                 | 2021-08-31 00:21:47,696 INFO  [RS:0;hbase-master:36661] regionserver.ReplicationSourceManager: Current list of replicators: [hbase-master,36661,1630369300709] other RSs: [hbase-master,36661,1630369300709]
hbase-master                 | 2021-08-31 00:21:47,730 INFO  [SplitLogWorker-hbase-master:36661] regionserver.SplitLogWorker: SplitLogWorker hbase-master,36661,1630369300709 starting
hbase-master                 | 2021-08-31 00:21:47,730 INFO  [RS:0;hbase-master:36661] regionserver.HeapMemoryManager: Starting HeapMemoryTuner chore.
hbase-master                 | 2021-08-31 00:21:47,732 INFO  [RS:0;hbase-master:36661] regionserver.HRegionServer: Serving as hbase-master,36661,1630369300709, RpcServer on hbase-master/172.18.0.6:36661, sessionid=0x17b9995221e0001
hbase-master                 | 2021-08-31 00:21:47,738 INFO  [RS:0;hbase-master:36661] quotas.RegionServerQuotaManager: Quota support disabled
hbase-master                 | 2021-08-31 00:21:48,732 INFO  [hbase-master:45735.activeMasterManager] master.ServerManager: Waiting for region servers count to settle; currently checked in 1, slept for 4366 ms, expecting minimum of 1, maximum of 2147483647, timeout of 4500 ms, interval of 1500 ms.
hbase-master                 | 2021-08-31 00:21:48,883 INFO  [hbase-master:45735.activeMasterManager] master.ServerManager: Finished waiting for region servers count to settle; checked in 1, slept for 4517 ms, expecting minimum of 1, maximum of 2147483647, master is running
hbase-master                 | 2021-08-31 00:21:48,892 INFO  [hbase-master:45735.activeMasterManager] master.MasterFileSystem: Log folder hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709 belongs to an existing region server
hbase-master                 | 2021-08-31 00:21:49,711 INFO  [hbase-master:45735.activeMasterManager] zookeeper.MetaTableLocator: Deleting hbase:meta region location in ZooKeeper
hbase-master                 | 2021-08-31 00:21:49,763 INFO  [hbase-master:45735.activeMasterManager] master.AssignmentManager: Setting node as OFFLINED in ZooKeeper for region {ENCODED => 1588230740, NAME => 'hbase:meta,,1', STARTKEY => '', ENDKEY => ''}
hbase-master                 | 2021-08-31 00:21:49,807 INFO  [hbase-master:45735.activeMasterManager] zookeeper.ZKTableStateManager: Moving table hbase:meta state from null to ENABLED
hbase-master                 | 2021-08-31 00:21:49,905 INFO  [hbase-master:45735.activeMasterManager] master.AssignmentManager: Assigning hbase:meta,,1.1588230740 to hbase-master,36661,1630369300709
hbase-master                 | 2021-08-31 00:21:49,905 INFO  [hbase-master:45735.activeMasterManager] master.RegionStates: Transition {1588230740 state=OFFLINE, ts=1630369309763, server=null} to {1588230740 state=PENDING_OPEN, ts=1630369309905, server=hbase-master,36661,1630369300709}
hbase-master                 | 2021-08-31 00:21:49,931 INFO  [PriorityRpcServer.handler=1,queue=1,port=36661] regionserver.RSRpcServices: Open hbase:meta,,1.1588230740
hbase-master                 | 2021-08-31 00:21:49,938 INFO  [hbase-master:45735.activeMasterManager] master.ServerManager: AssignmentManager hasn't finished failover cleanup; waiting
hbase-master                 | 2021-08-31 00:21:49,979 INFO  [RS_OPEN_META-hbase-master:36661-0] wal.WALFactory: Instantiating WALProvider of type class org.apache.hadoop.hbase.wal.DefaultWALProvider
hbase-master                 | 2021-08-31 00:21:49,981 INFO  [AM.ZK.Worker-pool2-t1] master.RegionStates: Transition {1588230740 state=PENDING_OPEN, ts=1630369309905, server=hbase-master,36661,1630369300709} to {1588230740 state=OPENING, ts=1630369309981, server=hbase-master,36661,1630369300709}
hbase-master                 | 2021-08-31 00:21:49,983 INFO  [RS_OPEN_META-hbase-master:36661-0] wal.FSHLog: WAL configuration: blocksize=128 MB, rollsize=121.60 MB, prefix=hbase-master%2C36661%2C1630369300709..meta, suffix=.meta, logDir=hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709, archiveDir=hdfs://namenode:8020/hbase/oldWALs
hbase-master                 | 2021-08-31 00:21:50,126 INFO  [RS_OPEN_META-hbase-master:36661-0] wal.FSHLog: Slow sync cost: 97 ms, current pipeline: []
hbase-master                 | 2021-08-31 00:21:50,126 INFO  [RS_OPEN_META-hbase-master:36661-0] wal.FSHLog: New WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369309983.meta
hbase-master                 | 2021-08-31 00:21:50,147 INFO  [RS_OPEN_META-hbase-master:36661-0] regionserver.RegionCoprocessorHost: Loaded coprocessor org.apache.hadoop.hbase.coprocessor.MultiRowMutationEndpoint from HTD of hbase:meta successfully.
hbase-master                 | 2021-08-31 00:21:50,155 INFO  [StoreOpener-1588230740-1] hfile.CacheConfig: Created cacheConfig for info: blockCache=LruBlockCache{blockCount=0, currentSize=1669592, freeSize=1625222312, maxSize=1626891904, heapSize=1669592, minSize=1545547264, minFactor=0.95, multiSize=772773632, multiFactor=0.5, singleSize=386386816, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
hbase-master                 | 2021-08-31 00:21:50,155 INFO  [StoreOpener-1588230740-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000
hbase-master                 | 2021-08-31 00:21:50,299 INFO  [RS_OPEN_META-hbase-master:36661-0] regionserver.HRegion: Onlined 1588230740; next sequenceid=3
hbase-master                 | 2021-08-31 00:21:50,316 WARN  [sync.1] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of WAL. current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:21:50,318 INFO  [PostOpenDeployTasks:1588230740] regionserver.HRegionServer: Post open deploy tasks for hbase:meta,,1.1588230740
hbase-master                 | 2021-08-31 00:21:50,319 INFO  [PostOpenDeployTasks:1588230740] zookeeper.MetaTableLocator: Setting hbase:meta region location in ZooKeeper as hbase-master,36661,1630369300709
hbase-master                 | 2021-08-31 00:21:50,471 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Slow sync cost: 122 ms, current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:21:50,473 INFO  [AM.ZK.Worker-pool2-t2] master.RegionStates: Transition {1588230740 state=OPENING, ts=1630369309981, server=hbase-master,36661,1630369300709} to {1588230740 state=OPEN, ts=1630369310473, server=hbase-master,36661,1630369300709}
hbase-master                 | 2021-08-31 00:21:50,475 INFO  [AM.ZK.Worker-pool2-t2] coordination.ZkOpenRegionCoordination: Handling OPENED of 1588230740 from hbase-master,45735,1630369299333; deleting unassigned node
hbase-master                 | 2021-08-31 00:21:50,523 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369309983.meta with entries=1, filesize=265 B; new WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369310318.meta
hbase-master                 | 2021-08-31 00:21:50,524 INFO  [hbase-master:45735.activeMasterManager] master.HMaster: hbase:meta with replicaId 0 assigned=1, rit=false, location=hbase-master,36661,1630369300709
hbase-master                 | 2021-08-31 00:21:50,526 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Archiving hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369309983.meta to hdfs://namenode:8020/hbase/oldWALs/hbase-master%2C36661%2C1630369300709..meta.1630369309983.meta
hbase-master                 | 2021-08-31 00:21:50,588 INFO  [hbase-master:45735.activeMasterManager] hbase.MetaMigrationConvertingToPB: hbase:meta doesn't have any entries to update.
hbase-master                 | 2021-08-31 00:21:50,588 INFO  [hbase-master:45735.activeMasterManager] hbase.MetaMigrationConvertingToPB: META already up-to date with PB serialization
hbase-master                 | 2021-08-31 00:21:50,593 INFO  [hbase-master:45735.activeMasterManager] master.AssignmentManager: Clean cluster startup. Assigning user regions
hbase-master                 | 2021-08-31 00:21:50,595 INFO  [hbase-master:45735.activeMasterManager] master.AssignmentManager: Joined the cluster in 6ms, failover=false
hbase-master                 | 2021-08-31 00:21:50,630 INFO  [hbase-master:45735.activeMasterManager] master.TableNamespaceManager: Namespace table not found. Creating...
hbase-master                 | 2021-08-31 00:21:51,688 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: creating HRegion hbase:namespace HTD == 'hbase:namespace', {NAME => 'info', BLOOMFILTER => 'ROW', VERSIONS => '10', IN_MEMORY => 'true', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', CACHE_DATA_IN_L1 => 'true', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '8192', REPLICATION_SCOPE => '0'} RootDir = hdfs://namenode:8020/hbase/.tmp Table name == hbase:namespace
hbase-master                 | 2021-08-31 00:21:51,876 INFO  [RegionOpenAndInitThread-hbase:namespace-1] regionserver.HRegion: Closed hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e.
hbase-master                 | 2021-08-31 00:21:52,187 WARN  [sync.3] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of WAL. current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:21:52,199 INFO  [ProcedureExecutor-0] hbase.MetaTableAccessor: Added 1
hbase-master                 | 2021-08-31 00:21:52,380 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369310318.meta with entries=1, filesize=270 B; new WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312190.meta
hbase-master                 | 2021-08-31 00:21:52,405 INFO  [ProcedureExecutor-0] zookeeper.ZKTableStateManager: Moving table hbase:namespace state from null to ENABLING
hbase-master                 | 2021-08-31 00:21:52,576 INFO  [ProcedureExecutor-0] master.AssignmentManager: Assigning 1 region(s) to hbase-master,36661,1630369300709
hbase-master                 | 2021-08-31 00:21:52,633 INFO  [ProcedureExecutor-0] master.RegionStates: Transition {5c94956e44945c16a05039143901db1e state=OFFLINE, ts=1630369312580, server=null} to {5c94956e44945c16a05039143901db1e state=PENDING_OPEN, ts=1630369312633, server=hbase-master,36661,1630369300709}
hbase-master                 | 2021-08-31 00:21:52,634 INFO  [PriorityRpcServer.handler=1,queue=1,port=36661] regionserver.RSRpcServices: Open hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e.
hbase-master                 | 2021-08-31 00:21:52,640 INFO  [ProcedureExecutor-0] zookeeper.ZKTableStateManager: Moving table hbase:namespace state from ENABLING to ENABLED
hbase-master                 | 2021-08-31 00:21:52,725 INFO  [AM.ZK.Worker-pool2-t5] master.RegionStates: Transition {5c94956e44945c16a05039143901db1e state=PENDING_OPEN, ts=1630369312633, server=hbase-master,36661,1630369300709} to {5c94956e44945c16a05039143901db1e state=OPENING, ts=1630369312725, server=hbase-master,36661,1630369300709}
hbase-master                 | 2021-08-31 00:21:52,772 INFO  [StoreOpener-5c94956e44945c16a05039143901db1e-1] hfile.CacheConfig: Created cacheConfig for info: blockCache=LruBlockCache{blockCount=0, currentSize=1669592, freeSize=1625222312, maxSize=1626891904, heapSize=1669592, minSize=1545547264, minFactor=0.95, multiSize=772773632, multiFactor=0.5, singleSize=386386816, singleFactor=0.25}, cacheDataOnRead=true, cacheDataOnWrite=false, cacheIndexesOnWrite=false, cacheBloomsOnWrite=false, cacheEvictOnClose=false, cacheDataCompressed=false, prefetchOnOpen=false
hbase-master                 | 2021-08-31 00:21:52,773 INFO  [StoreOpener-5c94956e44945c16a05039143901db1e-1] compactions.CompactionConfiguration: size [134217728, 9223372036854775807, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; major period 604800000, major jitter 0.500000, min locality to compact 0.000000
hbase-master                 | 2021-08-31 00:21:52,894 INFO  [RS_OPEN_REGION-hbase-master:36661-0] regionserver.HRegion: Onlined 5c94956e44945c16a05039143901db1e; next sequenceid=2
hbase-master                 | 2021-08-31 00:21:52,903 WARN  [sync.1] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of WAL. current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:21:52,906 INFO  [PostOpenDeployTasks:5c94956e44945c16a05039143901db1e] regionserver.HRegionServer: Post open deploy tasks for hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e.
hbase-master                 | 2021-08-31 00:21:52,920 WARN  [sync.0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of WAL. current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:21:52,922 INFO  [PostOpenDeployTasks:5c94956e44945c16a05039143901db1e] hbase.MetaTableAccessor: Updated row hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. with server=hbase-master,36661,1630369300709
hbase-master                 | 2021-08-31 00:21:52,971 INFO  [AM.ZK.Worker-pool2-t6] master.RegionStates: Transition {5c94956e44945c16a05039143901db1e state=OPENING, ts=1630369312725, server=hbase-master,36661,1630369300709} to {5c94956e44945c16a05039143901db1e state=OPEN, ts=1630369312970, server=hbase-master,36661,1630369300709}
hbase-master                 | 2021-08-31 00:21:53,116 INFO  [regionserver/hbase-master/172.18.0.6:0.logRoller] wal.FSHLog: Slow sync cost: 171 ms, current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:21:53,189 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Slow sync cost: 121 ms, current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:21:53,190 INFO  [regionserver/hbase-master/172.18.0.6:0.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369307448 with entries=1, filesize=370 B; new WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369312904
hbase-master                 | 2021-08-31 00:21:53,192 INFO  [regionserver/hbase-master/172.18.0.6:0.logRoller] wal.FSHLog: Archiving hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369307448 to hdfs://namenode:8020/hbase/oldWALs/hbase-master%2C36661%2C1630369300709.default.1630369307448
hbase-master                 | 2021-08-31 00:21:53,317 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312190.meta with entries=1, filesize=617 B; new WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312922.meta
hbase-master                 | 2021-08-31 00:21:53,658 INFO  [hbase-master:45735.activeMasterManager] master.HMaster: Master has completed initialization
hbase-master                 | 2021-08-31 00:21:53,660 INFO  [hbase-master:45735.activeMasterManager] quotas.MasterQuotaManager: Quota support disabled
hbase-master                 | 2021-08-31 00:21:53,663 INFO  [hbase-master:45735.activeMasterManager] zookeeper.ZooKeeperWatcher: not a secure deployment, proceeding
hbase-master                 | 2021-08-31 00:22:14,562 INFO  [WALProcedureStoreSyncThread] wal.WALProcedureStore: Remove log: hdfs://namenode:8020/hbase/MasterProcWALs/state-00000000000000000001.log
hbase-master                 | 2021-08-31 00:22:14,563 INFO  [WALProcedureStoreSyncThread] wal.WALProcedureStore: Removed logs: [hdfs://namenode:8020/hbase/MasterProcWALs/state-00000000000000000002.log]
hbase-master                 | 2021-08-31 00:26:42,402 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=1.59 MB, freeSize=1.51 GB, max=1.52 GB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=29, evicted=0, evictedPerRun=0.0
hbase-master                 | 2021-08-31 00:26:57,716 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 257020ms
hbase-master                 | 2021-08-31 00:26:57,718 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:meta,,1.1588230740 because info has an old edit so flush to free WALs after random delay 92810ms
hbase-master                 | 2021-08-31 00:27:07,708 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 155301ms
hive_metastore               | STARTUP_MSG:   classpath = /opt/hive/conf:/opt/hive/lib/HikariCP-2.5.1.jar:/opt/hive/lib/RoaringBitmap-0.5.18.jar:/opt/hive/lib/ST4-4.0.4.jar:/opt/hive/lib/accumulo-core-1.6.0.jar:/opt/hive/lib/accumulo-fate-1.6.0.jar:/opt/hive/lib/accumulo-start-1.6.0.jar:/opt/hive/lib/accumulo-trace-1.6.0.jar:/opt/hive/lib/activation-1.1.jar:/opt/hive/lib/aether-api-0.9.0.M2.jar:/opt/hive/lib/aether-connector-file-0.9.0.M2.jar:/opt/hive/lib/aether-connector-okhttp-0.0.9.jar:/opt/hive/lib/aether-impl-0.9.0.M2.jar:/opt/hive/lib/aether-spi-0.9.0.M2.jar:/opt/hive/lib/aether-util-0.9.0.M2.jar:/opt/hive/lib/aircompressor-0.3.jar:/opt/hive/lib/airline-0.7.jar:/opt/hive/lib/ant-1.6.5.jar:/opt/hive/lib/ant-1.9.1.jar:/opt/hive/lib/ant-launcher-1.9.1.jar:/opt/hive/lib/antlr-runtime-3.5.2.jar:/opt/hive/lib/antlr4-runtime-4.5.jar:/opt/hive/lib/asm-3.1.jar:/opt/hive/lib/asm-commons-3.1.jar:/opt/hive/lib/asm-tree-3.1.jar:/opt/hive/lib/avatica-1.8.0.jar:/opt/hive/lib/avatica-metrics-1.8.0.jar:/opt/hive/lib/avro-1.7.7.jar:/opt/hive/lib/bonecp-0.8.0.RELEASE.jar:/opt/hive/lib/bytebuffer-collections-0.2.5.jar:/opt/hive/lib/calcite-core-1.10.0.jar:/opt/hive/lib/calcite-druid-1.10.0.jar:/opt/hive/lib/calcite-linq4j-1.10.0.jar:/opt/hive/lib/classmate-1.0.0.jar:/opt/hive/lib/commons-cli-1.2.jar:/opt/hive/lib/commons-codec-1.4.jar:/opt/hive/lib/commons-collections-3.2.2.jar:/opt/hive/lib/commons-compiler-2.7.6.jar:/opt/hive/lib/commons-compress-1.9.jar:/opt/hive/lib/commons-dbcp-1.4.jar:/opt/hive/lib/commons-dbcp2-2.0.1.jar:/opt/hive/lib/commons-el-1.0.jar:/opt/hive/lib/commons-httpclient-3.0.1.jar:/opt/hive/lib/commons-io-2.4.jar:/opt/hive/lib/commons-lang-2.6.jar:/opt/hive/lib/commons-lang3-3.1.jar:/opt/hive/lib/commons-logging-1.2.jar:/opt/hive/lib/commons-math-2.2.jar:/opt/hive/lib/commons-math3-3.6.1.jar:/opt/hive/lib/commons-pool-1.5.4.jar:/opt/hive/lib/commons-pool2-2.2.jar:/opt/hive/lib/commons-vfs2-2.0.jar:/opt/hive/lib/compress-lzf-1.0.3.jar:/opt/hive/lib/config-magic-0.9.jar:/opt/hive/lib/curator-client-2.7.1.jar:/opt/hive/lib/curator-framework-2.7.1.jar:/opt/hive/lib/curator-recipes-2.7.1.jar:/opt/hive/lib/curator-x-discovery-2.11.0.jar:/opt/hive/lib/datanucleus-api-jdo-4.2.4.jar:/opt/hive/lib/datanucleus-core-4.1.17.jar:/opt/hive/lib/datanucleus-rdbms-4.1.19.jar:/opt/hive/lib/derby-10.10.2.0.jar:/opt/hive/lib/derbyclient-10.11.1.1.jar:/opt/hive/lib/derbynet-10.11.1.1.jar:/opt/hive/lib/disruptor-3.3.0.jar:/opt/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hive/lib/druid-api-0.9.2.jar:/opt/hive/lib/druid-common-0.9.2.jar:/opt/hive/lib/druid-console-0.0.2.jar:/opt/hive/lib/druid-hdfs-storage-0.9.2.jar:/opt/hive/lib/druid-processing-0.9.2.jar:/opt/hive/lib/druid-server-0.9.2.jar:/opt/hive/lib/eigenbase-properties-1.1.5.jar:/opt/hive/lib/emitter-0.3.6.jar:/opt/hive/lib/extendedset-1.3.10.jar:/opt/hive/lib/findbugs-annotations-1.3.9-1.jar:/opt/hive/lib/geoip2-0.4.0.jar:/opt/hive/lib/geronimo-annotation_1.0_spec-1.1.1.jar:/opt/hive/lib/geronimo-jaspic_1.0_spec-1.0.jar:/opt/hive/lib/geronimo-jta_1.1_spec-1.1.1.jar:/opt/hive/lib/google-http-client-jackson2-1.15.0-rc.jar:/opt/hive/lib/groovy-all-2.4.4.jar:/opt/hive/lib/gson-2.2.4.jar:/opt/hive/lib/guava-14.0.1.jar:/opt/hive/lib/guice-multibindings-4.1.0.jar:/opt/hive/lib/guice-servlet-4.1.0.jar:/opt/hive/lib/hbase-annotations-1.1.1.jar:/opt/hive/lib/hbase-client-1.1.1.jar:/opt/hive/lib/hbase-common-1.1.1-tests.jar:/opt/hive/lib/hbase-common-1.1.1.jar:/opt/hive/lib/hbase-hadoop-compat-1.1.1.jar:/opt/hive/lib/hbase-hadoop2-compat-1.1.1-tests.jar:/opt/hive/lib/hbase-hadoop2-compat-1.1.1.jar:/opt/hive/lib/hbase-prefix-tree-1.1.1.jar:/opt/hive/lib/hbase-procedure-1.1.1.jar:/opt/hive/lib/hbase-protocol-1.1.1.jar:/opt/hive/lib/hbase-server-1.1.1.jar:/opt/hive/lib/hibernate-validator-5.1.3.Final.jar:/opt/hive/lib/hive-accumulo-handler-2.3.2.jar:/opt/hive/lib/hive-beeline-2.3.2.jar:/opt/hive/lib/hive-cli-2.3.2.jar:/opt/hive/lib/hive-common-2.3.2.jar:/opt/hive/lib/hive-contrib-2.3.2.jar:/opt/hive/lib/hive-druid-handler-2.3.2.jar:/opt/hive/lib/hive-exec-2.3.2.jar:/opt/hive/lib/hive-hbase-handler-2.3.2.jar:/opt/hive/lib/hive-hcatalog-core-2.3.2.jar:/opt/hive/lib/hive-hcatalog-server-extensions-2.3.2.jar:/opt/hive/lib/hive-hplsql-2.3.2.jar:/opt/hive/lib/hive-jdbc-2.3.2.jar:/opt/hive/lib/hive-jdbc-handler-2.3.2.jar:/opt/hive/lib/hive-llap-client-2.3.2.jar:/opt/hive/lib/hive-llap-common-2.3.2-tests.jar:/opt/hive/lib/hive-llap-common-2.3.2.jar:/opt/hive/lib/hive-llap-ext-client-2.3.2.jar:/opt/hive/lib/hive-llap-server-2.3.2.jar:/opt/hive/lib/hive-llap-tez-2.3.2.jar:/opt/hive/lib/hive-metastore-2.3.2.jar:/opt/hive/lib/hive-serde-2.3.2.jar:/opt/hive/lib/hive-service-2.3.2.jar:/opt/hive/lib/hive-service-rpc-2.3.2.jar:/opt/hive/lib/hive-shims-0.23-2.3.2.jar:/opt/hive/lib/hive-shims-2.3.2.jar:/opt/hive/lib/hive-shims-common-2.3.2.jar:/opt/hive/lib/hive-shims-scheduler-2.3.2.jar:/opt/hive/lib/hive-storage-api-2.4.0.jar:/opt/hive/lib/hive-testutils-2.3.2.jar:/opt/hive/lib/hive-vector-code-gen-2.3.2.jar:/opt/hive/lib/htrace-core-3.1.0-incubating.jar:/opt/hive/lib/http-client-1.0.4.jar:/opt/hive/lib/httpclient-4.4.jar:/opt/hive/lib/httpcore-4.4.jar:/opt/hive/lib/icu4j-4.8.1.jar:/opt/hive/lib/irc-api-1.0-0014.jar:/opt/hive/lib/ivy-2.4.0.jar:/opt/hive/lib/jackson-annotations-2.6.0.jar:/opt/hive/lib/jackson-core-2.6.5.jar:/opt/hive/lib/jackson-databind-2.6.5.jar:/opt/hive/lib/jackson-dataformat-smile-2.4.6.jar:/opt/hive/lib/jackson-datatype-guava-2.4.6.jar:/opt/hive/lib/jackson-datatype-joda-2.4.6.jar:/opt/hive/lib/jackson-jaxrs-1.9.13.jar:/opt/hive/lib/jackson-jaxrs-base-2.4.6.jar:/opt/hive/lib/jackson-jaxrs-json-provider-2.4.6.jar:/opt/hive/lib/jackson-jaxrs-smile-provider-2.4.6.jar:/opt/hive/lib/jackson-module-jaxb-annotations-2.4.6.jar:/opt/hive/lib/jackson-xc-1.9.13.jar:/opt/hive/lib/jamon-runtime-2.3.1.jar:/opt/hive/lib/janino-2.7.6.jar:/opt/hive/lib/jasper-compiler-5.5.23.jar:/opt/hive/lib/jasper-runtime-5.5.23.jar:/opt/hive/lib/java-util-0.27.10.jar:/opt/hive/lib/javax.el-3.0.0.jar:/opt/hive/lib/javax.el-api-3.0.0.jar:/opt/hive/lib/javax.inject-1.jar:/opt/hive/lib/javax.jdo-3.2.0-m3.jar:/opt/hive/lib/javax.servlet-3.0.0.v201112011016.jar:/opt/hive/lib/javax.servlet-api-3.1.0.jar:/opt/hive/lib/javolution-5.5.1.jar:/opt/hive/lib/jboss-logging-3.1.3.GA.jar:/opt/hive/lib/jcodings-1.0.8.jar:/opt/hive/lib/jcommander-1.32.jar:/opt/hive/lib/jdbi-2.63.1.jar:/opt/hive/lib/jdo-api-3.0.1.jar:/opt/hive/lib/jersey-client-1.9.jar:/opt/hive/lib/jersey-guice-1.19.jar:/opt/hive/lib/jersey-server-1.14.jar:/opt/hive/lib/jettison-1.1.jar:/opt/hive/lib/jetty-6.1.26.jar:/opt/hive/lib/jetty-all-7.6.0.v20120127.jar:/opt/hive/lib/jetty-client-9.2.5.v20141112.jar:/opt/hive/lib/jetty-continuation-9.2.5.v20141112.jar:/opt/hive/lib/jetty-http-9.2.5.v20141112.jar:/opt/hive/lib/jetty-io-9.2.5.v20141112.jar:/opt/hive/lib/jetty-proxy-9.2.5.v20141112.jar:/opt/hive/lib/jetty-security-9.2.5.v20141112.jar:/opt/hive/lib/jetty-server-9.2.5.v20141112.jar:/opt/hive/lib/jetty-servlet-9.2.5.v20141112.jar:/opt/hive/lib/jetty-servlets-9.2.5.v20141112.jar:/opt/hive/lib/jetty-sslengine-6.1.26.jar:/opt/hive/lib/jetty-util-6.1.26.jar:/opt/hive/lib/jetty-util-9.2.5.v20141112.jar:/opt/hive/lib/jline-2.12.jar:/opt/hive/lib/joda-time-2.8.1.jar:/opt/hive/lib/joni-2.1.2.jar:/opt/hive/lib/jpam-1.1.jar:/opt/hive/lib/json-1.8.jar:/opt/hive/lib/json-path-2.1.0.jar:/opt/hive/lib/jsp-2.1-6.1.14.jar:/opt/hive/lib/jsp-api-2.0.jar:/opt/hive/lib/jsp-api-2.1-6.1.14.jar:/opt/hive/lib/jsp-api-2.1.jar:/opt/hive/lib/jsr305-3.0.0.jar:/opt/hive/lib/jta-1.1.jar:/opt/hive/lib/libfb303-0.9.3.jar:/opt/hive/lib/libthrift-0.9.3.jar:/opt/hive/lib/log4j-1.2-api-2.6.2.jar:/opt/hive/lib/log4j-api-2.6.2.jar:/opt/hive/lib/log4j-core-2.6.2.jar:/opt/hive/lib/log4j-jul-2.5.jar:/opt/hive/lib/log4j-slf4j-impl-2.6.2.jar:/opt/hive/lib/log4j-web-2.6.2.jar:/opt/hive/lib/lz4-1.3.0.jar:/opt/hive/lib/mail-1.4.1.jar:/opt/hive/lib/mapdb-1.0.8.jar:/opt/hive/lib/maven-aether-provider-3.1.1.jar:/opt/hive/lib/maven-model-3.1.1.jar:/opt/hive/lib/maven-model-builder-3.1.1.jar:/opt/hive/lib/maven-repository-metadata-3.1.1.jar:/opt/hive/lib/maven-scm-api-1.4.jar:/opt/hive/lib/maven-scm-provider-svn-commons-1.4.jar:/opt/hive/lib/maven-scm-provider-svnexe-1.4.jar:/opt/hive/lib/maven-settings-3.1.1.jar:/opt/hive/lib/maven-settings-builder-3.1.1.jar:/opt/hive/lib/maxminddb-0.2.0.jar:/opt/hive/lib/metrics-core-2.2.0.jar:/opt/hive/lib/metrics-core-3.1.0.jar:/opt/hive/lib/metrics-json-3.1.0.jar:/opt/hive/lib/metrics-jvm-3.1.0.jar:/opt/hive/lib/mysql-metadata-storage-0.9.2.jar:/opt/hive/lib/netty-3.6.2.Final.jar:/opt/hive/lib/netty-all-4.0.52.Final.jar:/opt/hive/lib/okhttp-1.0.2.jar:/opt/hive/lib/opencsv-2.3.jar:/opt/hive/lib/orc-core-1.3.3.jar:/opt/hive/lib/org.abego.treelayout.core-1.0.1.jar:/opt/hive/lib/paranamer-2.3.jar:/opt/hive/lib/parquet-hadoop-bundle-1.8.1.jar:/opt/hive/lib/pentaho-aggdesigner-algorithm-5.1.5-jhyde.jar:/opt/hive/lib/plexus-interpolation-1.19.jar:/opt/hive/lib/plexus-utils-3.0.15.jar:/opt/hive/lib/postgresql-9.4.1208.jre7.jar:/opt/hive/lib/postgresql-jdbc.jar:/opt/hive/lib/postgresql-metadata-storage-0.9.2.jar:/opt/hive/lib/protobuf-java-2.5.0.jar:/opt/hive/lib/regexp-1.3.jar:/opt/hive/lib/rhino-1.7R5.jar:/opt/hive/lib/server-metrics-0.2.8.jar:/opt/hive/lib/servlet-api-2.4.jar:/opt/hive/lib/servlet-api-2.5-6.1.14.jar:/opt/hive/lib/slider-core-0.90.2-incubating.jar:/opt/hive/lib/snappy-java-1.0.5.jar:/opt/hive/lib/spymemcached-2.11.7.jar:/opt/hive/lib/stax-api-1.0.1.jar:/opt/hive/lib/super-csv-2.2.0.jar:/opt/hive/lib/tempus-fugit-1.1.jar:/opt/hive/lib/tesla-aether-0.0.5.jar:/opt/hive/lib/transaction-api-1.1.jar:/opt/hive/lib/validation-api-1.1.0.Final.jar:/opt/hive/lib/velocity-1.5.jar:/opt/hive/lib/wagon-provider-api-2.4.jar:/opt/hive/lib/zookeeper-3.4.6.jar::/opt/hadoop-2.7.4/share/hadoop/tools/lib/hadoop-distcp-2.7.4.jar:/opt/hadoop-2.7.4/contrib/capacity-scheduler/*.jar:/etc/hadoop:/opt/hadoop-2.7.4/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hadoop-annotations-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hadoop-auth-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-nfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-common-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-api-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-client-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-registry-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.4.jar
hive_metastore               | STARTUP_MSG:   build = git://stakiar-MBP.local/Users/stakiar/Desktop/scratch-space/apache-hive -r 857a9fd8ad725a53bd95c1b2d6612f9b1155f44d; compiled by 'stakiar' on Thu Nov 9 09:11:39 PST 2017
hive_metastore               | ************************************************************/
hive_metastore               | 2021-08-31T00:22:01,076 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - Starting hive metastore on port 9083
hive_metastore               | 2021-08-31T00:22:01,165 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
hive_metastore               | 2021-08-31T00:22:03,112 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - Added admin role in metastore
hive_metastore               | 2021-08-31T00:22:03,136 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - Added public role in metastore
hive_metastore               | 2021-08-31T00:22:03,209 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - No user is added in admin role, since config is empty
hive_metastore               | 2021-08-31T00:22:03,318 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - Starting DB backed MetaStore Server with SetUGI enabled
hive_metastore               | 2021-08-31T00:22:03,322 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - Started the new metaserver on port [9083]...
hive_metastore               | 2021-08-31T00:22:03,322 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - Options.minWorkerThreads = 200
hive_metastore               | 2021-08-31T00:22:03,322 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - Options.maxWorkerThreads = 1000
hive_metastore               | 2021-08-31T00:22:03,322 INFO [main] org.apache.hadoop.hive.metastore.HiveMetaStore - TCP keepalive = true
hive_metastore               | 2021-08-31T00:22:13,045 INFO [pool-10-thread-2] org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:172.18.0.10 get_all_functions
hive_metastore               | 2021-08-31T00:22:13,086 INFO [pool-10-thread-2] org.apache.hadoop.hive.metastore.HiveMetaStore - 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
hive_metastore               | 2021-08-31T00:22:13,125 INFO [pool-10-thread-2] org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:172.18.0.10 get_all_databases
hive_metastore               | 2021-08-31T00:22:13,135 INFO [pool-10-thread-2] org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:172.18.0.10 get_all_tables: db=default
hive_metastore               | 2021-08-31T00:22:13,149 INFO [pool-10-thread-2] org.apache.hadoop.hive.metastore.HiveMetaStore - 1: source:172.18.0.10 get_multi_table : db=default tbls=
hbase-master                 | 2021-08-31 00:27:07,708 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:meta,,1.1588230740 because info has an old edit so flush to free WALs after random delay 287420ms
hbase-master                 | 2021-08-31 00:27:17,834 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 119338ms
hbase-master                 | 2021-08-31 00:27:17,835 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:meta,,1.1588230740 because info has an old edit so flush to free WALs after random delay 245699ms
hbase-master                 | 2021-08-31 00:27:27,694 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 225174ms
hbase-master                 | 2021-08-31 00:27:27,694 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:meta,,1.1588230740 because info has an old edit so flush to free WALs after random delay 129813ms
hbase-master                 | 2021-08-31 00:27:38,207 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 235132ms
hbase-master                 | 2021-08-31 00:27:38,208 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:meta,,1.1588230740 because info has an old edit so flush to free WALs after random delay 156455ms
hbase-master                 | 2021-08-31 00:27:47,751 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 118415ms
hbase-master                 | 2021-08-31 00:27:47,751 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:meta,,1.1588230740 because info has an old edit so flush to free WALs after random delay 169062ms
hbase-master                 | 2021-08-31 00:27:57,822 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 51079ms
hbase-master                 | 2021-08-31 00:27:57,823 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:meta,,1.1588230740 because info has an old edit so flush to free WALs after random delay 16163ms
hbase-master                 | 2021-08-31 00:28:07,770 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 68462ms
hbase-master                 | 2021-08-31 00:28:07,770 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:meta,,1.1588230740 because info has an old edit so flush to free WALs after random delay 284833ms
hbase-master                 | 2021-08-31 00:28:17,971 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 135972ms
hbase-master                 | 2021-08-31 00:28:17,972 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:meta,,1.1588230740 because info has an old edit so flush to free WALs after random delay 298581ms
hbase-master                 | 2021-08-31 00:28:27,694 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 278734ms
hbase-master                 | 2021-08-31 00:28:27,694 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:meta,,1.1588230740 because info has an old edit so flush to free WALs after random delay 146968ms
hbase-master                 | 2021-08-31 00:28:30,533 INFO  [MemStoreFlusher.0] regionserver.HRegion: Flushing 1/1 column families, memstore=1.23 KB
hbase-master                 | 2021-08-31 00:28:30,542 WARN  [sync.2] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of WAL. current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:28:30,780 INFO  [MemStoreFlusher.0] regionserver.DefaultStoreFlusher: Flushed, sequenceid=8, memsize=1.2 K, hasBloomFilter=false, into tmp file hdfs://namenode:8020/hbase/data/hbase/meta/1588230740/.tmp/aeff80002913436ba185a2305a568b8c
hbase-master                 | 2021-08-31 00:28:30,781 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312922.meta with entries=1, filesize=231 B; new WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369710542.meta
hbase-master                 | 2021-08-31 00:28:30,856 INFO  [MemStoreFlusher.0] regionserver.HStore: Added hdfs://namenode:8020/hbase/data/hbase/meta/1588230740/info/aeff80002913436ba185a2305a568b8c, entries=5, sequenceid=8, filesize=5.3 K
hbase-master                 | 2021-08-31 00:28:30,858 WARN  [sync.4] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of WAL. current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:28:30,858 INFO  [MemStoreFlusher.0] regionserver.HRegion: Finished memstore flush of ~1.23 KB/1264, currentsize=0 B/0 for region hbase:meta,,1.1588230740 in 325ms, sequenceid=8, compaction requested=false
hbase-master                 | 2021-08-31 00:28:30,994 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Rolled WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369710542.meta with entries=1, filesize=265 B; new WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369710858.meta
hbase-master                 | 2021-08-31 00:28:30,997 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Archiving hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369310318.meta to hdfs://namenode:8020/hbase/oldWALs/hbase-master%2C36661%2C1630369300709..meta.1630369310318.meta
hbase-master                 | 2021-08-31 00:28:31,066 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Archiving hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312190.meta to hdfs://namenode:8020/hbase/oldWALs/hbase-master%2C36661%2C1630369300709..meta.1630369312190.meta
hbase-master                 | 2021-08-31 00:28:31,138 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Archiving hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312922.meta to hdfs://namenode:8020/hbase/oldWALs/hbase-master%2C36661%2C1630369300709..meta.1630369312922.meta
hbase-master                 | 2021-08-31 00:28:31,198 INFO  [RS_OPEN_META-hbase-master:36661-0-MetaLogRoller] wal.FSHLog: Archiving hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369710542.meta to hdfs://namenode:8020/hbase/oldWALs/hbase-master%2C36661%2C1630369300709..meta.1630369710542.meta
hbase-master                 | 2021-08-31 00:28:37,899 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 125351ms
hbase-master                 | 2021-08-31 00:28:48,178 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 96401ms
hbase-master                 | 2021-08-31 00:28:58,495 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 35077ms
hbase-master                 | 2021-08-31 00:29:07,708 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 140053ms
hbase-master                 | 2021-08-31 00:29:17,694 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 272841ms
hbase-master                 | 2021-08-31 00:29:27,879 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 250766ms
hbase-master                 | 2021-08-31 00:29:37,825 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 227014ms
hbase-master                 | 2021-08-31 00:29:47,694 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 176759ms
hbase-master                 | 2021-08-31 00:29:57,717 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 263872ms
hbase-master                 | 2021-08-31 00:30:07,695 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 83951ms
hbase-master                 | 2021-08-31 00:30:17,873 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 73031ms
hbase-master                 | 2021-08-31 00:30:27,707 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 184202ms
hbase-master                 | 2021-08-31 00:30:37,984 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 234833ms
hbase-master                 | 2021-08-31 00:30:47,732 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 164721ms
hbase-master                 | 2021-08-31 00:30:57,697 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 22974ms
hbase-master                 | 2021-08-31 00:31:07,694 INFO  [hbase-master,36661,1630369300709_ChoreService_1] regionserver.HRegionServer: hbase-master,36661,1630369300709-MemstoreFlusherChore requesting flush of hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. because info has an old edit so flush to free WALs after random delay 49793ms
hbase-master                 | 2021-08-31 00:31:14,740 INFO  [MemStoreFlusher.1] regionserver.HRegion: Flushing 1/1 column families, memstore=344 B
hbase-master                 | 2021-08-31 00:31:14,744 WARN  [sync.0] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of WAL. current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:31:14,963 INFO  [MemStoreFlusher.1] regionserver.DefaultStoreFlusher: Flushed, sequenceid=7, memsize=344, hasBloomFilter=true, into tmp file hdfs://namenode:8020/hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e/.tmp/564a9fa8c9574d4ebacea3ad48aab682
hbase-master                 | 2021-08-31 00:31:14,965 INFO  [regionserver/hbase-master/172.18.0.6:0.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369312904 with entries=3, filesize=548 B; new WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369874744
hbase-master                 | 2021-08-31 00:31:15,044 INFO  [MemStoreFlusher.1] regionserver.HStore: Added hdfs://namenode:8020/hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e/info/564a9fa8c9574d4ebacea3ad48aab682, entries=2, sequenceid=7, filesize=4.8 K
hbase-master                 | 2021-08-31 00:31:15,048 WARN  [sync.2] wal.FSHLog: HDFS pipeline error detected. Found 1 replicas but expecting no less than 3 replicas.  Requesting close of WAL. current pipeline: [172.18.0.7:50010]
hbase-master                 | 2021-08-31 00:31:15,049 INFO  [MemStoreFlusher.1] regionserver.HRegion: Finished memstore flush of ~344 B/344, currentsize=0 B/0 for region hbase:namespace,,1630369310631.5c94956e44945c16a05039143901db1e. in 308ms, sequenceid=7, compaction requested=false
hbase-master                 | 2021-08-31 00:31:15,189 INFO  [regionserver/hbase-master/172.18.0.6:0.logRoller] wal.FSHLog: Rolled WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369874744 with entries=1, filesize=370 B; new WAL /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369875049
hbase-master                 | 2021-08-31 00:31:15,192 INFO  [regionserver/hbase-master/172.18.0.6:0.logRoller] wal.FSHLog: Archiving hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369312904 to hdfs://namenode:8020/hbase/oldWALs/hbase-master%2C36661%2C1630369300709.default.1630369312904
hbase-master                 | 2021-08-31 00:31:15,260 INFO  [regionserver/hbase-master/172.18.0.6:0.logRoller] wal.FSHLog: Archiving hdfs://namenode:8020/hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369874744 to hdfs://namenode:8020/hbase/oldWALs/hbase-master%2C36661%2C1630369300709.default.1630369874744
hbase-master                 | 2021-08-31 00:31:42,401 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=1.59 MB, freeSize=1.51 GB, max=1.52 GB, blockCount=0, accesses=0, hits=0, hitRatio=0, cachingAccesses=0, cachingHits=0, cachingHitsRatio=0,evictions=59, evicted=0, evictedPerRun=0.0
hbase-master                 | 2021-08-31 00:36:42,402 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=1.59 MB, freeSize=1.51 GB, max=1.52 GB, blockCount=1, accesses=1, hits=0, hitRatio=0, cachingAccesses=1, cachingHits=0, cachingHitsRatio=0,evictions=89, evicted=0, evictedPerRun=0.0
hbase-master                 | 2021-08-31 00:41:42,402 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=1.59 MB, freeSize=1.51 GB, max=1.52 GB, blockCount=1, accesses=2, hits=1, hitRatio=50.00%, , cachingAccesses=2, cachingHits=1, cachingHitsRatio=50.00%, evictions=119, evicted=0, evictedPerRun=0.0
hbase-master                 | 2021-08-31 00:46:42,402 INFO  [LruBlockCacheStatsExecutor] hfile.LruBlockCache: totalSize=1.59 MB, freeSize=1.51 GB, max=1.52 GB, blockCount=1, accesses=3, hits=2, hitRatio=66.67%, , cachingAccesses=3, cachingHits=2, cachingHitsRatio=66.67%, evictions=149, evicted=0, evictedPerRun=0.0
hive-metastore-postgresql    | The files belonging to this database system will be owned by user "postgres".
hive-metastore-postgresql    | This user must also own the server process.
hive-metastore-postgresql    | 
hive-metastore-postgresql    | The database cluster will be initialized with locale "en_US.utf8".
hive-metastore-postgresql    | The default database encoding has accordingly been set to "UTF8".
hive-metastore-postgresql    | The default text search configuration will be set to "english".
hive-metastore-postgresql    | 
hive-metastore-postgresql    | Data page checksums are disabled.
hive-metastore-postgresql    | 
hive-metastore-postgresql    | fixing permissions on existing directory /var/lib/postgresql/data ... ok
hive-metastore-postgresql    | creating subdirectories ... ok
hive-metastore-postgresql    | selecting default max_connections ... 100
hive-metastore-postgresql    | selecting default shared_buffers ... 128MB
hive-metastore-postgresql    | selecting dynamic shared memory implementation ... posix
hive-metastore-postgresql    | creating configuration files ... ok
hive-metastore-postgresql    | creating template1 database in /var/lib/postgresql/data/base/1 ... ok
hive-metastore-postgresql    | initializing pg_authid ... ok
hive-metastore-postgresql    | initializing dependencies ... ok
hive-metastore-postgresql    | creating system views ... ok
hive-metastore-postgresql    | loading system objects' descriptions ... ok
hive-metastore-postgresql    | creating collations ... ok
hive-metastore-postgresql    | creating conversions ... ok
hive-metastore-postgresql    | creating dictionaries ... ok
hive-metastore-postgresql    | setting privileges on built-in objects ... ok
hive-metastore-postgresql    | creating information schema ... ok
hive-metastore-postgresql    | loading PL/pgSQL server-side language ... ok
hive-metastore-postgresql    | vacuuming database template1 ... ok
hive-metastore-postgresql    | copying template1 to template0 ... ok
hive-metastore-postgresql    | copying template1 to postgres ... ok
hive-metastore-postgresql    | syncing data to disk ... ok
hive-metastore-postgresql    | 
hive-metastore-postgresql    | Success. You can now start the database server using:
hive-metastore-postgresql    | 
hive-metastore-postgresql    |     pg_ctl -D /var/lib/postgresql/data -l logfile start
hive-metastore-postgresql    | 
hive-metastore-postgresql    | 
hive-metastore-postgresql    | WARNING: enabling "trust" authentication for local connections
hive-metastore-postgresql    | You can change this by editing pg_hba.conf or using the option -A, or
hive-metastore-postgresql    | --auth-local and --auth-host, the next time you run initdb.
hive-metastore-postgresql    | ****************************************************
hive-metastore-postgresql    | WARNING: No password has been set for the database.
hive-metastore-postgresql    |          This will allow anyone with access to the
hive-metastore-postgresql    |          Postgres port to access your database. In
hive-metastore-postgresql    |          Docker's default configuration, this is
hive-metastore-postgresql    |          effectively any other container on the same
hive-metastore-postgresql    |          system.
hive-metastore-postgresql    | 
hive-metastore-postgresql    |          Use "-e POSTGRES_PASSWORD=password" to set
hive-metastore-postgresql    |          it in "docker run".
hive-metastore-postgresql    | ****************************************************
hive-metastore-postgresql    | waiting for server to start....LOG:  could not bind IPv6 socket: Cannot assign requested address
hive-metastore-postgresql    | HINT:  Is another postmaster already running on port 5432? If not, wait a few seconds and retry.
hive-metastore-postgresql    | LOG:  database system was shut down at 2021-08-31 00:21:34 UTC
hive-metastore-postgresql    | LOG:  MultiXact member wraparound protections are now enabled
hive-metastore-postgresql    | LOG:  database system is ready to accept connections
hive-metastore-postgresql    | LOG:  autovacuum launcher started
hive-metastore-postgresql    |  done
hive-metastore-postgresql    | server started
hive-metastore-postgresql    | ALTER ROLE
hive-metastore-postgresql    | 
hive-metastore-postgresql    | 
hive-metastore-postgresql    | /docker-entrypoint.sh: running /docker-entrypoint-initdb.d/init-user-db.sh
hive-metastore-postgresql    | CREATE ROLE
hive-metastore-postgresql    | CREATE DATABASE
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | You are now connected to database "metastore" as user "postgres".
hive-metastore-postgresql    | SET
hive-metastore-postgresql    | SET
hive-metastore-postgresql    | SET
hive-metastore-postgresql    | SET
hive-metastore-postgresql    | SET
hive-metastore-postgresql    | SET
hive-metastore-postgresql    | SET
hive-metastore-postgresql    | SET
hive-metastore-postgresql    | SET
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | ALTER TABLE
hive-metastore-postgresql    | REVOKE
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | INSERT 0 1
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | WARNING:  hash indexes are not WAL-logged and their use is discouraged
hive-metastore-postgresql    | psql:/hive/hive-txn-schema-2.3.0.postgres.sql:40: WARNING:  hash indexes are not WAL-logged and their use is discouraged
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | INSERT 0 1
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | WARNING:  hash indexes are not WAL-logged and their use is discouraged
hive-metastore-postgresql    | psql:/hive/hive-txn-schema-2.3.0.postgres.sql:74: WARNING:  hash indexes are not WAL-logged and their use is discouraged
hive-metastore-postgresql    | CREATE INDEX
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | INSERT 0 1
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | INSERT 0 1
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | CREATE TABLE
hive-metastore-postgresql    | Tuples only is on.
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | GRANT
hive-metastore-postgresql    | 
hive-metastore-postgresql    | LOG:  received fast shutdown request
hive-metastore-postgresql    | LOG:  aborting any active transactions
hive-metastore-postgresql    | LOG:  autovacuum launcher shutting down
hive-metastore-postgresql    | waiting for server to shut down....LOG:  shutting down
hive-metastore-postgresql    | ..LOG:  database system is shut down
hive-metastore-postgresql    |  done
hive-metastore-postgresql    | server stopped
hive-metastore-postgresql    | 
hive-metastore-postgresql    | PostgreSQL init process complete; ready for start up.
hive-metastore-postgresql    | 
hive-metastore-postgresql    | LOG:  database system was shut down at 2021-08-31 00:21:58 UTC
hive-metastore-postgresql    | LOG:  MultiXact member wraparound protections are now enabled
hive-metastore-postgresql    | LOG:  database system is ready to accept connections
hive-metastore-postgresql    | LOG:  autovacuum launcher started
hive-metastore-postgresql    | LOG:  incomplete startup packet
namenode                     | Configuring core
namenode                     |  - Setting hadoop.proxyuser.hue.hosts=*
namenode                     |  - Setting fs.defaultFS=hdfs://namenode:8020
namenode                     |  - Setting hadoop.proxyuser.hue.groups=*
namenode                     |  - Setting hadoop.http.staticuser.user=root
namenode                     | Configuring hdfs
namenode                     |  - Setting dfs.namenode.name.dir=file:///hadoop/dfs/name
namenode                     |  - Setting dfs.permissions.enabled=false
namenode                     |  - Setting dfs.webhdfs.enabled=true
namenode                     | Configuring yarn
namenode                     |  - Setting yarn.resourcemanager.fs.state-store.uri=/rmstate
namenode                     |  - Setting yarn.timeline-service.generic-application-history.enabled=true
namenode                     |  - Setting yarn.resourcemanager.recovery.enabled=true
namenode                     |  - Setting yarn.timeline-service.enabled=true
namenode                     |  - Setting yarn.log-aggregation-enable=true
namenode                     |  - Setting yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
namenode                     |  - Setting yarn.resourcemanager.system-metrics-publisher.enabled=true
namenode                     |  - Setting yarn.nodemanager.remote-app-log-dir=/app-logs
namenode                     |  - Setting yarn.resourcemanager.resource.tracker.address=resourcemanager:8031
namenode                     |  - Setting yarn.resourcemanager.hostname=resourcemanager
namenode                     |  - Setting yarn.timeline-service.hostname=historyserver
namenode                     |  - Setting yarn.log.server.url=http://historyserver:8188/applicationhistory/logs/
namenode                     |  - Setting yarn.resourcemanager.scheduler.address=resourcemanager:8030
namenode                     |  - Setting yarn.resourcemanager.address=resourcemanager:8032
namenode                     | Configuring httpfs
namenode                     | Configuring kms
namenode                     | Configuring mapred
namenode                     | Configuring for multihomed network
namenode                     | Formatting namenode name directory: /hadoop/dfs/name
namenode                     | 21/08/31 00:21:32 INFO namenode.NameNode: STARTUP_MSG: 
namenode                     | /************************************************************
namenode                     | STARTUP_MSG: Starting NameNode
namenode                     | STARTUP_MSG:   host = namenode/172.18.0.5
namenode                     | STARTUP_MSG:   args = [-format, test]
namenode                     | STARTUP_MSG:   version = 2.7.4
namenode                     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-2.7.4/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hadoop-annotations-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hadoop-auth-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-nfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-common-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-api-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-client-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-registry-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.4.jar:/contrib/capacity-scheduler/*.jar
namenode                     | STARTUP_MSG:   build = https://shv@git-wip-us.apache.org/repos/asf/hadoop.git -r cd915e1e8d9d0131462a0b7301586c175728a282; compiled by 'kshvachk' on 2017-08-01T00:29Z
namenode                     | STARTUP_MSG:   java = 1.8.0_131
namenode                     | ************************************************************/
namenode                     | 21/08/31 00:21:32 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
namenode                     | 21/08/31 00:21:32 INFO namenode.NameNode: createNameNode [-format, test]
namenode                     | Formatting using clusterid: CID-3ceaab1c-201a-45a6-9683-a461d7f02c68
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: No KeyProvider found.
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: fsLock is fair: true
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.BlockManager: The block deletion will start around 2021 Aug 31 00:21:33
namenode                     | 21/08/31 00:21:33 INFO util.GSet: Computing capacity for map BlocksMap
namenode                     | 21/08/31 00:21:33 INFO util.GSet: VM type       = 64-bit
namenode                     | 21/08/31 00:21:33 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB
namenode                     | 21/08/31 00:21:33 INFO util.GSet: capacity      = 2^21 = 2097152 entries
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.BlockManager: defaultReplication         = 3
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.BlockManager: maxReplication             = 512
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.BlockManager: minReplication             = 1
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
namenode                     | 21/08/31 00:21:33 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: supergroup          = supergroup
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: isPermissionEnabled = false
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: HA Enabled: false
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: Append Enabled: true
namenode                     | 21/08/31 00:21:33 INFO util.GSet: Computing capacity for map INodeMap
namenode                     | 21/08/31 00:21:33 INFO util.GSet: VM type       = 64-bit
namenode                     | 21/08/31 00:21:33 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB
namenode                     | 21/08/31 00:21:33 INFO util.GSet: capacity      = 2^20 = 1048576 entries
namenode                     | 21/08/31 00:21:33 INFO namenode.FSDirectory: ACLs enabled? false
namenode                     | 21/08/31 00:21:33 INFO namenode.FSDirectory: XAttrs enabled? true
namenode                     | 21/08/31 00:21:33 INFO namenode.FSDirectory: Maximum size of an xattr: 16384
namenode                     | 21/08/31 00:21:33 INFO namenode.NameNode: Caching file names occuring more than 10 times
namenode                     | 21/08/31 00:21:33 INFO util.GSet: Computing capacity for map cachedBlocks
namenode                     | 21/08/31 00:21:33 INFO util.GSet: VM type       = 64-bit
namenode                     | 21/08/31 00:21:33 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB
namenode                     | 21/08/31 00:21:33 INFO util.GSet: capacity      = 2^18 = 262144 entries
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
namenode                     | 21/08/31 00:21:33 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
namenode                     | 21/08/31 00:21:33 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
namenode                     | 21/08/31 00:21:33 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
namenode                     | 21/08/31 00:21:33 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
namenode                     | 21/08/31 00:21:33 INFO util.GSet: Computing capacity for map NameNodeRetryCache
namenode                     | 21/08/31 00:21:33 INFO util.GSet: VM type       = 64-bit
namenode                     | 21/08/31 00:21:33 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
namenode                     | 21/08/31 00:21:33 INFO util.GSet: capacity      = 2^15 = 32768 entries
namenode                     | 21/08/31 00:21:33 INFO namenode.FSImage: Allocated new BlockPoolId: BP-730104245-172.18.0.5-1630369293664
namenode                     | 21/08/31 00:21:33 INFO common.Storage: Storage directory /hadoop/dfs/name has been successfully formatted.
namenode                     | 21/08/31 00:21:33 INFO namenode.FSImageFormatProtobuf: Saving image file /hadoop/dfs/name/current/fsimage.ckpt_0000000000000000000 using no compression
namenode                     | 21/08/31 00:21:33 INFO namenode.FSImageFormatProtobuf: Image file /hadoop/dfs/name/current/fsimage.ckpt_0000000000000000000 of size 321 bytes saved in 0 seconds.
namenode                     | 21/08/31 00:21:34 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
namenode                     | 21/08/31 00:21:34 INFO util.ExitUtil: Exiting with status 0
namenode                     | 21/08/31 00:21:34 INFO namenode.NameNode: SHUTDOWN_MSG: 
namenode                     | /************************************************************
namenode                     | SHUTDOWN_MSG: Shutting down NameNode at namenode/172.18.0.5
namenode                     | ************************************************************/
namenode                     | 21/08/31 00:21:34 INFO namenode.NameNode: STARTUP_MSG: 
namenode                     | /************************************************************
namenode                     | STARTUP_MSG: Starting NameNode
namenode                     | STARTUP_MSG:   host = namenode/172.18.0.5
namenode                     | STARTUP_MSG:   args = []
namenode                     | STARTUP_MSG:   version = 2.7.4
namenode                     | STARTUP_MSG:   classpath = /etc/hadoop:/opt/hadoop-2.7.4/share/hadoop/common/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hadoop-annotations-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-httpclient-3.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-net-3.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-configuration-1.6.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-framework-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jets3t-0.9.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hadoop-auth-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/httpcore-4.2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/avro-1.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/activation-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-digester-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/curator-client-2.7.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/httpclient-4.2.5.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.4/share/hadoop/common/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-nfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/common/hadoop-common-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/htrace-core-3.1.0-incubating.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/lib/netty-all-4.0.23.Final.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/hdfs/hadoop-hdfs-nfs-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-codec-1.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/servlet-api-2.5.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-lang-2.6.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-client-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guice-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-cli-1.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-collections-3.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jetty-6.1.26.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/guava-11.0.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/activation-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jettison-1.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jsr305-3.0.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-json-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-api-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-client-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-registry-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-tests-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/asm-3.2.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/hadoop-annotations-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/guice-3.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/junit-4.11.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/javax.inject-1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/xz-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.4-tests.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.4.jar:/opt/hadoop-2.7.4/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.7.4.jar:/contrib/capacity-scheduler/*.jar
namenode                     | STARTUP_MSG:   build = https://shv@git-wip-us.apache.org/repos/asf/hadoop.git -r cd915e1e8d9d0131462a0b7301586c175728a282; compiled by 'kshvachk' on 2017-08-01T00:29Z
namenode                     | STARTUP_MSG:   java = 1.8.0_131
namenode                     | ************************************************************/
namenode                     | 21/08/31 00:21:34 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
namenode                     | 21/08/31 00:21:34 INFO namenode.NameNode: createNameNode []
namenode                     | 21/08/31 00:21:34 INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
namenode                     | 21/08/31 00:21:34 INFO impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
namenode                     | 21/08/31 00:21:34 INFO impl.MetricsSystemImpl: NameNode metrics system started
namenode                     | 21/08/31 00:21:34 INFO namenode.NameNode: fs.defaultFS is hdfs://namenode:8020
namenode                     | 21/08/31 00:21:34 INFO namenode.NameNode: Clients are to use namenode:8020 to access this namenode/service.
namenode                     | 21/08/31 00:21:34 INFO hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:50070
namenode                     | 21/08/31 00:21:34 INFO mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
namenode                     | 21/08/31 00:21:34 INFO server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
namenode                     | 21/08/31 00:21:34 INFO http.HttpRequestLog: Http request log for http.requests.namenode is not defined
namenode                     | 21/08/31 00:21:34 INFO http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
namenode                     | 21/08/31 00:21:34 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
namenode                     | 21/08/31 00:21:34 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
namenode                     | 21/08/31 00:21:34 INFO http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
namenode                     | 21/08/31 00:21:34 INFO http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
namenode                     | 21/08/31 00:21:34 INFO http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
namenode                     | 21/08/31 00:21:34 INFO http.HttpServer2: Jetty bound to port 50070
namenode                     | 21/08/31 00:21:34 INFO mortbay.log: jetty-6.1.26
namenode                     | 21/08/31 00:21:35 INFO mortbay.log: Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:50070
namenode                     | 21/08/31 00:21:35 WARN namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
namenode                     | 21/08/31 00:21:35 WARN namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: No KeyProvider found.
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: fsLock is fair: true
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.BlockManager: The block deletion will start around 2021 Aug 31 00:21:35
namenode                     | 21/08/31 00:21:35 INFO util.GSet: Computing capacity for map BlocksMap
namenode                     | 21/08/31 00:21:35 INFO util.GSet: VM type       = 64-bit
namenode                     | 21/08/31 00:21:35 INFO util.GSet: 2.0% max memory 889 MB = 17.8 MB
namenode                     | 21/08/31 00:21:35 INFO util.GSet: capacity      = 2^21 = 2097152 entries
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.BlockManager: dfs.block.access.token.enable=false
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.BlockManager: defaultReplication         = 3
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.BlockManager: maxReplication             = 512
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.BlockManager: minReplication             = 1
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.BlockManager: replicationRecheckInterval = 3000
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.BlockManager: encryptDataTransfer        = false
namenode                     | 21/08/31 00:21:35 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: supergroup          = supergroup
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: isPermissionEnabled = false
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: HA Enabled: false
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: Append Enabled: true
namenode                     | 21/08/31 00:21:35 INFO util.GSet: Computing capacity for map INodeMap
namenode                     | 21/08/31 00:21:35 INFO util.GSet: VM type       = 64-bit
namenode                     | 21/08/31 00:21:35 INFO util.GSet: 1.0% max memory 889 MB = 8.9 MB
namenode                     | 21/08/31 00:21:35 INFO util.GSet: capacity      = 2^20 = 1048576 entries
namenode                     | 21/08/31 00:21:35 INFO namenode.FSDirectory: ACLs enabled? false
namenode                     | 21/08/31 00:21:35 INFO namenode.FSDirectory: XAttrs enabled? true
namenode                     | 21/08/31 00:21:35 INFO namenode.FSDirectory: Maximum size of an xattr: 16384
namenode                     | 21/08/31 00:21:35 INFO namenode.NameNode: Caching file names occuring more than 10 times
namenode                     | 21/08/31 00:21:35 INFO util.GSet: Computing capacity for map cachedBlocks
namenode                     | 21/08/31 00:21:35 INFO util.GSet: VM type       = 64-bit
namenode                     | 21/08/31 00:21:35 INFO util.GSet: 0.25% max memory 889 MB = 2.2 MB
namenode                     | 21/08/31 00:21:35 INFO util.GSet: capacity      = 2^18 = 262144 entries
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: dfs.namenode.safemode.min.datanodes = 0
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: dfs.namenode.safemode.extension     = 30000
namenode                     | 21/08/31 00:21:35 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
namenode                     | 21/08/31 00:21:35 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
namenode                     | 21/08/31 00:21:35 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: Retry cache on namenode is enabled
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
namenode                     | 21/08/31 00:21:35 INFO util.GSet: Computing capacity for map NameNodeRetryCache
namenode                     | 21/08/31 00:21:35 INFO util.GSet: VM type       = 64-bit
namenode                     | 21/08/31 00:21:35 INFO util.GSet: 0.029999999329447746% max memory 889 MB = 273.1 KB
namenode                     | 21/08/31 00:21:35 INFO util.GSet: capacity      = 2^15 = 32768 entries
namenode                     | 21/08/31 00:21:35 INFO common.Storage: Lock on /hadoop/dfs/name/in_use.lock acquired by nodename 266@namenode
namenode                     | 21/08/31 00:21:35 INFO namenode.FileJournalManager: Recovering unfinalized segments in /hadoop/dfs/name/current
namenode                     | 21/08/31 00:21:35 INFO namenode.FSImage: No edit log streams selected.
namenode                     | 21/08/31 00:21:35 INFO namenode.FSImage: Planning to load image: FSImageFile(file=/hadoop/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
namenode                     | 21/08/31 00:21:35 INFO namenode.FSImageFormatPBINode: Loading 1 INodes.
namenode                     | 21/08/31 00:21:35 INFO namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
namenode                     | 21/08/31 00:21:35 INFO namenode.FSImage: Loaded image for txid 0 from /hadoop/dfs/name/current/fsimage_0000000000000000000
namenode                     | 21/08/31 00:21:35 INFO namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
namenode                     | 21/08/31 00:21:35 INFO namenode.FSEditLog: Starting log segment at 1
namenode                     | 21/08/31 00:21:36 INFO namenode.NameCache: initialized with 0 entries 0 lookups
namenode                     | 21/08/31 00:21:36 INFO namenode.FSNamesystem: Finished loading FSImage in 907 msecs
namenode                     | 21/08/31 00:21:36 INFO namenode.NameNode: RPC server is binding to 0.0.0.0:8020
namenode                     | 21/08/31 00:21:36 INFO ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000
namenode                     | 21/08/31 00:21:36 INFO ipc.Server: Starting Socket Reader #1 for port 8020
namenode                     | 21/08/31 00:21:36 INFO namenode.FSNamesystem: Registered FSNamesystemState MBean
namenode                     | 21/08/31 00:21:36 INFO namenode.LeaseManager: Number of blocks under construction: 0
namenode                     | 21/08/31 00:21:36 INFO namenode.LeaseManager: Number of blocks under construction: 0
namenode                     | 21/08/31 00:21:36 INFO namenode.FSNamesystem: initializing replication queues
namenode                     | 21/08/31 00:21:36 INFO hdfs.StateChange: STATE* Leaving safe mode after 1 secs
namenode                     | 21/08/31 00:21:36 INFO hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
namenode                     | 21/08/31 00:21:36 INFO hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
namenode                     | 21/08/31 00:21:36 INFO blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
namenode                     | 21/08/31 00:21:36 INFO blockmanagement.BlockManager: Total number of blocks            = 0
namenode                     | 21/08/31 00:21:36 INFO blockmanagement.BlockManager: Number of invalid blocks          = 0
namenode                     | 21/08/31 00:21:36 INFO blockmanagement.BlockManager: Number of under-replicated blocks = 0
namenode                     | 21/08/31 00:21:36 INFO blockmanagement.BlockManager: Number of  over-replicated blocks = 0
namenode                     | 21/08/31 00:21:36 INFO blockmanagement.BlockManager: Number of blocks being written    = 0
namenode                     | 21/08/31 00:21:36 INFO hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
namenode                     | 21/08/31 00:21:36 INFO ipc.Server: IPC Server Responder: starting
namenode                     | 21/08/31 00:21:36 INFO ipc.Server: IPC Server listener on 8020: starting
namenode                     | 21/08/31 00:21:36 INFO namenode.NameNode: NameNode RPC up at: namenode/172.18.0.5:8020
namenode                     | 21/08/31 00:21:36 INFO namenode.FSNamesystem: Starting services required for active state
namenode                     | 21/08/31 00:21:36 INFO blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
namenode                     | 21/08/31 00:21:40 INFO hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(172.18.0.7:50010, datanodeUuid=d96ad8f4-e251-4ce3-b385-1310f3797c39, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-3ceaab1c-201a-45a6-9683-a461d7f02c68;nsid=1845641953;c=0) storage d96ad8f4-e251-4ce3-b385-1310f3797c39
namenode                     | 21/08/31 00:21:40 INFO blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
namenode                     | 21/08/31 00:21:40 INFO net.NetworkTopology: Adding a new node: /default-rack/172.18.0.7:50010
namenode                     | 21/08/31 00:21:40 INFO blockmanagement.DatanodeDescriptor: Number of failed storage changes from 0 to 0
namenode                     | 21/08/31 00:21:40 INFO blockmanagement.DatanodeDescriptor: Adding new storage ID DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf for DN 172.18.0.7:50010
namenode                     | 21/08/31 00:21:40 INFO BlockStateChange: BLOCK* processReport 0xb1b301213f8: from storage DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf node DatanodeRegistration(172.18.0.7:50010, datanodeUuid=d96ad8f4-e251-4ce3-b385-1310f3797c39, infoPort=50075, infoSecurePort=0, ipcPort=50020, storageInfo=lv=-56;cid=CID-3ceaab1c-201a-45a6-9683-a461d7f02c68;nsid=1845641953;c=0), blocks: 0, hasStaleStorage: false, processing time: 0 msecs
namenode                     | 21/08/31 00:21:41 INFO hdfs.StateChange: BLOCK* allocate blk_1073741825_1001{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/.tmp/hbase.version
namenode                     | 21/08/31 00:21:41 INFO namenode.FSNamesystem: BLOCK* blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} is not COMPLETE (ucState = COMMITTED, replication# = 0 <  minimum = 1) in file /hbase/.tmp/hbase.version
namenode                     | 21/08/31 00:21:41 INFO namenode.EditLogFileOutputStream: Nothing to flush
namenode                     | 21/08/31 00:21:41 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741825_1001{UCState=COMMITTED, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 7
namenode                     | 21/08/31 00:21:41 INFO hdfs.StateChange: DIR* completeFile: /hbase/.tmp/hbase.version is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:41 INFO hdfs.StateChange: BLOCK* allocate blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/.tmp/hbase.id
namenode                     | 21/08/31 00:21:41 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741826_1002{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 0
namenode                     | 21/08/31 00:21:42 INFO hdfs.StateChange: DIR* completeFile: /hbase/.tmp/hbase.id is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:42 INFO hdfs.StateChange: BLOCK* allocate blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/data/hbase/meta/1588230740/.regioninfo
namenode                     | 21/08/31 00:21:42 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741827_1003{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 0
namenode                     | 21/08/31 00:21:42 INFO hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.regioninfo is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:42 INFO hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:42 INFO hdfs.StateChange: BLOCK* allocate blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/data/hbase/meta/.tmp/.tableinfo.0000000001
namenode                     | 21/08/31 00:21:42 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741828_1004{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 0
namenode                     | 21/08/31 00:21:42 INFO hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:47 INFO hdfs.StateChange: BLOCK* allocate blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369307448
namenode                     | 21/08/31 00:21:47 INFO hdfs.StateChange: BLOCK* fsync: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369307448 for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:50 INFO hdfs.StateChange: BLOCK* allocate blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369309983.meta
namenode                     | 21/08/31 00:21:50 INFO hdfs.StateChange: BLOCK* fsync: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369309983.meta for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:50 INFO hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/recovered.edits/3.seqid is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:50 INFO hdfs.StateChange: BLOCK* allocate blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369310318.meta
namenode                     | 21/08/31 00:21:50 INFO hdfs.StateChange: BLOCK* fsync: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369310318.meta for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:50 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741830_1006{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 83
namenode                     | 21/08/31 00:21:50 INFO hdfs.StateChange: DIR* completeFile: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369309983.meta is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:50 INFO hdfs.StateChange: BLOCK* allocate blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/MasterProcWALs/state-00000000000000000001.log
namenode                     | 21/08/31 00:21:50 INFO hdfs.StateChange: BLOCK* fsync: /hbase/MasterProcWALs/state-00000000000000000001.log for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:51 INFO hdfs.StateChange: BLOCK* allocate blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001
namenode                     | 21/08/31 00:21:51 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741833_1009{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 0
namenode                     | 21/08/31 00:21:51 INFO hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/hbase/namespace/.tmp/.tableinfo.0000000001 is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:51 INFO hdfs.StateChange: BLOCK* allocate blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/.tmp/data/hbase/namespace/5c94956e44945c16a05039143901db1e/.regioninfo
namenode                     | 21/08/31 00:21:51 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741834_1010{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 0
namenode                     | 21/08/31 00:21:51 INFO hdfs.StateChange: DIR* completeFile: /hbase/.tmp/data/hbase/namespace/5c94956e44945c16a05039143901db1e/.regioninfo is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:52 INFO hdfs.StateChange: BLOCK* allocate blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312190.meta
namenode                     | 21/08/31 00:21:52 INFO hdfs.StateChange: BLOCK* fsync: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312190.meta for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:52 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741831_1007{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 83
namenode                     | 21/08/31 00:21:52 INFO hdfs.StateChange: DIR* completeFile: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369310318.meta is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:52 INFO hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e/recovered.edits/2.seqid is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:52 INFO hdfs.StateChange: BLOCK* allocate blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369312904
namenode                     | 21/08/31 00:21:53 INFO hdfs.StateChange: BLOCK* fsync: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369312904 for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:53 INFO hdfs.StateChange: BLOCK* allocate blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312922.meta
namenode                     | 21/08/31 00:21:53 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741829_1005{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 83
namenode                     | 21/08/31 00:21:53 INFO hdfs.StateChange: BLOCK* fsync: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312922.meta for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:53 INFO hdfs.StateChange: DIR* completeFile: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369307448 is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:21:53 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741835_1011{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 83
namenode                     | 21/08/31 00:21:53 INFO hdfs.StateChange: DIR* completeFile: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312190.meta is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:22:14 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741832_1008{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 467
namenode                     | 21/08/31 00:22:14 INFO hdfs.StateChange: DIR* completeFile: /hbase/MasterProcWALs/state-00000000000000000001.log is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:22:14 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741832_1008 172.18.0.7:50010 
namenode                     | 21/08/31 00:22:15 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.7:50010 to delete [blk_1073741832_1008]
namenode                     | 21/08/31 00:28:30 INFO namenode.FSEditLog: Number of transactions: 125 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 8 Number of syncs: 85 SyncTimes(ms): 4152 
namenode                     | 21/08/31 00:28:30 INFO hdfs.StateChange: BLOCK* allocate blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369710542.meta
namenode                     | 21/08/31 00:28:30 INFO hdfs.StateChange: BLOCK* fsync: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369710542.meta for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:28:30 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741837_1013{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 83
namenode                     | 21/08/31 00:28:30 INFO hdfs.StateChange: BLOCK* allocate blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/data/hbase/meta/1588230740/.tmp/aeff80002913436ba185a2305a568b8c
namenode                     | 21/08/31 00:28:30 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741839_1015{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 0
namenode                     | 21/08/31 00:28:30 INFO hdfs.StateChange: DIR* completeFile: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369312922.meta is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:28:30 INFO hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/meta/1588230740/.tmp/aeff80002913436ba185a2305a568b8c is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:28:30 INFO hdfs.StateChange: BLOCK* allocate blk_1073741840_1016{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369710858.meta
namenode                     | 21/08/31 00:28:30 INFO hdfs.StateChange: BLOCK* fsync: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369710858.meta for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:28:30 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741838_1014{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 83
namenode                     | 21/08/31 00:28:30 INFO hdfs.StateChange: DIR* completeFile: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709..meta.1630369710542.meta is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:31:14 INFO namenode.FSEditLog: Number of transactions: 152 Total time for transactions(ms): 24 Number of transactions batched in Syncs: 8 Number of syncs: 106 SyncTimes(ms): 4752 
namenode                     | 21/08/31 00:31:14 INFO hdfs.StateChange: BLOCK* allocate blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369874744
namenode                     | 21/08/31 00:31:14 INFO hdfs.StateChange: BLOCK* fsync: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369874744 for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:31:14 INFO hdfs.StateChange: BLOCK* allocate blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e/.tmp/564a9fa8c9574d4ebacea3ad48aab682
namenode                     | 21/08/31 00:31:14 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741836_1012{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 83
namenode                     | 21/08/31 00:31:14 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741842_1018{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 0
namenode                     | 21/08/31 00:31:14 INFO hdfs.StateChange: DIR* completeFile: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369312904 is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:31:14 INFO hdfs.StateChange: DIR* completeFile: /hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e/.tmp/564a9fa8c9574d4ebacea3ad48aab682 is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:31:15 INFO hdfs.StateChange: BLOCK* allocate blk_1073741843_1019{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} for /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369875049
namenode                     | 21/08/31 00:31:15 INFO hdfs.StateChange: BLOCK* fsync: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369875049 for DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:31:15 INFO BlockStateChange: BLOCK* addStoredBlock: blockMap updated: 172.18.0.7:50010 is added to blk_1073741841_1017{UCState=UNDER_CONSTRUCTION, truncateBlock=null, primaryNodeIndex=-1, replicas=[ReplicaUC[[DISK]DS-bac6fdce-f619-4cc5-a097-a54fb8eda7cf:NORMAL:172.18.0.7:50010|RBW]]} size 83
namenode                     | 21/08/31 00:31:15 INFO hdfs.StateChange: DIR* completeFile: /hbase/WALs/hbase-master,36661,1630369300709/hbase-master%2C36661%2C1630369300709.default.1630369874744 is closed by DFSClient_NONMAPREDUCE_1336819110_1
namenode                     | 21/08/31 00:32:44 INFO namenode.FSEditLog: Number of transactions: 175 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 8 Number of syncs: 123 SyncTimes(ms): 5181 
namenode                     | 21/08/31 00:32:44 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741830_1006 172.18.0.7:50010 
namenode                     | 21/08/31 00:32:44 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741829_1005 172.18.0.7:50010 
namenode                     | 21/08/31 00:32:45 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.7:50010 to delete [blk_1073741829_1005, blk_1073741830_1006]
namenode                     | 21/08/31 00:38:44 INFO namenode.FSEditLog: Number of transactions: 177 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 8 Number of syncs: 125 SyncTimes(ms): 5244 
namenode                     | 21/08/31 00:38:44 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741831_1007 172.18.0.7:50010 
namenode                     | 21/08/31 00:38:44 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741835_1011 172.18.0.7:50010 
namenode                     | 21/08/31 00:38:44 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741837_1013 172.18.0.7:50010 
namenode                     | 21/08/31 00:38:44 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741838_1014 172.18.0.7:50010 
namenode                     | 21/08/31 00:38:45 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.7:50010 to delete [blk_1073741831_1007, blk_1073741835_1011, blk_1073741837_1013, blk_1073741838_1014]
namenode                     | 21/08/31 00:41:44 INFO namenode.FSEditLog: Number of transactions: 181 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 8 Number of syncs: 129 SyncTimes(ms): 5348 
namenode                     | 21/08/31 00:41:44 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741836_1012 172.18.0.7:50010 
namenode                     | 21/08/31 00:41:44 INFO BlockStateChange: BLOCK* addToInvalidates: blk_1073741841_1017 172.18.0.7:50010 
namenode                     | 21/08/31 00:41:45 INFO BlockStateChange: BLOCK* BlockManager: ask 172.18.0.7:50010 to delete [blk_1073741841_1017, blk_1073741836_1012]
zookeeper                    | JMX enabled by default
zookeeper                    | Using config: /opt/zookeeper-3.4.6/bin/../conf/zoo.cfg
zookeeper                    | 2021-08-31 00:21:32,763 [myid:] - INFO  [main:QuorumPeerConfig@103] - Reading configuration from: /opt/zookeeper-3.4.6/bin/../conf/zoo.cfg
zookeeper                    | 2021-08-31 00:21:32,768 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
zookeeper                    | 2021-08-31 00:21:32,768 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 1
zookeeper                    | 2021-08-31 00:21:32,769 [myid:] - WARN  [main:QuorumPeerMain@113] - Either no config or no quorum defined in config, running  in standalone mode
zookeeper                    | 2021-08-31 00:21:32,769 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@138] - Purge task started.
zookeeper                    | 2021-08-31 00:21:32,782 [myid:] - INFO  [PurgeTask:DatadirCleanupManager$PurgeTask@144] - Purge task completed.
zookeeper                    | 2021-08-31 00:21:32,783 [myid:] - INFO  [main:QuorumPeerConfig@103] - Reading configuration from: /opt/zookeeper-3.4.6/bin/../conf/zoo.cfg
zookeeper                    | 2021-08-31 00:21:32,784 [myid:] - INFO  [main:ZooKeeperServerMain@95] - Starting server
zookeeper                    | 2021-08-31 00:21:32,792 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.6-1569965, built on 02/20/2014 09:09 GMT
zookeeper                    | 2021-08-31 00:21:32,792 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=zookeeper
zookeeper                    | 2021-08-31 00:21:32,792 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.7.0_65
zookeeper                    | 2021-08-31 00:21:32,792 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
zookeeper                    | 2021-08-31 00:21:32,792 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-7-openjdk-amd64/jre
zookeeper                    | 2021-08-31 00:21:32,792 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/opt/zookeeper-3.4.6/bin/../build/classes:/opt/zookeeper-3.4.6/bin/../build/lib/*.jar:/opt/zookeeper-3.4.6/bin/../lib/slf4j-log4j12-1.6.1.jar:/opt/zookeeper-3.4.6/bin/../lib/slf4j-api-1.6.1.jar:/opt/zookeeper-3.4.6/bin/../lib/netty-3.7.0.Final.jar:/opt/zookeeper-3.4.6/bin/../lib/log4j-1.2.16.jar:/opt/zookeeper-3.4.6/bin/../lib/jline-0.9.94.jar:/opt/zookeeper-3.4.6/bin/../zookeeper-3.4.6.jar:/opt/zookeeper-3.4.6/bin/../src/java/lib/*.jar:/opt/zookeeper-3.4.6/bin/../conf:
zookeeper                    | 2021-08-31 00:21:32,793 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
zookeeper                    | 2021-08-31 00:21:32,793 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
zookeeper                    | 2021-08-31 00:21:32,796 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
zookeeper                    | 2021-08-31 00:21:32,796 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
zookeeper                    | 2021-08-31 00:21:32,796 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
zookeeper                    | 2021-08-31 00:21:32,796 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=5.11.0-27-generic
zookeeper                    | 2021-08-31 00:21:32,797 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=root
zookeeper                    | 2021-08-31 00:21:32,797 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/root
zookeeper                    | 2021-08-31 00:21:32,797 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/opt/zookeeper-3.4.6
zookeeper                    | 2021-08-31 00:21:32,798 [myid:] - INFO  [main:ZooKeeperServer@755] - tickTime set to 2000
zookeeper                    | 2021-08-31 00:21:32,798 [myid:] - INFO  [main:ZooKeeperServer@764] - minSessionTimeout set to -1
zookeeper                    | 2021-08-31 00:21:32,798 [myid:] - INFO  [main:ZooKeeperServer@773] - maxSessionTimeout set to -1
zookeeper                    | 2021-08-31 00:21:32,814 [myid:] - INFO  [main:NIOServerCnxnFactory@94] - binding to port 0.0.0.0/0.0.0.0:2181
zookeeper                    | 2021-08-31 00:21:39,772 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.18.0.6:55690
zookeeper                    | 2021-08-31 00:21:39,776 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.18.0.6:55690
zookeeper                    | 2021-08-31 00:21:39,778 [myid:] - INFO  [SyncThread:0:FileTxnLog@199] - Creating new log file: log.1
zookeeper                    | 2021-08-31 00:21:39,909 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x17b9995221e0000 with negotiated timeout 10000 for client /172.18.0.6:55690
zookeeper                    | 2021-08-31 00:21:40,713 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.18.0.6:55692
zookeeper                    | 2021-08-31 00:21:40,713 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.18.0.6:55692
zookeeper                    | 2021-08-31 00:21:40,788 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x17b9995221e0001 with negotiated timeout 10000 for client /172.18.0.6:55692
zookeeper                    | 2021-08-31 00:21:40,886 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.18.0.6:55696
zookeeper                    | 2021-08-31 00:21:40,886 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.18.0.6:55696
zookeeper                    | 2021-08-31 00:21:40,886 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.18.0.6:55698
zookeeper                    | 2021-08-31 00:21:40,887 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.18.0.6:55698
zookeeper                    | 2021-08-31 00:21:40,935 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x17b9995221e0002 with negotiated timeout 10000 for client /172.18.0.6:55696
zookeeper                    | 2021-08-31 00:21:40,985 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x17b9995221e0003 with negotiated timeout 10000 for client /172.18.0.6:55698
zookeeper                    | 2021-08-31 00:21:43,113 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.18.0.6:55710
zookeeper                    | 2021-08-31 00:21:43,116 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.18.0.6:55710
zookeeper                    | 2021-08-31 00:21:43,144 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x17b9995221e0004 with negotiated timeout 10000 for client /172.18.0.6:55710
zookeeper                    | 2021-08-31 00:21:43,298 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0001 type:create cxid:0x7 zxid:0x14 txntype:-1 reqpath:n/a Error Path:/hbase/flush-table-proc Error:KeeperErrorCode = NoNode for /hbase/flush-table-proc
zookeeper                    | 2021-08-31 00:21:43,302 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0000 type:create cxid:0x2c zxid:0x15 txntype:-1 reqpath:n/a Error Path:/hbase/flush-table-proc Error:KeeperErrorCode = NoNode for /hbase/flush-table-proc
zookeeper                    | 2021-08-31 00:21:43,391 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0000 type:create cxid:0x2d zxid:0x17 txntype:-1 reqpath:n/a Error Path:/hbase/flush-table-proc Error:KeeperErrorCode = NodeExists for /hbase/flush-table-proc
zookeeper                    | 2021-08-31 00:21:43,490 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0000 type:create cxid:0x2e zxid:0x19 txntype:-1 reqpath:n/a Error Path:/hbase/flush-table-proc/acquired Error:KeeperErrorCode = NodeExists for /hbase/flush-table-proc/acquired
zookeeper                    | 2021-08-31 00:21:43,590 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0000 type:create cxid:0x30 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/hbase/flush-table-proc/reached Error:KeeperErrorCode = NodeExists for /hbase/flush-table-proc/reached
zookeeper                    | 2021-08-31 00:21:43,686 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0000 type:create cxid:0x32 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/hbase/flush-table-proc/abort Error:KeeperErrorCode = NodeExists for /hbase/flush-table-proc/abort
zookeeper                    | 2021-08-31 00:21:43,739 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0001 type:create cxid:0xe zxid:0x1e txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot Error:KeeperErrorCode = NoNode for /hbase/online-snapshot
zookeeper                    | 2021-08-31 00:21:43,940 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0000 type:create cxid:0x36 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/hbase/online-snapshot/acquired Error:KeeperErrorCode = NodeExists for /hbase/online-snapshot/acquired
zookeeper                    | 2021-08-31 00:21:44,160 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@197] - Accepted socket connection from /172.18.0.6:55716
zookeeper                    | 2021-08-31 00:21:44,160 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@868] - Client attempting to establish new session at /172.18.0.6:55716
zookeeper                    | 2021-08-31 00:21:44,202 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@617] - Established session 0x17b9995221e0005 with negotiated timeout 10000 for client /172.18.0.6:55716
zookeeper                    | 2021-08-31 00:21:44,204 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0005 type:create cxid:0x1 zxid:0x26 txntype:-1 reqpath:n/a Error Path:/hbase/replication Error:KeeperErrorCode = NoNode for /hbase/replication
zookeeper                    | 2021-08-31 00:21:49,712 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0000 type:delete cxid:0x4a zxid:0x2b txntype:-1 reqpath:n/a Error Path:/hbase/meta-region-server Error:KeeperErrorCode = NoNode for /hbase/meta-region-server
zookeeper                    | 2021-08-31 00:21:50,322 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0001 type:setData cxid:0x2f zxid:0x30 txntype:-1 reqpath:n/a Error Path:/hbase/meta-region-server Error:KeeperErrorCode = NoNode for /hbase/meta-region-server
zookeeper                    | 2021-08-31 00:21:51,049 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0000 type:create cxid:0x5b3 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/hbase/table-lock/hbase:namespace Error:KeeperErrorCode = NoNode for /hbase/table-lock/hbase:namespace
zookeeper                    | 2021-08-31 00:21:53,474 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0000 type:create cxid:0x5d7 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/hbase/namespace/default Error:KeeperErrorCode = NodeExists for /hbase/namespace/default
zookeeper                    | 2021-08-31 00:21:53,561 [myid:] - INFO  [ProcessThread(sid:0 cport:-1)::PrepRequestProcessor@645] - Got user-level KeeperException when processing sessionid:0x17b9995221e0000 type:create cxid:0x5da zxid:0x46 txntype:-1 reqpath:n/a Error Path:/hbase/namespace/hbase Error:KeeperErrorCode = NodeExists for /hbase/namespace/hbase
spark                        | /opt/docker/conf/hadoop/capacity-scheduler.xml => /etc/hadoop/capacity-scheduler.xml
spark                        | /opt/docker/conf/hadoop/core-site.xml => /etc/hadoop/core-site.xml
spark                        | /opt/docker/conf/hadoop/hadoop-env.sh => /etc/hadoop/hadoop-env.sh
spark                        | /opt/docker/conf/hadoop/hdfs-site.xml => /etc/hadoop/hdfs-site.xml
spark                        | /opt/docker/conf/hadoop/mapred-site.xml => /etc/hadoop/mapred-site.xml
spark                        | /opt/docker/conf/hadoop/yarn-site.xml => /etc/hadoop/yarn-site.xml
spark                        | /opt/docker/conf/spark/spark-defaults.conf => /etc/spark/spark-defaults.conf
spark                        | /opt/docker/conf/jupyter-kernels/PySpark/kernel.json => /opt/anaconda3/share/jupyter/kernels/PySpark/kernel.json
spark                        | [W 00:21:33.741 NotebookApp] All authentication is disabled.  Anyone who can connect to this server will be able to run code.
spark                        | [I 00:21:33.776 NotebookApp] JupyterLab beta preview extension loaded from /opt/anaconda3/lib/python3.6/site-packages/jupyterlab
spark                        | [I 00:21:33.776 NotebookApp] JupyterLab application directory is /opt/anaconda3/share/jupyter/lab
spark                        | [I 00:21:33.781 NotebookApp] Serving notebooks from local directory: /mnt/notebooks
spark                        | [I 00:21:33.782 NotebookApp] 0 active kernels
spark                        | [I 00:21:33.782 NotebookApp] The Jupyter Notebook is running at:
spark                        | [I 00:21:33.782 NotebookApp] http://spark:8889/
spark                        | [I 00:21:33.782 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
(base) heron@acerubuntu:~/docker-bigdata$ 



-- verificar os logs do container namenode 

$ docker logs namenode # feito 

-- acessar o container namenode 

docker exec -it namenode bash

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash
root@namenode:/# 
root@namenode:/# 
root@namenode:/# quit
bash: quit: command not found
root@namenode:/# exit
exit
(base) heron@acerubuntu:~/docker-bigdata$ 





-- listar os diretorios do container namenode 

docker exec -it namenode ls -ltr

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash
root@namenode:/# ls -ltr
total 152
drwxr-xr-x   2 root root  4096 Nov 19  2017 home
drwxr-xr-x   2 root root  4096 Nov 19  2017 boot
drwxr-xr-x   2 root root  4096 Dec 10  2017 srv
drwxr-xr-x   3 root root  4096 Dec 10  2017 run
drwxr-xr-x   2 root root  4096 Dec 10  2017 mnt
drwxr-xr-x   2 root root  4096 Dec 10  2017 media
drwxr-xr-x   2 root root  4096 Dec 10  2017 lib64
-rwxr-xr-x   1 root root  4145 Feb  5  2018 entrypoint.sh
drwxr-xr-x   1 root root  4096 Feb  5  2018 lib
drwxr-xr-x   1 root root  4096 Feb  5  2018 var
drwxr-xr-x   1 root root  4096 Feb  5  2018 usr
drwxr-xr-x   1 root root  4096 Feb  5  2018 sbin
drwxr-xr-x   1 root root  4096 Feb  5  2018 bin
drwxr-xr-x   1 root root  4096 Feb  5  2018 opt
drwxr-xr-x   2 root root  4096 Feb  5  2018 hadoop-data
-rwxr-xr-x   1 root root   499 Oct  5  2018 run.sh
drwxr-xr-x   3 root root  4096 Oct  5  2018 hadoop
-rw-r--r--   1 root root 20895 Mar 19  2020 employees.java
drwx------   1 root root  4096 Mar 19  2020 root
-rw-r--r--   1 root root 24060 Mar 19  2020 derby.log
drwxr-xr-x   5 root root  4096 Mar 19  2020 metastore_db
drwxr-xr-x   1 root root  4096 Aug 31 00:21 etc
drwxr-xr-x   2 root root  4096 Aug 31 00:21 input
dr-xr-xr-x  13 root root     0 Aug 31 00:21 sys
dr-xr-xr-x 539 root root     0 Aug 31 00:21 proc
drwxr-xr-x   5 root root   340 Aug 31 00:21 dev
drwxrwxrwt   1 root root  4096 Aug 31 00:21 tmp
root@namenode:/# exit





-- parar os containers do cluster de big data 

$ docker-compose stop

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose stop
Stopping hive-server               ... done
Stopping hive_metastore            ... done
Stopping hive-metastore-postgresql ... done
Stopping datanode                  ... done
Stopping hbase-master              ... done
Stopping namenode                  ... done
Stopping zookeeper                 ... done
Stopping spark                     ... done
Stopping database                  ... done
(base) heron@acerubuntu:~/docker-bigdata$ 



--------------------------------------------------------------------------
-------------- AULA 03 - HDFS 
--------------------------------------------------------------------------

PARA EXECUTAR OS COMANDOS HDFS , É NECESSARIO ESTAR COM O SEU CLUSTER ATIVO ( CONTAINERS ATIVOS)

PARA EXECUTAR COMANDOS docker-compose é necessario estar com o terminal na pasta especifica

VERIFIQUE SE EXISTEM CONTAINERS ATIVOS 


(base) heron@acerubuntu:~/docker-bigdata$ pwd
/home/heron/docker-bigdata

(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ 


para verificar todos os containers , status, utilize o comando abaixo 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   21 hours ago   Exited (137) 21 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   21 hours ago   Exited (143) 21 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   21 hours ago   Exited (0) 21 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   21 hours ago   Exited (137) 21 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   21 hours ago   Exited (137) 21 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   21 hours ago   Exited (0) 21 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ 

podemos verificar que todos os containers ( serviços ) estao em Exited.

nao existe containers ativos, com isso devemos ativar o cluster 

-- ativar o cluster bigdata utilizand o comando abaixo , utilizando o parametro -d para realizar em background a incializacao
   do contrario, vai ficar aparecendo um log enorme até o cluster estar ativo.

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d
Starting zookeeper ... done
Starting namenode  ... done
Starting database     ... done
Starting spark        ... done
Starting datanode     ... done
Starting hbase-master ... done
Starting hive-metastore-postgresql ... done
Starting hive_metastore            ... done
Starting hive-server               ... done
(base) heron@acerubuntu:~/docker-bigdata$ 


#####################################################################################################################
################################ EXERCICIO AULA 03 0 HDFS ###########################################################
#####################################################################################################################

   -- pastas 
   /usr/local/bin
   /docker-bigdata 

   (base) heron@acerubuntu:~$ ls -ltr
total 68
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Videos
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Templates
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Public
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Music
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Documents
drwxrwxr-x  3 heron heron 4096 fev 14  2021 opt
drwxrwxr-x  2 heron heron 4096 fev 14  2021 bin
-rw-rw-r--  1 heron heron   26 fev 15  2021 meu_arquivo.txt
-rw-rw-r--  1 heron heron    0 fev 19  2021 ameu_arquivo.txt
-rw-rw-r--  1 heron heron   76 fev 21  2021 vim_basico.txt
drwxrwxr-x 28 heron heron 4096 jun  1 14:03 anaconda3
drwxrwxr-x  3 heron heron 4096 jun  2 11:54 PycharmProjects
drwxr-xr-x  2 heron heron 4096 jun  2 12:29 Downloads
drwxr-xr-x  8 heron heron 4096 jun  5 13:12 snap
drwxrwxr-x  4 heron heron 4096 ago 29 09:58 DataEngineer
drwxr-xr-x  2 heron heron 4096 ago 29 11:01 Pictures
drwxrwxr-x  5 heron heron 4096 ago 30 21:21 docker-bigdata
drwxr-xr-x  3 heron heron 4096 ago 31 20:19 Desktop
(base) heron@acerubuntu:~$ cd docker-bigdata




(base) heron@acerubuntu:~/docker-bigdata$ ls -ltr
total 376
-rwxrwxr-x  1 heron heron   3443 ago 30 20:31 README.md
-rw-rw-r--  1 heron heron 343678 ago 30 20:31 ecosystem.jpeg
-rwxrwxr-x  1 heron heron   3778 ago 30 20:31 docker-compose.yml
-rw-rw-r--  1 heron heron   5172 ago 30 20:31 docker-compose-parcial.yml
-rw-rw-r--  1 heron heron   6381 ago 30 20:31 docker-compose-completo.yml
-rw-rw-r--  1 heron heron   6755 ago 30 20:31 docker-compose-completo-windows.yml
drwxr-xr-x  2 root  root    4096 ago 30 21:21 input
drwxrwxr-x 15 heron heron   4096 ago 30 21:21 data
(base) heron@acerubuntu:~/docker-bigdata$ 


-- VAMS COLOCAR DADOS NA PASTA INPUT 

-- REALIZAMOS UMA MUDANÇA PARA O DIRETORIO INPUT , COM O COMANDO ABAIXO 

(base) heron@acerubuntu:~/docker-bigdata$ cd input/
(base) heron@acerubuntu:~/docker-bigdata/input$ 



2 -- COMO O CLUSTER ESTA EM EXECUÇÃO NAO TEMOS ACESSO A PASTA INPUT, temos que realizar utilizando 
   o comando sudo para realizar o dowload 

sudo git clone https://github.com/rodrigo-reboucas/exercises-data.git


(base) heron@acerubuntu:~/docker-bigdata$ cd input/
(base) heron@acerubuntu:~/docker-bigdata/input$ pwd
/home/heron/docker-bigdata/input
(base) heron@acerubuntu:~/docker-bigdata/input$ sudo git clone https://github.com/rodrigo-reboucas/exercises-data.git
[sudo] password for heron: 
Cloning into 'exercises-data'...
remote: Enumerating objects: 311, done.
remote: Total 311 (delta 0), reused 0 (delta 0), pack-reused 311
Receiving objects: 100% (311/311), 88.96 MiB | 15.45 MiB/s, done.
Resolving deltas: 100% (17/17), done.
Updating files: 100% (283/283), done.
(base) heron@acerubuntu:~/docker-bigdata/input$ 


(base) heron@acerubuntu:~/docker-bigdata/input$ ls
exercises-data
(base) heron@acerubuntu:~/docker-bigdata/input$ 


(base) heron@acerubuntu:~/docker-bigdata/input$ ls
exercises-data

(base) heron@acerubuntu:~/docker-bigdata/input$ ls exercises-data/
beneficio  db-sql  economicFitness  empreendimento  entrada1.txt  entrada2.txt  escola  hnpStats  iris  juros_selic  map.py  names  namesbystate  ouvidoria  populacaoLA  README.md  reduce.py  WordCount.java
(base) heron@acerubuntu:~/docker-bigdata/input$ 


3 - acessar o container namenode 
docker exec -it namenode bash

(base) heron@acerubuntu:~/docker-bigdata/input$ docker exec -it namenode bash
root@namenode:/# 


para sair , digitar exit 


4- Criar a estrutura de pastas apresentada ao lado pelo comando : $ hdfs dfs -ls -R /

-- lista todos os diretorios dentro do namenode 

root@namenode:/# hdfs dfs -ls -R /

    1;user/aluno
      i. <nome>
         1. data
         2. recover
         3. delete


root@namenode:/# hdfs dfs -ls -R /
drwxr-xr-x   - root supergroup          0 2021-08-31 23:41 /hbase
drwxr-xr-x   - root supergroup          0 2021-08-31 23:34 /hbase/.tmp
drwxr-xr-x   - root supergroup          0 2021-08-31 23:34 /hbase/MasterProcWALs
-rw-r--r--   3 root supergroup          0 2021-08-31 23:34 /hbase/MasterProcWALs/state-00000000000000000007.log
drwxr-xr-x   - root supergroup          0 2021-08-31 23:34 /hbase/WALs
drwxr-xr-x   - root supergroup          0 2021-08-31 23:41 /hbase/WALs/hbase-master,45779,1630452819601
-rw-r--r--   3 root supergroup         83 2021-08-31 23:41 /hbase/WALs/hbase-master,45779,1630452819601/hbase-master%2C45779%2C1630452819601..meta.1630453314788.meta
-rw-r--r--   3 root supergroup         83 2021-08-31 23:34 /hbase/WALs/hbase-master,45779,1630452819601/hbase-master%2C45779%2C1630452819601.default.1630452868488
drwxr-xr-x   - root supergroup          0 2021-08-31 23:47 /hbase/archive
drwxr-xr-x   - root supergroup          0 2021-08-31 21:47 /hbase/corrupt
drwxr-xr-x   - root supergroup          0 2021-08-31 00:21 /hbase/data
drwxr-xr-x   - root supergroup          0 2021-08-31 00:21 /hbase/data/default
drwxr-xr-x   - root supergroup          0 2021-08-31 00:21 /hbase/data/hbase
drwxr-xr-x   - root supergroup          0 2021-08-31 00:21 /hbase/data/hbase/meta
drwxr-xr-x   - root supergroup          0 2021-08-31 00:21 /hbase/data/hbase/meta/.tabledesc
-rw-r--r--   3 root supergroup        398 2021-08-31 00:21 /hbase/data/hbase/meta/.tabledesc/.tableinfo.0000000001
drwxr-xr-x   - root supergroup          0 2021-08-31 00:21 /hbase/data/hbase/meta/.tmp
drwxr-xr-x   - root supergroup          0 2021-08-31 23:41 /hbase/data/hbase/meta/1588230740
-rw-r--r--   3 root supergroup         32 2021-08-31 00:21 /hbase/data/hbase/meta/1588230740/.regioninfo
drwxr-xr-x   - root supergroup          0 2021-08-31 23:41 /hbase/data/hbase/meta/1588230740/.tmp
drwxr-xr-x   - root supergroup          0 2021-08-31 23:41 /hbase/data/hbase/meta/1588230740/info
-rw-r--r--   3 root supergroup       6355 2021-08-31 23:41 /hbase/data/hbase/meta/1588230740/info/970635aabd9744fbbaff6cdb74a77a54
drwxr-xr-x   - root supergroup          0 2021-08-31 23:34 /hbase/data/hbase/meta/1588230740/recovered.edits
-rw-r--r--   3 root supergroup          0 2021-08-31 23:34 /hbase/data/hbase/meta/1588230740/recovered.edits/14.seqid
drwxr-xr-x   - root supergroup          0 2021-08-31 00:21 /hbase/data/hbase/namespace
drwxr-xr-x   - root supergroup          0 2021-08-31 00:21 /hbase/data/hbase/namespace/.tabledesc
-rw-r--r--   3 root supergroup        312 2021-08-31 00:21 /hbase/data/hbase/namespace/.tabledesc/.tableinfo.0000000001
drwxr-xr-x   - root supergroup          0 2021-08-31 00:21 /hbase/data/hbase/namespace/.tmp
drwxr-xr-x   - root supergroup          0 2021-08-31 21:47 /hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e
-rw-r--r--   3 root supergroup         42 2021-08-31 00:21 /hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e/.regioninfo
drwxr-xr-x   - root supergroup          0 2021-08-31 00:31 /hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e/info
-rw-r--r--   3 root supergroup       4963 2021-08-31 00:31 /hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e/info/564a9fa8c9574d4ebacea3ad48aab682
drwxr-xr-x   - root supergroup          0 2021-08-31 23:34 /hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e/recovered.edits
-rw-r--r--   3 root supergroup          0 2021-08-31 23:34 /hbase/data/hbase/namespace/5c94956e44945c16a05039143901db1e/recovered.edits/9.seqid
-rw-r--r--   3 root supergroup         42 2021-08-31 00:21 /hbase/hbase.id
-rw-r--r--   3 root supergroup          7 2021-08-31 00:21 /hbase/hbase.version
drwxr-xr-x   - root supergroup          0 2021-08-31 23:45 /hbase/oldWALs
-rw-r--r--   3 root supergroup        617 2021-08-31 23:41 /hbase/oldWALs/hbase-master%2C45779%2C1630452819601..meta.1630452862598.meta
-rw-r--r--   3 root supergroup        231 2021-08-31 23:41 /hbase/oldWALs/hbase-master%2C45779%2C1630452819601..meta.1630452868576.meta
-rw-r--r--   3 root supergroup        265 2021-08-31 23:41 /hbase/oldWALs/hbase-master%2C45779%2C1630452819601..meta.1630453313930.meta
-rw-r--r--   3 root supergroup        366 2021-08-31 23:41 /hbase/oldWALs/hbase-master%2C45779%2C1630452819601..meta.1630453314238.meta
drwxrwxr-x   - root supergroup          0 2021-08-31 00:22 /tmp
drwx-wx-wx   - root supergroup          0 2021-08-31 00:22 /tmp/hive
drwx------   - root supergroup          0 2021-08-31 23:34 /tmp/hive/root
drwx------   - root supergroup          0 2021-08-31 00:22 /tmp/hive/root/18ed93ca-d042-4d3c-96bb-2fb284756bd1
drwx------   - root supergroup          0 2021-08-31 00:22 /tmp/hive/root/18ed93ca-d042-4d3c-96bb-2fb284756bd1/_tmp_space.db
drwx------   - root supergroup          0 2021-08-31 23:34 /tmp/hive/root/54d7e386-c41e-4ac0-97bd-f1840eb40ff9
drwx------   - root supergroup          0 2021-08-31 23:34 /tmp/hive/root/54d7e386-c41e-4ac0-97bd-f1840eb40ff9/_tmp_space.db
drwx------   - root supergroup          0 2021-08-31 21:47 /tmp/hive/root/9cb2665c-fb92-40a9-9dab-a5b6ebad2a18
drwx------   - root supergroup          0 2021-08-31 21:47 /tmp/hive/root/9cb2665c-fb92-40a9-9dab-a5b6ebad2a18/_tmp_space.db
drwxr-xr-x   - root supergroup          0 2021-08-31 00:22 /user
drwxr-xr-x   - root supergroup          0 2021-08-31 00:22 /user/hive
drwxrwxr-x   - root supergroup          0 2021-08-31 00:22 /user/hive/warehouse
root@namenode:/# 


root@namenode:/# hdfs dfs -ls -R /user
drwxr-xr-x   - root supergroup          0 2021-08-31 00:22 /user/hive
drwxrwxr-x   - root supergroup          0 2021-08-31 00:22 /user/hive/warehouse
root@namenode:/# 

--COMANDO PARA UTILIZAR HELP NO HDFS 

hdfs dfs -help 
hdfs dfs - help ls 

root@namenode:/# hdfs dfs -help cat
-cat [-ignoreCrc] <src> ... :
  Fetch all files that match the file pattern <src> and display their content on
  stdout.
root@namenode:/# hdfs dfs -help cp 
-cp [-f] [-p | -p[topax]] <src> ... <dst> :
  Copy files that match the file pattern <src> to a destination.  When copying
  multiple files, the destination must be a directory. Passing -p preserves status
  [topax] (timestamps, ownership, permission, ACLs, XAttr). If -p is specified
  with no <arg>, then preserves timestamps, ownership, permission. If -pa is
  specified, then preserves permission also because ACL is a super-set of
  permission. Passing -f overwrites the destination if it already exists. raw
  namespace extended attributes are preserved if (1) they are supported (HDFS
  only) and, (2) all of the source and target pathnames are in the /.reserved/raw
  hierarchy. raw namespace xattr preservation is determined solely by the presence
  (or absence) of the /.reserved/raw prefix and not by the -p option.
root@namenode:/# 


root@namenode:/# hdfs dfs -mkdir -p /user/aluno/heron/data
root@namenode:/# hdfs dfs -ls -R /user
drwxr-xr-x   - root supergroup          0 2021-09-01 00:08 /user/aluno
drwxr-xr-x   - root supergroup          0 2021-09-01 00:08 /user/aluno/heron
drwxr-xr-x   - root supergroup          0 2021-09-01 00:08 /user/aluno/heron/data
drwxr-xr-x   - root supergroup          0 2021-08-31 00:22 /user/hive
drwxrwxr-x   - root supergroup          0 2021-08-31 00:22 /user/hive/warehouse
root@namenode:/# 

root@namenode:/# hdfs dfs -mkdir /user/aluno/heron/recover
root@namenode:/# hdfs dfs -mkdir /user/aluno/heron/delete 
root@namenode:/# hdfs dfs -ls -R /user
drwxr-xr-x   - root supergroup          0 2021-09-01 00:08 /user/aluno
drwxr-xr-x   - root supergroup          0 2021-09-01 00:10 /user/aluno/heron
drwxr-xr-x   - root supergroup          0 2021-09-01 00:08 /user/aluno/heron/data
drwxr-xr-x   - root supergroup          0 2021-09-01 00:10 /user/aluno/heron/delete
drwxr-xr-x   - root supergroup          0 2021-09-01 00:09 /user/aluno/heron/recover
drwxr-xr-x   - root supergroup          0 2021-08-31 00:22 /user/hive
drwxrwxr-x   - root supergroup          0 2021-08-31 00:22 /user/hive/warehouse
root@namenode:/# 


5. Enviar a pasta “/input/exercises-data/escola” e o arquivo “/input/exercises-data/entrada1.txt” para data

root@namenode:/# ls -ltr
total 152
drwxr-xr-x   2 root root  4096 Nov 19  2017 home
drwxr-xr-x   2 root root  4096 Nov 19  2017 boot
drwxr-xr-x   2 root root  4096 Dec 10  2017 srv
drwxr-xr-x   3 root root  4096 Dec 10  2017 run
drwxr-xr-x   2 root root  4096 Dec 10  2017 mnt
drwxr-xr-x   2 root root  4096 Dec 10  2017 media
drwxr-xr-x   2 root root  4096 Dec 10  2017 lib64
-rwxr-xr-x   1 root root  4145 Feb  5  2018 entrypoint.sh
drwxr-xr-x   1 root root  4096 Feb  5  2018 lib
drwxr-xr-x   1 root root  4096 Feb  5  2018 var
drwxr-xr-x   1 root root  4096 Feb  5  2018 usr
drwxr-xr-x   1 root root  4096 Feb  5  2018 sbin
drwxr-xr-x   1 root root  4096 Feb  5  2018 bin
drwxr-xr-x   1 root root  4096 Feb  5  2018 opt
drwxr-xr-x   2 root root  4096 Feb  5  2018 hadoop-data
-rwxr-xr-x   1 root root   499 Oct  5  2018 run.sh
drwxr-xr-x   3 root root  4096 Oct  5  2018 hadoop
-rw-r--r--   1 root root 20895 Mar 19  2020 employees.java
drwx------   1 root root  4096 Mar 19  2020 root
-rw-r--r--   1 root root 24060 Mar 19  2020 derby.log
drwxr-xr-x   5 root root  4096 Mar 19  2020 metastore_db
drwxr-xr-x   1 root root  4096 Aug 31 00:21 etc
dr-xr-xr-x  13 root root     0 Aug 31 23:33 sys
dr-xr-xr-x 492 root root     0 Aug 31 23:33 proc
drwxr-xr-x   5 root root   340 Aug 31 23:33 dev
drwxrwxrwt   1 root root  4096 Aug 31 23:33 tmp

drwxr-xr-x   3 root root  4096 Aug 31 23:38 input

root@namenode:/# 

root@namenode:/# ls /input/
exercises-data
root@namenode:/# 

root@namenode:/# hdfs dfs -put /input/exercises-data/escola/ /user/aluno/heron/data
root@namenode:/# hdfs dfs -ls -R /user/aluno/heron/data
drwxr-xr-x   - root supergroup          0 2021-09-01 00:22 /user/aluno/heron/data/escola
-rw-r--r--   3 root supergroup        147 2021-09-01 00:22 /user/aluno/heron/data/escola/README.md
-rw-r--r--   3 root supergroup     546284 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.csv
-rw-r--r--   3 root supergroup    4891872 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.json
-rw-r--r--   3 root supergroup      98437 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.png
-rw-r--r--   3 root supergroup    6044140 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.xml
-rw-r--r--   3 root supergroup       4667 2021-09-01 00:22 /user/aluno/heron/data/escola/bens-imoveis.json
-rw-r--r--   3 root supergroup      78599 2021-09-01 00:22 /user/aluno/heron/data/escola/bens-imoveis.png
-rw-r--r--   3 root supergroup       5630 2021-09-01 00:22 /user/aluno/heron/data/escola/bens-imoveis.xml
-rw-r--r--   3 root supergroup       1998 2021-09-01 00:22 /user/aluno/heron/data/escola/bens_imovel.csv
-rw-r--r--   3 root supergroup     731195 2021-09-01 00:22 /user/aluno/heron/data/escola/componentes-curriculares.csv
-rw-r--r--   3 root supergroup    9787990 2021-09-01 00:22 /user/aluno/heron/data/escola/componentes-curriculares.json
-rw-r--r--   3 root supergroup     109655 2021-09-01 00:22 /user/aluno/heron/data/escola/componentes-curriculares.png
-rw-r--r--   3 root supergroup      18308 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.csv
-rw-r--r--   3 root supergroup     253692 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.json
-rw-r--r--   3 root supergroup      97271 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.png
-rw-r--r--   3 root supergroup     295196 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.xml
-rw-r--r--   3 root supergroup      12129 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.csv
-rw-r--r--   3 root supergroup     279549 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.json
-rw-r--r--   3 root supergroup      96691 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.png
-rw-r--r--   3 root supergroup     336640 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.xml
-rw-r--r--   3 root supergroup      18694 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.csv
-rw-r--r--   3 root supergroup      33426 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.json
-rw-r--r--   3 root supergroup     169764 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.png
-rw-r--r--   3 root supergroup      41473 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.xml
-rw-r--r--   3 root supergroup     105897 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.csv
-rw-r--r--   3 root supergroup    2597473 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.json
-rw-r--r--   3 root supergroup      89028 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.png
-rw-r--r--   3 root supergroup    3069250 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.xml
-rw-r--r--   3 root supergroup     314729 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades-organizacionais.json
-rw-r--r--   3 root supergroup     102433 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades-organizacionais.png
-rw-r--r--   3 root supergroup     382416 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades-organizacionais.xml
-rw-r--r--   3 root supergroup      40235 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades.csv
root@namenode:/# 


root@namenode:/# 
root@namenode:/# hdfs dfs -put /input/exercises-data/entrada1.txt /user/aluno/heron/data
root@namenode:/# 

root@namenode:/# hdfs dfs -put /input/exercises-data/entrada1.txt /user/aluno/heron/data
root@namenode:/# hdfs dfs -ls /user/aluno/heron/data
Found 2 items
-rw-r--r--   3 root supergroup         54 2021-09-01 00:25 /user/aluno/heron/data/entrada1.txt
drwxr-xr-x   - root supergroup          0 2021-09-01 00:22 /user/aluno/heron/data/escola
root@namenode:/# 



6. Mover o arquivo “entrada1.txt” para recover


root@namenode:/# hdfs dfs -mv /user/aluno/heron/data/entrada1.txt /user/aluno/heron/recover
root@namenode:/# 

--verificacao se foi 

root@namenode:/# hdfs dfs -ls /user/aluno/heron/recover
Found 1 items
-rw-r--r--   3 root supergroup         54 2021-09-01 00:25 /user/aluno/heron/recover/entrada1.txt
root@namenode:/# 

root@namenode:/# hdfs dfs -ls /user/aluno/heron/data   
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-09-01 00:22 /user/aluno/heron/data/escola
root@namenode:/# 




7. Baixar o arquivo do hdfs “escola/alunos.json” para o sistema local /




root@namenode:/# hdfs dfs -get /user/aluno/heron/data/escola/alunos.json /

isto joga o arquivo no path local do namenode




8. Deletar a pasta recover


root@namenode:/# hdfs dfs -rm /user/aluno/heron/recover
rm: `/user/aluno/heron/recover': Is a directory
root@namenode:/# hdfs dfs -rm -R /user/aluno/heron/recover
21/09/01 00:36:30 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.
Deleted /user/aluno/heron/recover
root@namenode:/# 


* importante configurar um time da lixeira pois o cluster pode estar configurado com a lixeira para 0 minutes.


9. Deletar permanentemente o delete


hdfs dfs -rm -skipTrash -R /user/aluno/heron/delete

root@namenode:/# hdfs dfs -rm -skipTrash -R /user/aluno/heron/delete
Deleted /user/aluno/heron/delete
root@namenode:/# 




10. Procurar o arquivo “alunos.csv” dentro do /user


root@namenode:/# hdfs dfs -find /user -name alunos.csv              
/user/aluno/heron/data/escola/alunos.csv
root@namenode:/# 


* comando lento 



11. Mostrar o último 1KB do arquivo “alunos.csv”


root@namenode:/# hdfs dfs -tail /user/aluno/heron/data/escola/alunos.csv
NHO KANAREK",2018,0,N,2081113,2399342
26660,"PIETRA DE SOUZA MATANA",2019,0,N,2081113,2399351
11693,"PIETRA MARINÉE ZAMIN",2016,1,G,62151,62474
573,"PIETRA PERES SCHLUMPF",2015,,M,2081113,3402
23268,"PIETRA SOUTO LEMBERCK",2018,0,N,2081113,2399362
17350,"PIETRO ANTUNES MACHADO",2017,,M,37350,511414
27185,"PIETRO BORGES TIECHER",2019,0,N,2081113,2399346
486,"PIETRO CORADINI FOLETTO",2015,,M,2081113,3402
26272,"PIETRO EGLON DOLMAZE DE MEDEIROS",2019,0,N,2081113,2399335
24473,"PIETRO HENRIQUE SILVA DOS SANTOS",2018,0,N,2081113,2399355
4364,"PLINIO BITENCURT FINAMOR",2014,1,T,37350,39
2084,"POLIANA GRAUPE DE ALMEIDA",2012,0,M,37350,1117
21855,"POLIANA WAHLBRINCK VOLZ",2018,0,N,2081113,2399327
1528,"POLYANA FOLETTO PRAUCHNER",2014,0,M,37350,1212
21162,"POLYANA FOLETTO PRAUCHNER",2018,1,G,5997,712452
21672,"POLYANA FUCILINI",2018,0,N,2081113,2399116
20089,"PRAXEDES RODRIGUES DE RODRIGUES",2017,,M,37350,3763
27509,"PRECILA FRANCESCKI TURRA",2019,1,T,2081111,34236
1345,"PREDON DE SOUZA DA SILVA",2015,,M,37350,11442
root@namenode:/# 




12. Mostrar as 2 primeiras linhas do arquivo “alunos.csv”

root@namenode:/# hdfs dfs -cat /user/aluno/heron/data/escola/alunos.csv | head -n 2
id_discente,nome,ano_ingresso,periodo_ingresso,nivel,id_forma_ingresso,id_curso
18957,"ABELARDO DA SILVA COELHO",2017,1,G,62151,76995
cat: Unable to write to output stream.
root@namenode:/# 





13. Verificação de soma das informações do arquivo “alunos.csv”
checksum, gera um codigo  MD5-of-0MD5-of-512CRC32C


root@namenode:/# hdfs dfs -checksum /user/aluno/heron/data/escola/alunos.csv            
/user/aluno/heron/data/escola/alunos.csv  MD5-of-0MD5-of-512CRC32C   000002000000000000000000164b9235a4d65a1e8ebfe12eb97ac471
root@namenode:/# 





14. Criar um arquivo em branco com o nome de “test” no data


root@namenode:/# hdfs dfs -touchz /user/aluno/heron/data/test               
root@namenode:/# hdfs dfs -ls /user/aluno/heron/data/    
Found 2 items
drwxr-xr-x   - root supergroup          0 2021-09-01 00:22 /user/aluno/heron/data/escola
-rw-r--r--   3 root supergroup          0 2021-09-01 01:03 /user/aluno/heron/data/test
root@namenode:/# 



15. Alterar o fator de replicação do arquivo “test” para 2

replicacao para 2 


root@namenode:/# hdfs dfs -setrep 2 /user/aluno/heron/data/test
Replication 2 set: /user/aluno/heron/data/test
root@namenode:/# 


voce consegue ver as replicacoes no ls 

root@namenode:/# hdfs dfs -ls /user/aluno/heron/data/
Found 2 items
drwxr-xr-x   - root supergroup          0 2021-09-01 00:22 /user/aluno/heron/data/escola
-rw-r--r--   2 root supergroup          0 2021-09-01 01:03 /user/aluno/heron/data/test
root@namenode:/# 



16. Ver as informações do arquivo “alunos.csv"


root@namenode:/# hdfs dfs -stat %o /user/aluno/heron/data/escola/alunos.csv
134217728
root@namenode:/# 



17. Exibir o espaço livre do data e o uso do disco

root@namenode:/# hdfs dfs -df /user/aluno/heron/data/                 
Filesystem                    Size      Used     Available  Use%
hdfs://namenode:8020  983429038080  31187046  892167082150    0%
root@namenode:/# 

root@namenode:/# hdfs dfs -df -h /user/aluno/heron/data/
Filesystem               Size    Used  Available  Use%
hdfs://namenode:8020  915.9 G  29.7 M    830.9 G    0%
root@namenode:/# 


root@namenode:/# hdfs dfs -du -h /user/aluno/heron/data/
29.2 M  /user/aluno/heron/data/escola
0       /user/aluno/heron/data/test
root@namenode:/# hdfs dfs -du -h /                      
12.1 K  /hbase
0       /tmp
29.2 M  /user
root@namenode:/# 


#########################################################################################################
#############################   EXERCICO AULA 04 - HIVE      ############################################
#########################################################################################################


(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ 


para verificar todos os containers , status, utilize o comando abaixo 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   21 hours ago   Exited (137) 21 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   21 hours ago   Exited (143) 21 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   21 hours ago   Exited (0) 21 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   21 hours ago   Exited (137) 21 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   21 hours ago   Exited (137) 21 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   21 hours ago   Exited (0) 21 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ 

podemos verificar que todos os containers ( serviços ) estao em Exited.

nao existe containers ativos, com isso devemos ativar o cluster 

-- ativar o cluster bigdata utilizand o comando abaixo , utilizando o parametro -d para realizar em background a incializacao
   do contrario, vai ficar aparecendo um log enorme até o cluster estar ativo.

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d





1. Enviar o arquivo local “/input/exercises-data/populacaoLA/populacaoLA.csv” para o diretório no HDFS
“/user/aluno/<nome>/data/populacao”

   # vamos acessar o namenode 

   docker exec -it namenode bash

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash
root@namenode:/#

root@namenode:/# ls -ltr
total 152
drwxr-xr-x   2 root root  4096 Nov 19  2017 home
drwxr-xr-x   2 root root  4096 Nov 19  2017 boot
drwxr-xr-x   2 root root  4096 Dec 10  2017 srv
drwxr-xr-x   3 root root  4096 Dec 10  2017 run
drwxr-xr-x   2 root root  4096 Dec 10  2017 mnt
drwxr-xr-x   2 root root  4096 Dec 10  2017 media
drwxr-xr-x   2 root root  4096 Dec 10  2017 lib64
-rwxr-xr-x   1 root root  4145 Feb  5  2018 entrypoint.sh
drwxr-xr-x   1 root root  4096 Feb  5  2018 lib
drwxr-xr-x   1 root root  4096 Feb  5  2018 var
drwxr-xr-x   1 root root  4096 Feb  5  2018 usr
drwxr-xr-x   1 root root  4096 Feb  5  2018 sbin
drwxr-xr-x   1 root root  4096 Feb  5  2018 bin
drwxr-xr-x   1 root root  4096 Feb  5  2018 opt
drwxr-xr-x   2 root root  4096 Feb  5  2018 hadoop-data
-rwxr-xr-x   1 root root   499 Oct  5  2018 run.sh
drwxr-xr-x   3 root root  4096 Oct  5  2018 hadoop
-rw-r--r--   1 root root 20895 Mar 19  2020 employees.java
drwx------   1 root root  4096 Mar 19  2020 root
-rw-r--r--   1 root root 24060 Mar 19  2020 derby.log
drwxr-xr-x   5 root root  4096 Mar 19  2020 metastore_db
drwxr-xr-x   1 root root  4096 Aug 31 00:21 etc
drwxr-xr-x   3 root root  4096 Aug 31 23:38 input
dr-xr-xr-x  13 root root     0 Sep  2 23:28 sys
dr-xr-xr-x 540 root root     0 Sep  2 23:28 proc
drwxr-xr-x   5 root root   340 Sep  2 23:28 dev
drwxrwxrwt   1 root root  4096 Sep  2 23:28 tmp

root@namenode:/# ls /input/exercises-data/populacaoLA/
README.md  populacaoLA.csv  populacaoLA.json
root@namenode:/# 

# vamos mandar o arquivo xxx para o diretorio dentro do hdfs /user/aluno/rodrigo/data/populacao

# criar um diretorio no HDFS para isto 

root@namenode:/# hdfs dfs -mkdir /user/aluno/heron/data/populacao


root@namenode:/# hdfs dfs -ls -R /user/aluno/
drwxr-xr-x   - root supergroup          0 2021-09-01 00:43 /user/aluno/heron
drwxr-xr-x   - root supergroup          0 2021-09-02 23:41 /user/aluno/heron/data
drwxr-xr-x   - root supergroup          0 2021-09-01 00:22 /user/aluno/heron/data/escola
-rw-r--r--   3 root supergroup        147 2021-09-01 00:22 /user/aluno/heron/data/escola/README.md
-rw-r--r--   3 root supergroup     546284 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.csv
-rw-r--r--   3 root supergroup    4891872 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.json
-rw-r--r--   3 root supergroup      98437 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.png
-rw-r--r--   3 root supergroup    6044140 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.xml
-rw-r--r--   3 root supergroup       4667 2021-09-01 00:22 /user/aluno/heron/data/escola/bens-imoveis.json
-rw-r--r--   3 root supergroup      78599 2021-09-01 00:22 /user/aluno/heron/data/escola/bens-imoveis.png
-rw-r--r--   3 root supergroup       5630 2021-09-01 00:22 /user/aluno/heron/data/escola/bens-imoveis.xml
-rw-r--r--   3 root supergroup       1998 2021-09-01 00:22 /user/aluno/heron/data/escola/bens_imovel.csv
-rw-r--r--   3 root supergroup     731195 2021-09-01 00:22 /user/aluno/heron/data/escola/componentes-curriculares.csv
-rw-r--r--   3 root supergroup    9787990 2021-09-01 00:22 /user/aluno/heron/data/escola/componentes-curriculares.json
-rw-r--r--   3 root supergroup     109655 2021-09-01 00:22 /user/aluno/heron/data/escola/componentes-curriculares.png
-rw-r--r--   3 root supergroup      18308 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.csv
-rw-r--r--   3 root supergroup     253692 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.json
-rw-r--r--   3 root supergroup      97271 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.png
-rw-r--r--   3 root supergroup     295196 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.xml
-rw-r--r--   3 root supergroup      12129 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.csv
-rw-r--r--   3 root supergroup     279549 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.json
-rw-r--r--   3 root supergroup      96691 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.png
-rw-r--r--   3 root supergroup     336640 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.xml
-rw-r--r--   3 root supergroup      18694 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.csv
-rw-r--r--   3 root supergroup      33426 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.json
-rw-r--r--   3 root supergroup     169764 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.png
-rw-r--r--   3 root supergroup      41473 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.xml
-rw-r--r--   3 root supergroup     105897 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.csv
-rw-r--r--   3 root supergroup    2597473 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.json
-rw-r--r--   3 root supergroup      89028 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.png
-rw-r--r--   3 root supergroup    3069250 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.xml
-rw-r--r--   3 root supergroup     314729 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades-organizacionais.json
-rw-r--r--   3 root supergroup     102433 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades-organizacionais.png
-rw-r--r--   3 root supergroup     382416 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades-organizacionais.xml
-rw-r--r--   3 root supergroup      40235 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades.csv

drwxr-xr-x   - root supergroup          0 2021-09-02 23:41 /user/aluno/heron/data/populacao

-rw-r--r--   2 root supergroup          0 2021-09-01 01:03 /user/aluno/heron/data/test
root@namenode:/# 



# copiar o arquivo populacaoLA.csv , do local namenode /input/exercises-data/populacaoLA/ para dentro da pasta /user/aluno/heron/data/populacao no HDFS

root@namenode:/# ls -ltr /input/exercises-data/populacaoLA/
total 88
-rw-r--r-- 1 root root 12183 Aug 31 23:38 populacaoLA.csv
-rw-r--r-- 1 root root   376 Aug 31 23:38 README.md
-rw-r--r-- 1 root root 73400 Aug 31 23:38 populacaoLA.json
root@namenode:/# 

/input/exercises-data/populacaoLA/populacaoLA.csv /user/aluno/heron/data/populacao

root@namenode:/# hdfs dfs -put /input/exercises-data/populacaoLA/populacaoLA.csv /user/aluno/heron/data/populacao

# faz a verificacao se o arquivo foi 
root@namenode:/# hdfs dfs -ls /user/aluno/heron/data/populacao
Found 1 items
-rw-r--r--   3 root supergroup      12183 2021-09-03 00:02 /user/aluno/heron/data/populacao/populacaoLA.csv
root@namenode:/# 


# vendo o conteudo do arquivo , do inicio 

root@namenode:/# hdfs dfs -cat /user/aluno/heron/data/populacao/populacaoLA.csv | head -n 3
Zip Code,Total Population,Median Age,Total Males,Total Females,Total Households,Average Household Size
91371,1,73.5,0,1,1,1
90001,57110,26.6,28468,28642,12971,4.4
root@namenode:/# 



2. Listar os bancos de dados no Hive

# sair do namenode , utilizando o comando CTRl + D ou exit e acessar o container do hive atraves do 2º comando 

root@namenode:/# exit
(base) heron@acerubuntu:~/docker-bigdata$ 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it hive-server bash

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it hive-server bash
root@hive_server:/opt# 

# verificar as formas de acesso

root@hive_server:/opt# beeline --help
Usage: java org.apache.hive.cli.beeline.BeeLine 
   -u <database url>               the JDBC URL to connect to
   -r                              reconnect to last saved connect url (in conjunction with !save)
   -n <username>                   the username to connect as
   -p <password>                   the password to connect as


 Example:
    1. Connect using simple authentication to HiveServer2 on localhost:10000
    $ beeline -u jdbc:hive2://localhost:10000 username password

    2. Connect using simple authentication to HiveServer2 on hs.local:10000 using -n for username and -p for password
    $ beeline -n username -p password -u jdbc:hive2://hs2.local:10012

    3. Connect using Kerberos authentication with hive/localhost@mydomain.com as HiveServer2 principal
    $ beeline -u "jdbc:hive2://hs2.local:10013/default;principal=hive/localhost@mydomain.com"

    4. Connect using SSL connection to HiveServer2 on localhost at 10000
    $ beeline "jdbc:hive2://localhost:10000/default;ssl=true;sslTrustStore=/usr/local/truststore;trustStorePassword=mytruststorepassword"

    5. Connect using LDAP authentication
    $ beeline -u jdbc:hive2://hs2.local:10013/default <ldap-username> <ldap-password>



root@hive_server:/opt# beeline -u jdbc:hive2://localhost:10000
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://localhost:10000
Connected to: Apache Hive (version 2.3.2)
Driver: Hive JDBC (version 2.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.2 by Apache Hive
0: jdbc:hive2://localhost:10000> 




0: jdbc:hive2://localhost:10000> show databases;
+----------------+
| database_name  |
+----------------+
| default        |
+----------------+
1 row selected (0.767 seconds)
0: jdbc:hive2://localhost:10000> 





3. Criar o banco de dados <nome>

0: jdbc:hive2://localhost:10000> create database heron;
No rows affected (0.801 seconds)

0: jdbc:hive2://localhost:10000> show databases;
+----------------+
| database_name  |
+----------------+
| default        |
| heron          |
+----------------+
2 rows selected (0.023 seconds)
0: jdbc:hive2://localhost:10000> 



4. Criar a Tabela Hive no BD <nome>



a. Tabela interna: pop
b. Campos:
   o zip_code - int
   o total_population - int
   o median_age - float
   o total_males - int
   o total_females - int
   o total_households - int
   o average_household_size - float
c. Propriedades

d. Delimitadores: Campo ‘,’ | Linha ‘\n’

e. Sem Partição

f. Tipo do arquivo: Texto

g. tblproperties("skip.header.line.count"="1")’


# para criar a tabela, temos que estar no banco especifico 

0: jdbc:hive2://localhost:10000> use heron;
No rows affected (0.036 seconds)
0: jdbc:hive2://localhost:10000> 

0: jdbc:hive2://localhost:10000> create table pop(
. . . . . . . . . . . . . . . .> zip_code int,
. . . . . . . . . . . . . . . .> total_population int,
. . . . . . . . . . . . . . . .> median_age float,
. . . . . . . . . . . . . . . .> total_males int,
. . . . . . . . . . . . . . . .> total_females int,
. . . . . . . . . . . . . . . .> total_households int,
. . . . . . . . . . . . . . . .> average_household_size float
. . . . . . . . . . . . . . . .> )
. . . . . . . . . . . . . . . .> row format delimited
. . . . . . . . . . . . . . . .> fields terminated by ','
. . . . . . . . . . . . . . . .> lines terminated by '\n'
. . . . . . . . . . . . . . . .> stored as textfile
. . . . . . . . . . . . . . . .> tblproperties("skip.header.line.count"="1");
No rows affected (0.827 seconds)
0: jdbc:hive2://localhost:10000> 


# para criar a tabela , melhor digitar tudo numa unica linha 




5. Visualizar a descrição da tabela pop


0: jdbc:hive2://localhost:10000> desc pop;
+-------------------------+------------+----------+
|        col_name         | data_type  | comment  |
+-------------------------+------------+----------+
| zip_code                | int        |          |
| total_population        | int        |          |
| median_age              | float      |          |
| total_males             | int        |          |
| total_females           | int        |          |
| total_households        | int        |          |
| average_household_size  | float      |          |
+-------------------------+------------+----------+
7 rows selected (0.164 seconds)
0: jdbc:hive2://localhost:10000> 



0: jdbc:hive2://localhost:10000> desc formatted pop;
+-------------------------------+----------------------------------------------------+-----------------------------+
|           col_name            |                     data_type                      |           comment           |
+-------------------------------+----------------------------------------------------+-----------------------------+
| # col_name                    | data_type                                          | comment                     |
|                               | NULL                                               | NULL                        |
| zip_code                      | int                                                |                             |
| total_population              | int                                                |                             |
| median_age                    | float                                              |                             |
| total_males                   | int                                                |                             |
| total_females                 | int                                                |                             |
| total_households              | int                                                |                             |
| average_household_size        | float                                              |                             |
|                               | NULL                                               | NULL                        |
| # Detailed Table Information  | NULL                                               | NULL                        |
| Database:                     | heron                                              | NULL                        |
| Owner:                        | root                                               | NULL                        |
| CreateTime:                   | Fri Sep 03 00:33:02 UTC 2021                       | NULL                        |
| LastAccessTime:               | UNKNOWN                                            | NULL                        |
| Retention:                    | 0                                                  | NULL                        |
| Location:                     | hdfs://namenode:8020/user/hive/warehouse/heron.db/pop | NULL                        |
| Table Type:                   | MANAGED_TABLE                                      | NULL                        |
| Table Parameters:             | NULL                                               | NULL                        |
|                               | COLUMN_STATS_ACCURATE                              | {\"BASIC_STATS\":\"true\"}  |
|                               | numFiles                                           | 0                           |
|                               | numRows                                            | 0                           |
|                               | rawDataSize                                        | 0                           |
|                               | skip.header.line.count                             | 1                           |
|                               | totalSize                                          | 0                           |
|                               | transient_lastDdlTime                              | 1630629182                  |
|                               | NULL                                               | NULL                        |
| # Storage Information         | NULL                                               | NULL                        |
| SerDe Library:                | org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe | NULL                        |
| InputFormat:                  | org.apache.hadoop.mapred.TextInputFormat           | NULL                        |
| OutputFormat:                 | org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat | NULL                        |
| Compressed:                   | No                                                 | NULL                        |
| Num Buckets:                  | -1                                                 | NULL                        |
| Bucket Columns:               | []                                                 | NULL                        |
| Sort Columns:                 | []                                                 | NULL                        |
| Storage Desc Params:          | NULL                                               | NULL                        |
|                               | field.delim                                        | ,                           |
|                               | line.delim                                         | \n                          |
|                               | serialization.format                               | ,                           |
+-------------------------------+----------------------------------------------------+-----------------------------+
39 rows selected (0.098 seconds)
0: jdbc:hive2://localhost:10000> 

# para sair do banco utilizar o comando CTRL + D 

# para sair do namenode CTRL + D 

0: jdbc:hive2://localhost:10000> Closing: 0: jdbc:hive2://localhost:10000
root@hive_server:/opt# exit
(base) heron@acerubuntu:~/docker-bigdata$ docker-compose stop
Stopping hive-server               ... done
Stopping hive_metastore            ... done
Stopping hive-metastore-postgresql ... done
Stopping datanode                  ... done
Stopping hbase-master              ... done
Stopping namenode                  ... done
Stopping zookeeper                 ... done
Stopping spark                     ... done
Stopping database                  ... done
(base) heron@acerubuntu:~/docker-bigdata$ 



#########################################
EXERCICIOS - AULA 04 - INSERIR DADOS NA TABELA RAW 
#########################################


(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ 


para verificar todos os containers , status, utilize o comando abaixo 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   21 hours ago   Exited (137) 21 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   21 hours ago   Exited (143) 21 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   21 hours ago   Exited (0) 21 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   21 hours ago   Exited (137) 21 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   21 hours ago   Exited (137) 21 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   21 hours ago   Exited (0) 21 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ 

podemos verificar que todos os containers ( serviços ) estao em Exited.

nao existe containers ativos, com isso devemos ativar o cluster 

-- ativar o cluster bigdata utilizand o comando abaixo , utilizando o parametro -d para realizar em background a incializacao
   do contrario, vai ficar aparecendo um log enorme até o cluster estar ativo.

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d



1.Visualizar a descrição da tabela pop do banco de dados <nome>


(base) heron@acerubuntu:~$ ls -ltr
total 68
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Videos
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Templates
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Public
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Music
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Documents
drwxrwxr-x  3 heron heron 4096 fev 14  2021 opt
drwxrwxr-x  2 heron heron 4096 fev 14  2021 bin
-rw-rw-r--  1 heron heron   26 fev 15  2021 meu_arquivo.txt
-rw-rw-r--  1 heron heron    0 fev 19  2021 ameu_arquivo.txt
-rw-rw-r--  1 heron heron   76 fev 21  2021 vim_basico.txt
drwxrwxr-x 28 heron heron 4096 jun  1 14:03 anaconda3
drwxrwxr-x  3 heron heron 4096 jun  2 11:54 PycharmProjects
drwxr-xr-x  2 heron heron 4096 jun  2 12:29 Downloads
drwxr-xr-x  8 heron heron 4096 jun  5 13:12 snap
drwxrwxr-x  4 heron heron 4096 ago 29 09:58 DataEngineer
drwxr-xr-x  2 heron heron 4096 ago 29 11:01 Pictures
drwxrwxr-x  5 heron heron 4096 ago 30 21:21 docker-bigdata
drwxr-xr-x  3 heron heron 4096 ago 31 20:19 Desktop
(base) heron@acerubuntu:~$ cd docker-bigdata/
(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED      STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   4 days ago   Exited (137) 37 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   4 days ago   Exited (143) 37 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   4 days ago   Exited (0) 37 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   4 days ago   Exited (137) 37 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   4 days ago   Exited (137) 37 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   4 days ago   Exited (137) 37 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   4 days ago   Exited (137) 37 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   4 days ago   Exited (137) 37 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   4 days ago   Exited (0) 37 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d
Starting namenode  ... done
Starting database     ... done
Starting spark     ... done
Starting zookeeper    ... done
Starting hbase-master              ... done
Starting datanode     ... done
Starting hive-metastore-postgresql ... done
Starting hive_metastore            ... done
Starting hive-server               ... done
(base) heron@acerubuntu:~/docker-bigdata$ 


### CONECTAR NO HIVE 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it hive-server bash
root@hive_server:/opt# 

### CONECTAR NO BEELINE 

root@hive_server:/opt# beeline -u jdbc:hive2://localhost:10000

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://localhost:10000
Connected to: Apache Hive (version 2.3.2)
Driver: Hive JDBC (version 2.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.2 by Apache Hive
0: jdbc:hive2://localhost:10000> 



### visualizar os dbs 

0: jdbc:hive2://localhost:10000> show databases;
+----------------+
| database_name  |
+----------------+
| default        |
| heron          |
+----------------+
2 rows selected (0.71 seconds)




### entrar num db

0: jdbc:hive2://localhost:10000> use heron;



### visualiza todas as tabelas de um banco 

0: jdbc:hive2://localhost:10000> show tables;
+-----------+
| tab_name  |
+-----------+
| pop       |
+-----------+
1 row selected (0.037 seconds)
0: jdbc:hive2://localhost:10000> 




### visualizar a descricao da tabela 

0: jdbc:hive2://localhost:10000> desc pop;
+-------------------------+------------+----------+
|        col_name         | data_type  | comment  |
+-------------------------+------------+----------+
| zip_code                | int        |          |
| total_population        | int        |          |
| median_age              | float      |          |
| total_males             | int        |          |
| total_females           | int        |          |
| total_households        | int        |          |
| average_household_size  | float      |          |
+-------------------------+------------+----------+
7 rows selected (0.071 seconds)


0: jdbc:hive2://localhost:10000> desc formatted pop;
+-------------------------------+----------------------------------------------------+-----------------------------+
|           col_name            |                     data_type                      |           comment           |
+-------------------------------+----------------------------------------------------+-----------------------------+
| # col_name                    | data_type                                          | comment                     |
|                               | NULL                                               | NULL                        |
| zip_code                      | int                                                |                             |
| total_population              | int                                                |                             |
| median_age                    | float                                              |                             |
| total_males                   | int                                                |                             |
| total_females                 | int                                                |                             |
| total_households              | int                                                |                             |
| average_household_size        | float                                              |                             |
|                               | NULL                                               | NULL                        |
| # Detailed Table Information  | NULL                                               | NULL                        |
| Database:                     | heron                                              | NULL                        |
| Owner:                        | root                                               | NULL                        |
| CreateTime:                   | Fri Sep 03 00:33:02 UTC 2021                       | NULL                        |
| LastAccessTime:               | UNKNOWN                                            | NULL                        |
| Retention:                    | 0                                                  | NULL                        |
| Location:                     | hdfs://namenode:8020/user/hive/warehouse/heron.db/pop | NULL                        |
| Table Type:                   | MANAGED_TABLE                                      | NULL                        |
| Table Parameters:             | NULL                                               | NULL                        |
|                               | COLUMN_STATS_ACCURATE                              | {\"BASIC_STATS\":\"true\"}  |
|                               | numFiles                                           | 0                           |
|                               | numRows                                            | 0                           |
|                               | rawDataSize                                        | 0                           |
|                               | skip.header.line.count                             | 1                           |
|                               | totalSize                                          | 0                           |
|                               | transient_lastDdlTime                              | 1630629182                  |
|                               | NULL                                               | NULL                        |
| # Storage Information         | NULL                                               | NULL                        |
| SerDe Library:                | org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe | NULL                        |
| InputFormat:                  | org.apache.hadoop.mapred.TextInputFormat           | NULL                        |
| OutputFormat:                 | org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat | NULL                        |
| Compressed:                   | No                                                 | NULL                        |
| Num Buckets:                  | -1                                                 | NULL                        |
| Bucket Columns:               | []                                                 | NULL                        |
| Sort Columns:                 | []                                                 | NULL                        |
| Storage Desc Params:          | NULL                                               | NULL                        |
|                               | field.delim                                        | ,                           |
|                               | line.delim                                         | \n                          |
|                               | serialization.format                               | ,                           |
+-------------------------------+----------------------------------------------------+-----------------------------+
39 rows selected (0.08 seconds)
0: jdbc:hive2://localhost:10000> 


##$$$$$ - table type : indica SE A TABELA É INTERNA OU EXTERNA, NO CASO DE MANAGED_TABLE É INTERNA.




2.Selecionar os 10 primeiros registros da tabela pop


0: jdbc:hive2://localhost:10000> SELECT * FROM POP LIMIT 10;
+---------------+-----------------------+-----------------+------------------+--------------------+-----------------------+-----------------------------+
| pop.zip_code  | pop.total_population  | pop.median_age  | pop.total_males  | pop.total_females  | pop.total_households  | pop.average_household_size  |
+---------------+-----------------------+-----------------+------------------+--------------------+-----------------------+-----------------------------+
+---------------+-----------------------+-----------------+------------------+--------------------+-----------------------+-----------------------------+
No rows selected (1.441 seconds)
0: jdbc:hive2://localhost:10000> 





3.Carregar o arquivo do HDFS “/user/aluno/<nome>/data/população/populacaoLA.csv” para a tabela Hive pop

para verificar se o arquivo existe, devemos entrar no namenode e verificar se o arquivo esta la , atraves do hdfs dfs



## - acessando o namenode para visualizar o arquivo

docker exec -it namenode bash

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash
root@namenode:/# ls -ltr
total 152
drwxr-xr-x   2 root root  4096 Nov 19  2017 home
drwxr-xr-x   2 root root  4096 Nov 19  2017 boot
drwxr-xr-x   2 root root  4096 Dec 10  2017 srv
drwxr-xr-x   3 root root  4096 Dec 10  2017 run
drwxr-xr-x   2 root root  4096 Dec 10  2017 mnt
drwxr-xr-x   2 root root  4096 Dec 10  2017 media
drwxr-xr-x   2 root root  4096 Dec 10  2017 lib64
-rwxr-xr-x   1 root root  4145 Feb  5  2018 entrypoint.sh
drwxr-xr-x   1 root root  4096 Feb  5  2018 lib
drwxr-xr-x   1 root root  4096 Feb  5  2018 var
drwxr-xr-x   1 root root  4096 Feb  5  2018 usr
drwxr-xr-x   1 root root  4096 Feb  5  2018 sbin
drwxr-xr-x   1 root root  4096 Feb  5  2018 bin
drwxr-xr-x   1 root root  4096 Feb  5  2018 opt
drwxr-xr-x   2 root root  4096 Feb  5  2018 hadoop-data
-rwxr-xr-x   1 root root   499 Oct  5  2018 run.sh
drwxr-xr-x   3 root root  4096 Oct  5  2018 hadoop
-rw-r--r--   1 root root 20895 Mar 19  2020 employees.java
drwx------   1 root root  4096 Mar 19  2020 root
-rw-r--r--   1 root root 24060 Mar 19  2020 derby.log
drwxr-xr-x   5 root root  4096 Mar 19  2020 metastore_db
drwxr-xr-x   1 root root  4096 Aug 31 00:21 etc
drwxr-xr-x   3 root root  4096 Aug 31 23:38 input
dr-xr-xr-x  13 root root     0 Sep  4 13:26 sys
dr-xr-xr-x 536 root root     0 Sep  4 13:26 proc
drwxr-xr-x   5 root root   340 Sep  4 13:26 dev
drwxrwxrwt   1 root root  4096 Sep  4 13:26 tmp
root@namenode:/# 


## verificacao se a pasta/arquivo existe no HDFS DFS , O ARQUIVO 

root@namenode:/# hdfs dfs -ls -R /user/aluno/heron/data/populacao
-rw-r--r--   3 root supergroup      12183 2021-09-03 00:02 /user/aluno/heron/data/populacao/populacaoLA.csv
root@namenode:/# 


## INSERIOR O ARQUIVO NA TABELA 

# UTILIZA O COMANDO LOAD , NAO UTILIZA load data local inpath pois o arquivo ja se encontra no hdfs e nao no drive.
load data inpath 

0: jdbc:hive2://localhost:10000> load data inpath '/user/aluno/heron/data/populacao' overwrite into table pop;
No rows affected (1.306 seconds)
0: jdbc:hive2://localhost:10000> 



4.Selecionar os 10 primeiros registros da tabela pop


0: jdbc:hive2://localhost:10000> SELECT * FROM POP LIMIT 10;
+---------------+-----------------------+-----------------+------------------+--------------------+-----------------------+-----------------------------+
| pop.zip_code  | pop.total_population  | pop.median_age  | pop.total_males  | pop.total_females  | pop.total_households  | pop.average_household_size  |
+---------------+-----------------------+-----------------+------------------+--------------------+-----------------------+-----------------------------+
| 91371         | 1                     | 73.5            | 0                | 1                  | 1                     | 1.0                         |
| 90001         | 57110                 | 26.6            | 28468            | 28642              | 12971                 | 4.4                         |
| 90002         | 51223                 | 25.5            | 24876            | 26347              | 11731                 | 4.36                        |
| 90003         | 66266                 | 26.3            | 32631            | 33635              | 15642                 | 4.22                        |
| 90004         | 62180                 | 34.8            | 31302            | 30878              | 22547                 | 2.73                        |
| 90005         | 37681                 | 33.9            | 19299            | 18382              | 15044                 | 2.5                         |
| 90006         | 59185                 | 32.4            | 30254            | 28931              | 18617                 | 3.13                        |
| 90007         | 40920                 | 24.0            | 20915            | 20005              | 11944                 | 3.0                         |
| 90008         | 32327                 | 39.7            | 14477            | 17850              | 13841                 | 2.33                        |
| 90010         | 3800                  | 37.8            | 1874             | 1926               | 2014                  | 1.87                        |
+---------------+-----------------------+-----------------+------------------+--------------------+-----------------------+-----------------------------+
10 rows selected (0.15 seconds)
0: jdbc:hive2://localhost:10000> 







5.Contar a quantidade de registros da tabela pop


0: jdbc:hive2://localhost:10000> select count(*) from pop;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+------+
| _c0  |
+------+
| 319  |
+------+
1 row selected (1.857 seconds)
0: jdbc:hive2://localhost:10000> 






6. Clicar no botão de Enviar Tarefa, e enviar o texto: ok




#########################################
EXERCICIOS - AULA 05 - Exercícios - Criação de Tabela Particionada Hive
#########################################


(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ 


para verificar todos os containers , status, utilize o comando abaixo 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   21 hours ago   Exited (137) 21 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   21 hours ago   Exited (143) 21 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   21 hours ago   Exited (0) 21 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   21 hours ago   Exited (137) 21 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   21 hours ago   Exited (137) 21 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   21 hours ago   Exited (0) 21 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ 

podemos verificar que todos os containers ( serviços ) estao em Exited.

nao existe containers ativos, com isso devemos ativar o cluster 

-- ativar o cluster bigdata utilizand o comando abaixo , utilizando o parametro -d para realizar em background a incializacao
   do contrario, vai ficar aparecendo um log enorme até o cluster estar ativo.

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d


(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED      STATUS                        PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   6 days ago   Exited (137) 16 minutes ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   6 days ago   Exited (143) 16 minutes ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   6 days ago   Exited (0) 16 minutes ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   6 days ago   Exited (0) 2 hours ago                  hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   6 days ago   Exited (137) 16 minutes ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   6 days ago   Exited (137) 16 minutes ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   6 days ago   Exited (0) 16 minutes ago               database
(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d
Starting namenode  ... done
Starting database     ... done
Starting spark        ... done
Starting zookeeper    ... done
Starting hbase-master ... done
Starting datanode     ... done
Starting hive-metastore-postgresql ... done
Starting hive_metastore            ... done
Starting hive-server               ... done
(base) heron@acerubuntu:~/docker-bigdata$ 






1. Criar o diretório “/user/aluno/<nome>/data/nascimento” no HDFS

Criar o diretório “/user/aluno/heron/data/nascimento” no HDFS


1ª forma - entrar no namenode e executar o comando - ls / para verificar todos os diretorios dentro do HDFS

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash^C
(base) heron@acerubuntu:~/docker-bigdata$ 

2ª forma executar os comandos de fora do namonode 

root@namenode:/# exit               

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode hdfs dfs -mkdir /user/aluno/heron/data/nascimento
(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode hdfs dfs -ls -R /user/aluno/heron/data/

drwxr-xr-x   - root supergroup          0 2021-09-01 00:22 /user/aluno/heron/data/escola
-rw-r--r--   3 root supergroup        147 2021-09-01 00:22 /user/aluno/heron/data/escola/README.md
-rw-r--r--   3 root supergroup     546284 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.csv
-rw-r--r--   3 root supergroup    4891872 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.json
-rw-r--r--   3 root supergroup      98437 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.png
-rw-r--r--   3 root supergroup    6044140 2021-09-01 00:22 /user/aluno/heron/data/escola/alunos.xml
-rw-r--r--   3 root supergroup       4667 2021-09-01 00:22 /user/aluno/heron/data/escola/bens-imoveis.json
-rw-r--r--   3 root supergroup      78599 2021-09-01 00:22 /user/aluno/heron/data/escola/bens-imoveis.png
-rw-r--r--   3 root supergroup       5630 2021-09-01 00:22 /user/aluno/heron/data/escola/bens-imoveis.xml
-rw-r--r--   3 root supergroup       1998 2021-09-01 00:22 /user/aluno/heron/data/escola/bens_imovel.csv
-rw-r--r--   3 root supergroup     731195 2021-09-01 00:22 /user/aluno/heron/data/escola/componentes-curriculares.csv
-rw-r--r--   3 root supergroup    9787990 2021-09-01 00:22 /user/aluno/heron/data/escola/componentes-curriculares.json
-rw-r--r--   3 root supergroup     109655 2021-09-01 00:22 /user/aluno/heron/data/escola/componentes-curriculares.png
-rw-r--r--   3 root supergroup      18308 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.csv
-rw-r--r--   3 root supergroup     253692 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.json
-rw-r--r--   3 root supergroup      97271 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.png
-rw-r--r--   3 root supergroup     295196 2021-09-01 00:22 /user/aluno/heron/data/escola/cursos.xml
-rw-r--r--   3 root supergroup      12129 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.csv
-rw-r--r--   3 root supergroup     279549 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.json
-rw-r--r--   3 root supergroup      96691 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.png
-rw-r--r--   3 root supergroup     336640 2021-09-01 00:22 /user/aluno/heron/data/escola/designacoes.xml
-rw-r--r--   3 root supergroup      18694 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.csv
-rw-r--r--   3 root supergroup      33426 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.json
-rw-r--r--   3 root supergroup     169764 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.png
-rw-r--r--   3 root supergroup      41473 2021-09-01 00:22 /user/aluno/heron/data/escola/prestadoras-servico.xml
-rw-r--r--   3 root supergroup     105897 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.csv
-rw-r--r--   3 root supergroup    2597473 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.json
-rw-r--r--   3 root supergroup      89028 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.png
-rw-r--r--   3 root supergroup    3069250 2021-09-01 00:22 /user/aluno/heron/data/escola/servidores.xml
-rw-r--r--   3 root supergroup     314729 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades-organizacionais.json
-rw-r--r--   3 root supergroup     102433 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades-organizacionais.png
-rw-r--r--   3 root supergroup     382416 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades-organizacionais.xml
-rw-r--r--   3 root supergroup      40235 2021-09-01 00:22 /user/aluno/heron/data/escola/unidades.csv
drwxr-xr-x   - root supergroup          0 2021-09-06 22:48 /user/aluno/heron/data/nascimento
-rw-r--r--   2 root supergroup          0 2021-09-01 01:03 /user/aluno/heron/data/test
(base) heron@acerubuntu:~/docker-bigdata$ 


(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode hdfs dfs -ls /user/aluno/heron/data/
Found 3 items
drwxr-xr-x   - root supergroup          0 2021-09-01 00:22 /user/aluno/heron/data/escola
drwxr-xr-x   - root supergroup          0 2021-09-06 22:48 /user/aluno/heron/data/nascimento
-rw-r--r--   2 root supergroup          0 2021-09-01 01:03 /user/aluno/heron/data/test
(base) heron@acerubuntu:~/docker-bigdata$ 




2. Criar e usar o Banco de dados <nome>

 # o banco de dados hive com o nome heron ja existe , entao seguir os proximos procedimentos 


# entrar no hive 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it hive-server bash

root@hive_server:/opt# 

# entrar no beeline 


root@hive_server:/opt# beeline -u jdbc:hive2://localhost:10000

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://localhost:10000
Connected to: Apache Hive (version 2.3.2)
Driver: Hive JDBC (version 2.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.2 by Apache Hive
0: jdbc:hive2://localhost:10000> 







3. Criar uma tabela externa no Hive com os parâmetros:


a) Tabela: nascimento
b) Campos: nome (String), sexo (String) e frequencia (int)
c) Partição: ano
d) Delimitadores:




i) Campo ‘,’



ii)  Linha ‘\n’

e) Salvar

i) Tipo do arquivo: texto

ii) HDFS: '/user/aluno/<nome>/data/nascimento’


0: jdbc:hive2://localhost:10000> show databases;
+----------------+
| database_name  |
+----------------+
| default        |
| heron          |
+----------------+


0: jdbc:hive2://localhost:10000> use heron;
No rows affected (0.025 seconds)

0: jdbc:hive2://localhost:10000> show tables;
+-----------+
| tab_name  |
+-----------+
| pop       |
+-----------+
1 row selected (0.035 seconds)
0: jdbc:hive2://localhost:10000> 


0: jdbc:hive2://localhost:10000> create external table nascimento(nome string, sexo string, frequencia int) partitioned by (ano int) row format delimited fields terminated by ',' lines terminated by '\n' stored as textfile location '/user/aluno/heron/data/nascimento'; 
No rows affected (1.059 seconds)
0: jdbc:hive2://localhost:10000> 


0: jdbc:hive2://localhost:10000> show tables;
+-------------+
|  tab_name   |
+-------------+
| nascimento  |
| pop         |
+-------------+
2 rows selected (0.041 seconds)
0: jdbc:hive2://localhost:10000> 





4.Adicionar partição ano=2015


0: jdbc:hive2://localhost:10000> alter table nascimento add partition(ano=2015);
No rows affected (0.558 seconds)
0: jdbc:hive2://localhost:10000> 


# para verificar se a particao foi criada ( pasta ), sair do hive ou abrir um outro terminal e acessar o namenode e verificar a pasta 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash
root@namenode:/# hdfs dfs -ls /user/aluno/heron/data/nascimento
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-09-06 23:16 /user/aluno/heron/data/nascimento/ano=2015
root@namenode:/# 



5.Enviar o arquivo local “input/exercises-data/names/yob2015.txt” para o HDFS no diretório /user/aluno/<nome>/data/nascimento/ano=2015


# entra no namenode ( nó do cluster ) e vai na pasta especifica 

root@namenode:/# hdfs dfs -ls /user/aluno/heron/data/nascimento
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-09-06 23:16 /user/aluno/heron/data/nascimento/ano=2015
root@namenode:/# ls /input/exercises-data/names
NationalReadMe.pdf  yob1889.txt  yob1899.txt  yob1909.txt  yob1919.txt  yob1929.txt  yob1939.txt  yob1949.txt  yob1959.txt  yob1969.txt  yob1979.txt  yob1989.txt  yob1999.txt   yob2009.txt
yob1880.txt     yob1890.txt  yob1900.txt  yob1910.txt  yob1920.txt   yob1930.txt  yob1940.txt  yob1950.txt  yob1960.txt  yob1970.txt  yob1980.txt  yob1990.txt  yob2000.txt   yob2010.txt
yob1881.txt     yob1891.txt  yob1901.txt  yob1911.txt  yob1921.txt   yob1931.txt  yob1941.txt  yob1951.txt  yob1961.txt  yob1971.txt  yob1981.txt  yob1991.txt  yob2001.txt   yob2011.txt
yob1882.txt     yob1892.txt  yob1902.txt  yob1912.txt  yob1922.txt   yob1932.txt  yob1942.txt  yob1952.txt  yob1962.txt  yob1972.txt  yob1982.txt  yob1992.txt  yob2002.txt   yob2012.txt
yob1883.txt     yob1893.txt  yob1903.txt  yob1913.txt  yob1923.txt   yob1933.txt  yob1943.txt  yob1953.txt  yob1963.txt  yob1973.txt  yob1983.txt  yob1993.txt  yob2003.txt   yob2013.txt
yob1884.txt     yob1894.txt  yob1904.txt  yob1914.txt  yob1924.txt   yob1934.txt  yob1944.txt  yob1954.txt  yob1964.txt  yob1974.txt  yob1984.txt  yob1994.txt  yob2004.txt   yob2014.txt
yob1885.txt     yob1895.txt  yob1905.txt  yob1915.txt  yob1925.txt   yob1935.txt  yob1945.txt  yob1955.txt  yob1965.txt  yob1975.txt  yob1985.txt  yob1995.txt  yob2005.txt   yob2015.txt
yob1886.txt     yob1896.txt  yob1906.txt  yob1916.txt  yob1926.txt   yob1936.txt  yob1946.txt  yob1956.txt  yob1966.txt  yob1976.txt  yob1986.txt  yob1996.txt  yob2006.txt   yob2016.txt
yob1887.txt     yob1897.txt  yob1907.txt  yob1917.txt  yob1927.txt   yob1937.txt  yob1947.txt  yob1957.txt  yob1967.txt  yob1977.txt  yob1987.txt  yob1997.txt  yob2007.txt   yob2017.txt
yob1888.txt     yob1898.txt  yob1908.txt  yob1918.txt  yob1928.txt   yob1938.txt  yob1948.txt  yob1958.txt  yob1968.txt  yob1978.txt  yob1988.txt  yob1998.txt  yob2008.txt
root@namenode:/# 



# coloca o arquivo local na pasta do hdfs 

root@namenode:/# hdfs dfs -put /input/exercises-data/names/yob2015.txt /user/aluno/heron/data/nascimento/ano=2015
root@namenode:/# 


6.Selecionar os 10 primeiros registros da tabela nascimento no Hive

0: jdbc:hive2://localhost:10000> select * from heron.nascimento limit 10;
+------------------+------------------+------------------------+-----------------+
| nascimento.nome  | nascimento.sexo  | nascimento.frequencia  | nascimento.ano  |
+------------------+------------------+------------------------+-----------------+
| Emma             | F                | 20435                  | 2015            |
| Olivia           | F                | 19669                  | 2015            |
| Sophia           | F                | 17402                  | 2015            |
| Ava              | F                | 16361                  | 2015            |
| Isabella         | F                | 15594                  | 2015            |
| Mia              | F                | 14892                  | 2015            |
| Abigail          | F                | 12390                  | 2015            |
| Emily            | F                | 11780                  | 2015            |
| Charlotte        | F                | 11390                  | 2015            |
| Harper           | F                | 10291                  | 2015            |
+------------------+------------------+------------------------+-----------------+






7.Repita o processo do 4 ao 6 para os anos de 2016 e 2017.


# primeiramente criar as particoes nas tabelas, isto ira criar as pastas no hdfs e atualizar o metabase do hive

0: jdbc:hive2://localhost:10000> alter table nascimento add partition(ano=2016);
No rows affected (0.119 seconds)
0: jdbc:hive2://localhost:10000> alter table nascimento add partition(ano=2017);
No rows affected (0.111 seconds)
0: jdbc:hive2://localhost:10000> 


# coloquei os arquivos nas  pastas de particao de 2016 e 2017
root@namenode:/# hdfs dfs -put /input/exercises-data/names/yob2016.txt /user/aluno/heron/data/nascimento/ano=2016
root@namenode:/# hdfs dfs -put /input/exercises-data/names/yob2017.txt /user/aluno/heron/data/nascimento/ano=2017


root@namenode:/# hdfs dfs -ls /user/aluno/heron/data/nascimento
Found 3 items
drwxr-xr-x   - root supergroup          0 2021-09-06 23:25 /user/aluno/heron/data/nascimento/ano=2015
drwxr-xr-x   - root supergroup          0 2021-09-06 23:31 /user/aluno/heron/data/nascimento/ano=2016
drwxr-xr-x   - root supergroup          0 2021-09-06 23:32 /user/aluno/heron/data/nascimento/ano=2017
root@namenode:/# 



0: jdbc:hive2://localhost:10000> select * from heron.nascimento where ano=2015 limit 10;
+------------------+------------------+------------------------+-----------------+
| nascimento.nome  | nascimento.sexo  | nascimento.frequencia  | nascimento.ano  |
+------------------+------------------+------------------------+-----------------+
| Emma             | F                | 20435                  | 2015            |
| Olivia           | F                | 19669                  | 2015            |
| Sophia           | F                | 17402                  | 2015            |
| Ava              | F                | 16361                  | 2015            |
| Isabella         | F                | 15594                  | 2015            |
| Mia              | F                | 14892                  | 2015            |
| Abigail          | F                | 12390                  | 2015            |
| Emily            | F                | 11780                  | 2015            |
| Charlotte        | F                | 11390                  | 2015            |
| Harper           | F                | 10291                  | 2015            |
+------------------+------------------+------------------------+-----------------+
10 rows selected (0.562 seconds)
0: jdbc:hive2://localhost:10000> select * from heron.nascimento where ano=2016 limit 10;
+------------------+------------------+------------------------+-----------------+
| nascimento.nome  | nascimento.sexo  | nascimento.frequencia  | nascimento.ano  |
+------------------+------------------+------------------------+-----------------+
| Emma             | F                | 19471                  | 2016            |
| Olivia           | F                | 19327                  | 2016            |
| Ava              | F                | 16283                  | 2016            |
| Sophia           | F                | 16112                  | 2016            |
| Isabella         | F                | 14772                  | 2016            |
| Mia              | F                | 14415                  | 2016            |
| Charlotte        | F                | 13080                  | 2016            |
| Abigail          | F                | 11747                  | 2016            |
| Emily            | F                | 10957                  | 2016            |
| Harper           | F                | 10773                  | 2016            |
+------------------+------------------+------------------------+-----------------+
10 rows selected (0.104 seconds)
0: jdbc:hive2://localhost:10000> select * from heron.nascimento where ano=2017 limit 10;
+------------------+------------------+------------------------+-----------------+
| nascimento.nome  | nascimento.sexo  | nascimento.frequencia  | nascimento.ano  |
+------------------+------------------+------------------------+-----------------+
| Emma             | F                | 19738                  | 2017            |
| Olivia           | F                | 18632                  | 2017            |
| Ava              | F                | 15902                  | 2017            |
| Isabella         | F                | 15100                  | 2017            |
| Sophia           | F                | 14831                  | 2017            |
| Mia              | F                | 13437                  | 2017            |
| Charlotte        | F                | 12893                  | 2017            |
| Amelia           | F                | 11800                  | 2017            |
| Evelyn           | F                | 10675                  | 2017            |
| Abigail          | F                | 10551                  | 2017            |
+------------------+------------------+------------------------+-----------------+
10 rows selected (0.115 seconds)
0: jdbc:hive2://localhost:10000> 







8. Clicar no botão de Enviar Tarefa, e enviar o texto: ok



########################################
EXERCICIOS - AULA 06 - Exercícios - Seleção de Tabelas HIVE
########################################


# acionar o container do cluster, para isso é necessario estar dentro da pasta ao qual estao alocados o arquivo docker

(base) heron@acerubuntu:~$ ls -ltr
total 68
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Videos
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Templates
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Public
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Music
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Documents
drwxrwxr-x  3 heron heron 4096 fev 14  2021 opt
drwxrwxr-x  2 heron heron 4096 fev 14  2021 bin
-rw-rw-r--  1 heron heron   26 fev 15  2021 meu_arquivo.txt
-rw-rw-r--  1 heron heron    0 fev 19  2021 ameu_arquivo.txt
-rw-rw-r--  1 heron heron   76 fev 21  2021 vim_basico.txt
drwxrwxr-x 28 heron heron 4096 jun  1 14:03 anaconda3
drwxrwxr-x  3 heron heron 4096 jun  2 11:54 PycharmProjects
drwxr-xr-x  2 heron heron 4096 jun  2 12:29 Downloads
drwxr-xr-x  8 heron heron 4096 jun  5 13:12 snap
drwxrwxr-x  4 heron heron 4096 ago 29 09:58 DataEngineer
drwxr-xr-x  2 heron heron 4096 ago 29 11:01 Pictures
drwxrwxr-x  5 heron heron 4096 ago 30 21:21 docker-bigdata
drwxr-xr-x  3 heron heron 4096 ago 31 20:19 Desktop


(base) heron@acerubuntu:~$ cd docker-bigdata/
(base) heron@acerubuntu:~/docker-bigdata$


# verificar os containers ativos 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ 


para verificar todos os containers , status, utilize o comando abaixo 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   21 hours ago   Exited (137) 21 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   21 hours ago   Exited (143) 21 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   21 hours ago   Exited (0) 21 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   21 hours ago   Exited (137) 21 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   21 hours ago   Exited (137) 21 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   21 hours ago   Exited (0) 21 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ 

podemos verificar que todos os containers ( serviços ) estao em Exited.

nao existe containers ativos, com isso devemos ativar o cluster 

-- ativar o cluster bigdata utilizand o comando abaixo , utilizando o parametro -d para realizar em background a incializacao
   do contrario, vai ficar aparecendo um log enorme até o cluster estar ativo.

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d


(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED      STATUS                        PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   6 days ago   Exited (137) 16 minutes ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   6 days ago   Exited (143) 16 minutes ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   6 days ago   Exited (0) 16 minutes ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   6 days ago   Exited (0) 2 hours ago                  hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   6 days ago   Exited (137) 16 minutes ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   6 days ago   Exited (137) 16 minutes ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   6 days ago   Exited (0) 16 minutes ago               database
(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d
Starting namenode  ... done
Starting database     ... done
Starting spark        ... done
Starting zookeeper    ... done
Starting hbase-master ... done
Starting datanode     ... done
Starting hive-metastore-postgresql ... done
Starting hive_metastore            ... done
Starting hive-server               ... done
(base) heron@acerubuntu:~/docker-bigdata$ 






1. Selecionar os 10 primeiros registros da tabela nascimento pelo ano de 2016

# entrar no container do hive e no beeline 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it hive-server bash

root@hive_server:/opt# beeline -u jdbc:hive2://localhost:10000
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://localhost:10000
Connected to: Apache Hive (version 2.3.2)
Driver: Hive JDBC (version 2.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.2 by Apache Hive
0: jdbc:hive2://localhost:10000> 


# mostrar os dbs e as tabelas e entrar no nosso banco de dados : heron 

0: jdbc:hive2://localhost:10000> show databases;
+----------------+
| database_name  |
+----------------+
| default        |
| heron          |
+----------------+
2 rows selected (0.771 seconds)
0: jdbc:hive2://localhost:10000> use heron;
No rows affected (0.023 seconds)
0: jdbc:hive2://localhost:10000> show tables;
+-------------+
|  tab_name   |
+-------------+
| nascimento  |
| pop         |
+-------------+
2 rows selected (0.039 seconds)
0: jdbc:hive2://localhost:10000> 


0: jdbc:hive2://localhost:10000> select * from nascimento where ano=2016 limit 10;
+------------------+------------------+------------------------+-----------------+
| nascimento.nome  | nascimento.sexo  | nascimento.frequencia  | nascimento.ano  |
+------------------+------------------+------------------------+-----------------+
| Emma             | F                | 19471                  | 2016            |
| Olivia           | F                | 19327                  | 2016            |
| Ava              | F                | 16283                  | 2016            |
| Sophia           | F                | 16112                  | 2016            |
| Isabella         | F                | 14772                  | 2016            |
| Mia              | F                | 14415                  | 2016            |
| Charlotte        | F                | 13080                  | 2016            |
| Abigail          | F                | 11747                  | 2016            |
| Emily            | F                | 10957                  | 2016            |
| Harper           | F                | 10773                  | 2016            |
+------------------+------------------+------------------------+-----------------+
10 rows selected (1.895 seconds)
0: jdbc:hive2://localhost:10000> 




2. Contar a quantidade de nomes de crianças nascidas em 2017

0: jdbc:hive2://localhost:10000> select count(nome) from nascimento where ano=2017;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+--------+
|  _c0   |
+--------+
| 32469  |
+--------+
1 row selected (1.261 seconds)
0: jdbc:hive2://localhost:10000> select count(distinct nome) from nascimento where ano=2017;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+--------+
|  _c0   |
+--------+
| 29910  |
+--------+
1 row selected (1.315 seconds)
0: jdbc:hive2://localhost:10000> 


0: jdbc:hive2://localhost:10000> select * from nascimento where ano=2017 and nome='Zion';
+------------------+------------------+------------------------+-----------------+
| nascimento.nome  | nascimento.sexo  | nascimento.frequencia  | nascimento.ano  |
+------------------+------------------+------------------------+-----------------+
| Zion             | F                | 284                    | 2017            |
| Zion             | M                | 1956                   | 2017            |
+------------------+------------------+------------------------+-----------------+
2 rows selected (0.139 seconds)
0: jdbc:hive2://localhost:10000> 



3. Contar a quantidade de crianças nascidas em 2017

0: jdbc:hive2://localhost:10000> select sum(frequencia) as qtd from nascimento where ano=2017;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+----------+
|   qtd    |
+----------+
| 3546301  |
+----------+
1 row selected (1.252 seconds)
0: jdbc:hive2://localhost:10000> 



4. Contar a quantidade de crianças nascidas por sexo no ano de 2015


0: jdbc:hive2://localhost:10000> select sexo, sum(frequencia) as qtd from nascimento where ano=2015 group by sexo;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+-------+----------+
| sexo  |   qtd    |
+-------+----------+
| F     | 1778883  |
| M     | 1909804  |
+-------+----------+
2 rows selected (1.261 seconds)
0: jdbc:hive2://localhost:10000> 






5. Mostrar por ordem de ano decrescente a quantidade de crianças nascidas por sexo


0: jdbc:hive2://localhost:10000> select ano, sexo, sum(frequencia) as qtd from nascimento group by ano, sexo order by 1 desc;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+-------+-------+----------+
|  ano  | sexo  |   qtd    |
+-------+-------+----------+
| 2017  | M     | 1834490  |
| 2017  | F     | 1711811  |
| 2016  | M     | 1889052  |
| 2016  | F     | 1763916  |
| 2015  | M     | 1909804  |
| 2015  | F     | 1778883  |
+-------+-------+----------+
6 rows selected (2.479 seconds)
0: jdbc:hive2://localhost:10000> select ano, sexo, sum(frequencia) as qtd from nascimento group by ano, sexo order by 1 desc, 2 asc;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+-------+-------+----------+
|  ano  | sexo  |   qtd    |
+-------+-------+----------+
| 2017  | F     | 1711811  |
| 2017  | M     | 1834490  |
| 2016  | F     | 1763916  |
| 2016  | M     | 1889052  |
| 2015  | F     | 1778883  |
| 2015  | M     | 1909804  |
+-------+-------+----------+
6 rows selected (2.451 seconds)
0: jdbc:hive2://localhost:10000> 





6. Mostrar por ordem de ano decrescente a quantidade de crianças nascidas por sexo com o nome iniciado com ‘A’

0: jdbc:hive2://localhost:10000> select ano, sexo, sum(frequencia) as qtd from nascimento where nome like 'A%' group by ano, sexo order by 1 desc, 2 asc;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+-------+-------+---------+
|  ano  | sexo  |   qtd   |
+-------+-------+---------+
| 2017  | F     | 308551  |
| 2017  | M     | 185566  |
| 2016  | F     | 324185  |
| 2016  | M     | 191854  |
| 2015  | F     | 329690  |
| 2015  | M     | 194722  |
+-------+-------+---------+
6 rows selected (2.45 seconds)
0: jdbc:hive2://localhost:10000> 



7. Qual nome e quantidade das 5 crianças mais nascidas em 2016


0: jdbc:hive2://localhost:10000> select nome, max(frequencia) as qtd from nascimento where ano=2016 group by nome order by qtd desc limit 5;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+---------+--------+
|  nome   |  qtd   |
+---------+--------+
| Emma    | 19471  |
| Olivia  | 19327  |
| Noah    | 19082  |
| Liam    | 18198  |
| Ava     | 16283  |
+---------+--------+
5 rows selected (2.515 seconds)
0: jdbc:hive2://localhost:10000> 





8. Qual nome e quantidade das 5 crianças mais nascidas em 2016 do sexo masculino e feminino


0: jdbc:hive2://localhost:10000> select sexo, nome, max(frequencia) as qtd from nascimento where ano=2016 group by sexo, nome order by qtd desc limit 5;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+-------+---------+--------+
| sexo  |  nome   |  qtd   |
+-------+---------+--------+
| F     | Emma    | 19471  |
| F     | Olivia  | 19327  |
| M     | Noah    | 19082  |
| M     | Liam    | 18198  |
| F     | Ava     | 16283  |
+-------+---------+--------+
5 rows selected (2.58 seconds)
0: jdbc:hive2://localhost:10000> 





9. Clicar no botão de Enviar Tarefa, e enviar o texto: ok




########################################
EXERCICIOS - AULA 06 - Exercícios - Criação de Tabelas Otimizadas HIVE
########################################


# acionar o container do cluster, para isso é necessario estar dentro da pasta ao qual estao alocados o arquivo docker

(base) heron@acerubuntu:~$ ls -ltr
total 68
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Videos
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Templates
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Public
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Music
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Documents
drwxrwxr-x  3 heron heron 4096 fev 14  2021 opt
drwxrwxr-x  2 heron heron 4096 fev 14  2021 bin
-rw-rw-r--  1 heron heron   26 fev 15  2021 meu_arquivo.txt
-rw-rw-r--  1 heron heron    0 fev 19  2021 ameu_arquivo.txt
-rw-rw-r--  1 heron heron   76 fev 21  2021 vim_basico.txt
drwxrwxr-x 28 heron heron 4096 jun  1 14:03 anaconda3
drwxrwxr-x  3 heron heron 4096 jun  2 11:54 PycharmProjects
drwxr-xr-x  2 heron heron 4096 jun  2 12:29 Downloads
drwxr-xr-x  8 heron heron 4096 jun  5 13:12 snap
drwxrwxr-x  4 heron heron 4096 ago 29 09:58 DataEngineer
drwxr-xr-x  2 heron heron 4096 ago 29 11:01 Pictures
drwxrwxr-x  5 heron heron 4096 ago 30 21:21 docker-bigdata
drwxr-xr-x  3 heron heron 4096 ago 31 20:19 Desktop


(base) heron@acerubuntu:~$ cd docker-bigdata/
(base) heron@acerubuntu:~/docker-bigdata$


# verificar os containers ativos 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ 


para verificar todos os containers , status, utilize o comando abaixo 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   21 hours ago   Exited (137) 21 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   21 hours ago   Exited (143) 21 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   21 hours ago   Exited (0) 21 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   21 hours ago   Exited (137) 21 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   21 hours ago   Exited (137) 21 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   21 hours ago   Exited (0) 21 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ 

podemos verificar que todos os containers ( serviços ) estao em Exited.

nao existe containers ativos, com isso devemos ativar o cluster 

-- ativar o cluster bigdata utilizand o comando abaixo , utilizando o parametro -d para realizar em background a incializacao
   do contrario, vai ficar aparecendo um log enorme até o cluster estar ativo.

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d


(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED      STATUS                        PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   6 days ago   Exited (137) 16 minutes ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   6 days ago   Exited (143) 16 minutes ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   6 days ago   Exited (0) 16 minutes ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   6 days ago   Exited (0) 2 hours ago                  hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   6 days ago   Exited (137) 16 minutes ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   6 days ago   Exited (137) 16 minutes ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   6 days ago   Exited (0) 16 minutes ago               database
(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d
Starting namenode  ... done
Starting database     ... done
Starting spark        ... done
Starting zookeeper    ... done
Starting hbase-master ... done
Starting datanode     ... done
Starting hive-metastore-postgresql ... done
Starting hive_metastore            ... done
Starting hive-server               ... done
(base) heron@acerubuntu:~/docker-bigdata$ 




1. Usar o banco de dados <nome>

# entrar no container do hive e no beeline 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it hive-server bash

root@hive_server:/opt# beeline -u jdbc:hive2://localhost:10000
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://localhost:10000
Connected to: Apache Hive (version 2.3.2)
Driver: Hive JDBC (version 2.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.2 by Apache Hive
0: jdbc:hive2://localhost:10000> 


# mostrar os dbs e as tabelas e entrar no nosso banco de dados : heron 

0: jdbc:hive2://localhost:10000> show databases;
+----------------+
| database_name  |
+----------------+
| default        |
| heron          |
+----------------+
2 rows selected (0.771 seconds)


0: jdbc:hive2://localhost:10000> use heron;
No rows affected (0.023 seconds)
0: jdbc:hive2://localhost:10000> show tables;
+-------------+
|  tab_name   |
+-------------+
| nascimento  |
| pop         |
+-------------+
2 rows selected (0.039 seconds)
0: jdbc:hive2://localhost:10000> 




2. Selecionar os 10 primeiros registros da tabela pop


0: jdbc:hive2://localhost:10000> select * from pop limit 10;
+---------------+-----------------------+-----------------+------------------+--------------------+-----------------------+-----------------------------+
| pop.zip_code  | pop.total_population  | pop.median_age  | pop.total_males  | pop.total_females  | pop.total_households  | pop.average_household_size  |
+---------------+-----------------------+-----------------+------------------+--------------------+-----------------------+-----------------------------+
| 91371         | 1                     | 73.5            | 0                | 1                  | 1                     | 1.0                         |
| 90001         | 57110                 | 26.6            | 28468            | 28642              | 12971                 | 4.4                         |
| 90002         | 51223                 | 25.5            | 24876            | 26347              | 11731                 | 4.36                        |
| 90003         | 66266                 | 26.3            | 32631            | 33635              | 15642                 | 4.22                        |
| 90004         | 62180                 | 34.8            | 31302            | 30878              | 22547                 | 2.73                        |
| 90005         | 37681                 | 33.9            | 19299            | 18382              | 15044                 | 2.5                         |
| 90006         | 59185                 | 32.4            | 30254            | 28931              | 18617                 | 3.13                        |
| 90007         | 40920                 | 24.0            | 20915            | 20005              | 11944                 | 3.0                         |
| 90008         | 32327                 | 39.7            | 14477            | 17850              | 13841                 | 2.33                        |
| 90010         | 3800                  | 37.8            | 1874             | 1926               | 2014                  | 1.87                        |
+---------------+-----------------------+-----------------+------------------+--------------------+-----------------------+-----------------------------+
10 rows selected (0.117 seconds)
0: jdbc:hive2://localhost:10000> 




3. Criar a tabela pop_parquet no formato parquet para ler os dados da tabela pop


zip_code int, total_population int, median_age float, total_males int, total_females int, total_households int, average_household_size float) stored as parquet;

. . . . . . . . . . . . . . . .> tblproperties("skip.header.line.count"="1");


0: jdbc:hive2://localhost:10000> create table pop_parquet(zip_code int, total_population int, median_age float, total_males int, total_females int, total_households int, average_household_size float) stored as parquet;
No rows affected (1.058 seconds)
0: jdbc:hive2://localhost:10000> 



4. Inserir os dados da tabela pop na pop_parquet


insert into pop_parquet select  * from pop;


0: jdbc:hive2://localhost:10000> insert into pop_parquet select * from pop;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
No rows affected (2.429 seconds)
0: jdbc:hive2://localhost:10000> 




5. Contar os registros da tabela pop_parquet

0: jdbc:hive2://localhost:10000> select count(*) from pop;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
+------+
| _c0  |
+------+
| 319  |
+------+
1 row selected (1.33 seconds)
0: jdbc:hive2://localhost:10000> select count(*) from pop_parquet;
+------+
| _c0  |
+------+
| 319  |
+------+
1 row selected (0.093 seconds)
0: jdbc:hive2://localhost:10000> 




6. Selecionar os 10 primeiros registros da tabela pop_parquet


0: jdbc:hive2://localhost:10000> select * from pop_parquet limit 10;
+-----------------------+-------------------------------+-------------------------+--------------------------+----------------------------+-------------------------------+-------------------------------------+
| pop_parquet.zip_code  | pop_parquet.total_population  | pop_parquet.median_age  | pop_parquet.total_males  | pop_parquet.total_females  | pop_parquet.total_households  | pop_parquet.average_household_size  |
+-----------------------+-------------------------------+-------------------------+--------------------------+----------------------------+-------------------------------+-------------------------------------+
| 91371                 | 1                             | 73.5                    | 0                        | 1                          | 1                             | 1.0                                 |
| 90001                 | 57110                         | 26.6                    | 28468                    | 28642                      | 12971                         | 4.4                                 |
| 90002                 | 51223                         | 25.5                    | 24876                    | 26347                      | 11731                         | 4.36                                |
| 90003                 | 66266                         | 26.3                    | 32631                    | 33635                      | 15642                         | 4.22                                |
| 90004                 | 62180                         | 34.8                    | 31302                    | 30878                      | 22547                         | 2.73                                |
| 90005                 | 37681                         | 33.9                    | 19299                    | 18382                      | 15044                         | 2.5                                 |
| 90006                 | 59185                         | 32.4                    | 30254                    | 28931                      | 18617                         | 3.13                                |
| 90007                 | 40920                         | 24.0                    | 20915                    | 20005                      | 11944                         | 3.0                                 |
| 90008                 | 32327                         | 39.7                    | 14477                    | 17850                      | 13841                         | 2.33                                |
| 90010                 | 3800                          | 37.8                    | 1874                     | 1926                       | 2014                          | 1.87                                |
+-----------------------+-------------------------------+-------------------------+--------------------------+----------------------------+-------------------------------+-------------------------------------+
10 rows selected (0.151 seconds)
0: jdbc:hive2://localhost:10000> 






7. Criar a tabela pop_parquet_snappy no formato parquet com compressão Snappy para ler os dados da tabela pop


0: jdbc:hive2://localhost:10000> create table pop_parquet_snappy(zip_code int, total_population int, median_age float, total_males int, total_females int, total_households int, average_household_size float) stored as parquet tblproperties('parquet.compress'='SNAPPY');
No rows affected (0.241 seconds)
0: jdbc:hive2://localhost:10000> 







8. Inserir os dados da tabela pop na pop_parquet_snappy


0: jdbc:hive2://localhost:10000> insert into pop_parquet_snappy select * from pop;
WARNING: Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
No rows affected (2.129 seconds)
0: jdbc:hive2://localhost:10000> 




9. Contar os registros da tabela pop_parquet_snappy


0: jdbc:hive2://localhost:10000> select count(*) from pop_parquet_snappy;
+------+
| _c0  |
+------+
| 319  |
+------+
1 row selected (0.087 seconds)
0: jdbc:hive2://localhost:10000> 



10. Selecionar os 10 primeiros registros da tabela pop_parquet_snappy



0: jdbc:hive2://localhost:10000> select * from pop_parquet_snappy limit 10;
+------------------------------+--------------------------------------+--------------------------------+---------------------------------+-----------------------------------+--------------------------------------+--------------------------------------------+
| pop_parquet_snappy.zip_code  | pop_parquet_snappy.total_population  | pop_parquet_snappy.median_age  | pop_parquet_snappy.total_males  | pop_parquet_snappy.total_females  | pop_parquet_snappy.total_households  | pop_parquet_snappy.average_household_size  |
+------------------------------+--------------------------------------+--------------------------------+---------------------------------+-----------------------------------+--------------------------------------+--------------------------------------------+
| 91371                        | 1                                    | 73.5                           | 0                               | 1                                 | 1                                    | 1.0                                        |
| 90001                        | 57110                                | 26.6                           | 28468                           | 28642                             | 12971                                | 4.4                                        |
| 90002                        | 51223                                | 25.5                           | 24876                           | 26347                             | 11731                                | 4.36                                       |
| 90003                        | 66266                                | 26.3                           | 32631                           | 33635                             | 15642                                | 4.22                                       |
| 90004                        | 62180                                | 34.8                           | 31302                           | 30878                             | 22547                                | 2.73                                       |
| 90005                        | 37681                                | 33.9                           | 19299                           | 18382                             | 15044                                | 2.5                                        |
| 90006                        | 59185                                | 32.4                           | 30254                           | 28931                             | 18617                                | 3.13                                       |
| 90007                        | 40920                                | 24.0                           | 20915                           | 20005                             | 11944                                | 3.0                                        |
| 90008                        | 32327                                | 39.7                           | 14477                           | 17850                             | 13841                                | 2.33                                       |
| 90010                        | 3800                                 | 37.8                           | 1874                            | 1926                              | 2014                                 | 1.87                                       |
+------------------------------+--------------------------------------+--------------------------------+---------------------------------+-----------------------------------+--------------------------------------+--------------------------------------------+
10 rows selected (0.088 seconds)
0: jdbc:hive2://localhost:10000> 






11. Comparar as tabelas pop, pop_parquet e pop_parquet_snappy no HDFS.



root@namenode:/# hdfs dfs -ls -R -h /user/hive/warehouse/heron.db
drwxrwxr-x   - root supergroup          0 2021-09-03 00:02 /user/hive/warehouse/heron.db/pop
-rwxrwxr-x   3 root supergroup     11.9 K 2021-09-03 00:02 /user/hive/warehouse/heron.db/pop/populacaoLA.csv
drwxrwxr-x   - root supergroup          0 2021-09-07 22:49 /user/hive/warehouse/heron.db/pop_parquet
-rwxrwxr-x   3 root supergroup      9.3 K 2021-09-07 22:49 /user/hive/warehouse/heron.db/pop_parquet/000000_0
drwxrwxr-x   - root supergroup          0 2021-09-07 22:57 /user/hive/warehouse/heron.db/pop_parquet_snappy
-rwxrwxr-x   3 root supergroup      9.3 K 2021-09-07 22:57 /user/hive/warehouse/heron.db/pop_parquet_snappy/000000_0
root@namenode:/# hdfs dfs -ls -R -du -h /user/hive/warehouse/heron.db


root@namenode:/# hdfs dfs -du -h /user/hive/warehouse/heron.db
11.9 K  /user/hive/warehouse/heron.db/pop
9.3 K   /user/hive/warehouse/heron.db/pop_parquet
9.3 K   /user/hive/warehouse/heron.db/pop_parquet_snappy
root@namenode:/# 





12. Clicar no botão de Enviar Tarefa, e enviar o texto: ok





########################################
EXERCICIOS - AULA 07 - Exercícios - MySQL - Preparação do Banco de Dados de Testes
########################################


# acionar o container do cluster, para isso é necessario estar dentro da pasta ao qual estao alocados o arquivo docker

(base) heron@acerubuntu:~$ ls -ltr
total 68
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Videos
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Templates
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Public
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Music
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Documents
drwxrwxr-x  3 heron heron 4096 fev 14  2021 opt
drwxrwxr-x  2 heron heron 4096 fev 14  2021 bin
-rw-rw-r--  1 heron heron   26 fev 15  2021 meu_arquivo.txt
-rw-rw-r--  1 heron heron    0 fev 19  2021 ameu_arquivo.txt
-rw-rw-r--  1 heron heron   76 fev 21  2021 vim_basico.txt
drwxrwxr-x 28 heron heron 4096 jun  1 14:03 anaconda3
drwxrwxr-x  3 heron heron 4096 jun  2 11:54 PycharmProjects
drwxr-xr-x  2 heron heron 4096 jun  2 12:29 Downloads
drwxr-xr-x  8 heron heron 4096 jun  5 13:12 snap
drwxrwxr-x  4 heron heron 4096 ago 29 09:58 DataEngineer
drwxr-xr-x  2 heron heron 4096 ago 29 11:01 Pictures
drwxrwxr-x  5 heron heron 4096 ago 30 21:21 docker-bigdata
drwxr-xr-x  3 heron heron 4096 ago 31 20:19 Desktop


(base) heron@acerubuntu:~$ cd docker-bigdata/
(base) heron@acerubuntu:~/docker-bigdata$


# verificar os containers ativos 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ 


para verificar todos os containers , status, utilize o comando abaixo 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   21 hours ago   Exited (137) 21 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   21 hours ago   Exited (143) 21 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   21 hours ago   Exited (0) 21 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   21 hours ago   Exited (137) 21 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   21 hours ago   Exited (137) 21 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   21 hours ago   Exited (0) 21 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ 

podemos verificar que todos os containers ( serviços ) estao em Exited.

nao existe containers ativos, com isso devemos ativar o cluster 

-- ativar o cluster bigdata utilizand o comando abaixo , utilizando o parametro -d para realizar em background a incializacao
   do contrario, vai ficar aparecendo um log enorme até o cluster estar ativo.

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d


(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED      STATUS                        PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   6 days ago   Exited (137) 16 minutes ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   6 days ago   Exited (143) 16 minutes ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   6 days ago   Exited (0) 16 minutes ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   6 days ago   Exited (0) 2 hours ago                  hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   6 days ago   Exited (137) 16 minutes ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   6 days ago   Exited (137) 16 minutes ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   6 days ago   Exited (0) 16 minutes ago               database
(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d
Starting namenode  ... done
Starting database     ... done
Starting spark        ... done
Starting zookeeper    ... done
Starting hbase-master ... done
Starting datanode     ... done
Starting hive-metastore-postgresql ... done
Starting hive_metastore            ... done
Starting hive-server               ... done
(base) heron@acerubuntu:~/docker-bigdata$ 





1. Copiar os dados do local para o contêiner database


      # copiar os dados do local para o container database 

      (base) heron@acerubuntu:~$ cd docker-bigdata/
      (base) heron@acerubuntu:~/docker-bigdata$ ls -ltr
      total 376
      -rwxrwxr-x  1 heron heron   3443 ago 30 20:31 README.md
      -rw-rw-r--  1 heron heron 343678 ago 30 20:31 ecosystem.jpeg
      -rwxrwxr-x  1 heron heron   3778 ago 30 20:31 docker-compose.yml
      -rw-rw-r--  1 heron heron   5172 ago 30 20:31 docker-compose-parcial.yml
      -rw-rw-r--  1 heron heron   6381 ago 30 20:31 docker-compose-completo.yml
      -rw-rw-r--  1 heron heron   6755 ago 30 20:31 docker-compose-completo-windows.yml
      drwxrwxr-x 15 heron heron   4096 ago 30 21:21 data
      drwxr-xr-x  3 root  root    4096 ago 31 20:38 input
      (base) heron@acerubuntu:~/docker-bigdata$ 

      (base) heron@acerubuntu:~/docker-bigdata$ ls -ltr input/exercises-data/db-sql/
      total 168340
      -rw-r--r-- 1 root root      964 ago 31 20:38 Changelog
      -rw-r--r-- 1 root root     4009 ago 31 20:38 README.md
      -rw-r--r-- 1 root root      250 ago 31 20:38 load_departments.dump
      drwxr-xr-x 2 root root     4096 ago 31 20:38 images
      -rw-r--r-- 1 root root     4193 ago 31 20:38 employees.sql
      -rw-r--r-- 1 root root     6276 ago 31 20:38 employees_partitioned.sql
      -rw-r--r-- 1 root root     7948 ago 31 20:38 employees_partitioned_5.1.sql
      -rw-r--r-- 1 root root     1090 ago 31 20:38 load_dept_manager.dump
      -rw-r--r-- 1 root root 14159880 ago 31 20:38 load_dept_emp.dump
      -rw-r--r-- 1 root root 17722832 ago 31 20:38 load_employees.dump
      -rw-r--r-- 1 root root 39806034 ago 31 20:38 load_salaries1.dump
      -rw-r--r-- 1 root root 39805981 ago 31 20:38 load_salaries2.dump
      -rw-r--r-- 1 root root 39080916 ago 31 20:38 load_salaries3.dump
      -rw-r--r-- 1 root root     4568 ago 31 20:38 objects.sql
      -rw-r--r-- 1 root root 21708736 ago 31 20:38 load_titles.dump
      -rw-r--r-- 1 root root     4882 ago 31 20:38 test_employees_sha.sql
      -rw-r--r-- 1 root root     4878 ago 31 20:38 test_employees_md5.sql
      -rw-r--r-- 1 root root     1800 ago 31 20:38 sql_test.sh
      -rw-r--r-- 1 root root      272 ago 31 20:38 show_elapsed.sql
      drwxr-xr-x 2 root root     4096 ago 31 20:38 sakila
      (base) heron@acerubuntu:~/docker-bigdata$ 


      # reiniciando os containers ( serviços ) 

      (base) heron@acerubuntu:~/docker-bigdata$ docker ps
      CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
      (base) heron@acerubuntu:~/docker-bigdata$ docker-compose start
      Starting namenode                  ... done
      Starting datanode                  ... done
      Starting hive-metastore-postgresql ... done
      Starting hive-metastore            ... done
      Starting hive-server               ... done
      Starting database                  ... done
      Starting zookeeper                 ... done
      Starting hbase-master              ... done
      Starting spark                     ... done
      (base) heron@acerubuntu:~/docker-bigdata$ docker ps
      CONTAINER ID   IMAGE                    COMMAND                  CREATED      STATUS                             PORTS                                                                                                                NAMES
      0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   8 days ago   Up 15 seconds                      0.0.0.0:10000->10000/tcp, :::10000->10000/tcp, 10002/tcp                                                             hive-server
      7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   8 days ago   Up 16 seconds                      10000/tcp, 0.0.0.0:9083->9083/tcp, :::9083->9083/tcp, 10002/tcp                                                      hive_metastore
      cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   8 days ago   Up 16 seconds                      5432/tcp                                                                                                             hive-metastore-postgresql
      4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   8 days ago   Up 16 seconds (health: starting)   0.0.0.0:50075->50075/tcp, :::50075->50075/tcp                                                                        datanode
      fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   8 days ago   Up 16 seconds                      16000/tcp, 0.0.0.0:16010->16010/tcp, :::16010->16010/tcp                                                             hbase-master
      3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   8 days ago   Up 17 seconds (health: starting)   0.0.0.0:50070->50070/tcp, :::50070->50070/tcp                                                                        namenode
      aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   8 days ago   Up 17 seconds                      22/tcp, 2888/tcp, 3888/tcp, 0.0.0.0:2181->2181/tcp, :::2181->2181/tcp                                                zookeeper
      5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   8 days ago   Up 17 seconds                      0.0.0.0:4040-4043->4040-4043/tcp, :::4040-4043->4040-4043/tcp, 0.0.0.0:8889->8889/tcp, :::8889->8889/tcp, 8899/tcp   spark
      13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   8 days ago   Up 17 seconds                      33060/tcp, 0.0.0.0:33061->3306/tcp, :::33061->3306/tcp                                                               database
      (base) heron@acerubuntu:~/docker-bigdata$ 


      # entrando no container database 

      (base) heron@acerubuntu:~/docker-bigdata$ docker exec -it database bash
      root@database:/# 


      # copia o diretorio/arquivos locais para o container database

      (base) heron@acerubuntu:~/docker-bigdata$ docker cp input/exercises-data/db-sql/ database:/
      (base) heron@acerubuntu:~/docker-bigdata$ 


      # verificacao no container que os arquivos foram copiados e transferidos 

      (base) heron@acerubuntu:~/docker-bigdata$ docker exec -it database bash
      root@database:/# ls /
      bin  boot  data  db-sql  dev  docker-entrypoint-initdb.d  entrypoint.sh  etc  home  lib  lib64  media  mnt  opt  proc  root  run  sbin srv  sys  tmp  usr  var
      root@database:/# ls /db-sql
      Changelog      employees_partitioned.sql      load_departments.dump   load_employees.dump  load_salaries3.dump sakila        test_employees_md5.sql
      README.md      employees_partitioned_5.1.sql  load_dept_emp.dump      load_salaries1.dump  load_titles.dump show_elapsed.sql  test_employees_sha.sql
      employees.sql  images               load_dept_manager.dump  load_salaries2.dump  objects.sql    sql_test.sh
      root@database:/# 



      # para acessar o servidor mysql , utilizar o comando abaixo 

      root@database:/# 
      root@database:/# mysql -h localhost -u root -psecret


      mysql> show databases;
      +--------------------+
      | Database           |
      +--------------------+
      | information_schema |
      | employees          |
      | hue                |
      | mysql              |
      | performance_schema |
      | sys                |
      +--------------------+
      6 rows in set (0.10 sec)


      # comando para copiar os arquivos para o container database 

      $ docker cp input/exercises-data/db-sql/ database:/



2. Acessar o contêiner database


   $ docker exec -it database bash



3. Instalar Banco de Dados de testes

Diretório /db-sql - BD employees (Já existe)
  $ cd /db-sql  

  $ mysql -psecret < employees.sql



# para criar o banco de dados sakila executar os comandos abaixo 

Diretório /db-sql/sakila - BD sakila
$ cd /db-sql/sakila/

$ mysql -psecret < sakila-mv-schema.sql
$ mysql -psecret < sakila-mv-data.sql


####

root@database:/# cd /db-sql/sakila/
root@database:/db-sql/sakila#  ls
README.md  insert_rental.sql  sakila-mv-data.sql  sakila-mv-schema.sql
root@database:/db-sql/sakila# 


# executando a criação dos objetos do banco sakila 

root@database:/db-sql/sakila# mysql -psecret < sakila-mv-schema.sql
mysql: [Warning] Using a password on the command line interface can be insecure.
root@database:/db-sql/sakila# 


# copiando os dados , executando a carga de dados no banco sakila 
root@database:/db-sql/sakila# mysql -psecret < sakila-mv-data.sql
mysql: [Warning] Using a password on the command line interface can be insecure.
root@database:/db-sql/sakila#



# verificar se foram carregados, entrar no mysql e verificar os databases 

root@database:/db-sql/sakila# mysql -h localhost -u root -psecret
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 6
Server version: 5.7.29 MySQL Community Server (GPL)

Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> 


mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| employees          |
| hue                |
| mysql              |
| performance_schema |
| sakila             |
| sys                |
+--------------------+
7 rows in set (0.00 sec)


# usar o db sakila 


mysql> use sakila;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

1
mysql> show tables;
+----------------------------+
| Tables_in_sakila           |
+----------------------------+
| actor                      |
| actor_info                 |
| address                    |
| category                   |
| city                       |
| country                    |
| customer                   |
| customer_list              |
| film                       |
| film_actor                 |
| film_category              |
| film_list                  |
| film_text                  |
| inventory                  |
| language                   |
| nicer_but_slower_film_list |
| payment                    |
| rental                     |
| sales_by_film_category     |
| sales_by_store             |
| staff                      |
| staff_list                 |
| store                      |
+----------------------------+
23 rows in set (0.00 sec)


mysql> select * from city limit 10;
+---------+--------------------+------------+---------------------+
| city_id | city               | country_id | last_update         |
+---------+--------------------+------------+---------------------+
|       1 | A Corua (La Corua) |         87 | 2006-02-15 04:45:25 |
|       2 | Abha               |         82 | 2006-02-15 04:45:25 |
|       3 | Abu Dhabi          |        101 | 2006-02-15 04:45:25 |
|       4 | Acua               |         60 | 2006-02-15 04:45:25 |
|       5 | Adana              |         97 | 2006-02-15 04:45:25 |
|       6 | Addis Abeba        |         31 | 2006-02-15 04:45:25 |
|       7 | Aden               |        107 | 2006-02-15 04:45:25 |
|       8 | Adoni              |         44 | 2006-02-15 04:45:25 |
|       9 | Ahmadnagar         |         44 | 2006-02-15 04:45:25 |
|      10 | Akishima           |         50 | 2006-02-15 04:45:25 |
+---------+--------------------+------------+---------------------+
10 rows in set (0.00 sec)



4. Clicar no botão de Enviar Tarefa, e enviar o texto: ok




########################################
EXERCICIOS - AULA 07 - Exercícios - Pesquisa e Criação de Tabelas
########################################


# acionar o container do cluster, para isso é necessario estar dentro da pasta ao qual estao alocados o arquivo docker

(base) heron@acerubuntu:~$ ls -ltr
total 68
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Videos
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Templates
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Public
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Music
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Documents
drwxrwxr-x  3 heron heron 4096 fev 14  2021 opt
drwxrwxr-x  2 heron heron 4096 fev 14  2021 bin
-rw-rw-r--  1 heron heron   26 fev 15  2021 meu_arquivo.txt
-rw-rw-r--  1 heron heron    0 fev 19  2021 ameu_arquivo.txt
-rw-rw-r--  1 heron heron   76 fev 21  2021 vim_basico.txt
drwxrwxr-x 28 heron heron 4096 jun  1 14:03 anaconda3
drwxrwxr-x  3 heron heron 4096 jun  2 11:54 PycharmProjects
drwxr-xr-x  2 heron heron 4096 jun  2 12:29 Downloads
drwxr-xr-x  8 heron heron 4096 jun  5 13:12 snap
drwxrwxr-x  4 heron heron 4096 ago 29 09:58 DataEngineer
drwxr-xr-x  2 heron heron 4096 ago 29 11:01 Pictures
drwxrwxr-x  5 heron heron 4096 ago 30 21:21 docker-bigdata
drwxr-xr-x  3 heron heron 4096 ago 31 20:19 Desktop


(base) heron@acerubuntu:~$ cd docker-bigdata/
(base) heron@acerubuntu:~/docker-bigdata$


# verificar os containers ativos 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ 


para verificar todos os containers , status, utilize o comando abaixo 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   21 hours ago   Exited (137) 21 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   21 hours ago   Exited (143) 21 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   21 hours ago   Exited (0) 21 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   21 hours ago   Exited (137) 21 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   21 hours ago   Exited (137) 21 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   21 hours ago   Exited (0) 21 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ 

podemos verificar que todos os containers ( serviços ) estao em Exited.

nao existe containers ativos, com isso devemos ativar o cluster 

-- ativar o cluster bigdata utilizand o comando abaixo , utilizando o parametro -d para realizar em background a incializacao
   do contrario, vai ficar aparecendo um log enorme até o cluster estar ativo.

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d


(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED      STATUS                        PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   6 days ago   Exited (137) 16 minutes ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   6 days ago   Exited (143) 16 minutes ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   6 days ago   Exited (0) 16 minutes ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   6 days ago   Exited (0) 2 hours ago                  hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   6 days ago   Exited (137) 16 minutes ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   6 days ago   Exited (137) 16 minutes ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   6 days ago   Exited (0) 16 minutes ago               database
(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d
Starting namenode  ... done
Starting database     ... done
Starting spark        ... done
Starting zookeeper    ... done
Starting hbase-master ... done
Starting datanode     ... done
Starting hive-metastore-postgresql ... done
Starting hive_metastore            ... done
Starting hive-server               ... done
(base) heron@acerubuntu:~/docker-bigdata$ 



# o sqoop esta no container namenode 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE                    COMMAND                  CREATED      STATUS                    PORTS                                                                                                                NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   8 days ago   Up 46 minutes             0.0.0.0:10000->10000/tcp, :::10000->10000/tcp, 10002/tcp                                                             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   8 days ago   Up 46 minutes             10000/tcp, 0.0.0.0:9083->9083/tcp, :::9083->9083/tcp, 10002/tcp                                                      hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   8 days ago   Up 46 minutes             5432/tcp                                                                                                             hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   8 days ago   Up 46 minutes (healthy)   0.0.0.0:50075->50075/tcp, :::50075->50075/tcp                                                                        datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   8 days ago   Up 46 minutes             16000/tcp, 0.0.0.0:16010->16010/tcp, :::16010->16010/tcp                                                             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   8 days ago   Up 46 minutes (healthy)   0.0.0.0:50070->50070/tcp, :::50070->50070/tcp                                                                        namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   8 days ago   Up 46 minutes             22/tcp, 2888/tcp, 3888/tcp, 0.0.0.0:2181->2181/tcp, :::2181->2181/tcp                                                zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   8 days ago   Up 46 minutes             0.0.0.0:4040-4043->4040-4043/tcp, :::4040-4043->4040-4043/tcp, 0.0.0.0:8889->8889/tcp, :::8889->8889/tcp, 8899/tcp   spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   8 days ago   Up 46 minutes             33060/tcp, 0.0.0.0:33061->3306/tcp, :::33061->3306/tcp                                                               database
(base) heron@acerubuntu:~/docker-bigdata$ 


# verificar versao do sqoop 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash

root@namenode:/# sqoop version
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 13:42:44 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
Sqoop 1.4.7
git commit id 2328971411f57f0cb683dfb79d19d4d19d185dd8
Compiled by maugli on Thu Dec 21 15:59:58 STD 2017
root@namenode:/# 


root@namenode:/# sqoop help   
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 13:44:25 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
usage: sqoop COMMAND [ARGS]

Available commands:
  codegen            Generate code to interact with database records
  create-hive-table  Import a table definition into Hive
  eval               Evaluate a SQL statement and display the results
  export             Export an HDFS directory to a database table
  help               List available commands
  import             Import a table from a database to HDFS
  import-all-tables  Import tables from a database to HDFS
  import-mainframe   Import datasets from a mainframe server to HDFS
  job                Work with saved jobs
  list-databases     List available databases on a server
  list-tables        List available tables in a database
  merge              Merge results of incremental imports
  metastore          Run a standalone Sqoop metastore
  version            Display version information

See 'sqoop help COMMAND' for information on a specific command.
root@namenode:/# 



Todos os comandos precisam ser executados pelo Sqoop.





1. Mostrar todos os databases


root@namenode:/# sqoop list-databases --connect jdbc:mysql://database --username root --password secret

Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 14:09:59 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/08 14:09:59 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/08 14:09:59 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Wed Sep 08 14:09:59 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.

information_schema
employees
hue
mysql
performance_schema
sakila
sys
root@namenode:/# 






2. Mostrar todas as tabelas do bd employees


root@namenode:/# sqoop list-tables --connect jdbc:mysql://database/employees --username root --password secret

Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 14:12:44 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/08 14:12:44 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/08 14:12:44 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Wed Sep 08 14:12:44 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
current_dept_emp
departments
dept_emp
dept_emp_latest_date
dept_manager
employees
employees_2
titles
root@namenode:/# 





3. Inserir os valores ('d010', 'BI') na tabela departments do bd employees

# primeiro vamos listar os registros da tabela departments 

root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "select * from departments"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 14:17:29 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/08 14:17:29 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/08 14:17:30 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Wed Sep 08 14:17:30 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
-------------------------------
| dept_no | dept_name            | 
-------------------------------
| d009 | Customer Service     | 
| d005 | Development          | 
| d002 | Finance              | 
| d003 | Human Resources      | 
| d001 | Marketing            | 
| d004 | Production           | 
| d006 | Quality Management   | 
| d008 | Research             | 
| d007 | Sales                | 
-------------------------------
root@namenode:/# 


root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "insert into departments values('d010','BI')"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 14:19:57 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/08 14:19:57 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/08 14:19:57 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Wed Sep 08 14:19:57 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
21/09/08 14:19:57 INFO tool.EvalSqlTool: 1 row(s) updated.
root@namenode:/# 









4. Pesquisar todos os registros da tabela departments

root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "select * from departments"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 14:20:50 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/08 14:20:50 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/08 14:20:50 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Wed Sep 08 14:20:51 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
-------------------------------
| dept_no | dept_name            | 
-------------------------------
| d010 | BI                   | 
| d009 | Customer Service     | 
| d005 | Development          | 
| d002 | Finance              | 
| d003 | Human Resources      | 
| d001 | Marketing            | 
| d004 | Production           | 
| d006 | Quality Management   | 
| d008 | Research             | 
| d007 | Sales                | 
-------------------------------
root@namenode:/# 





5. Criar a tabela benefits(cod int(2)  AUTO_INCREMENT PRIMARY KEY, name varchar(30)) no bd employees



root@namenode:/# 
root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "create table benefits(cod int(2) AUTO_INCREMENT PRIMARY KEY, name varchar(30))"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 14:27:33 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/08 14:27:33 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/08 14:27:33 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Wed Sep 08 14:27:33 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
21/09/08 14:27:34 INFO tool.EvalSqlTool: 0 row(s) updated.
root@namenode:/# 



# verificar se existe a tabela criada 

root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "select * from benefits"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 14:28:30 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/08 14:28:30 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/08 14:28:30 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Wed Sep 08 14:28:30 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
-----------------------------
| cod | name                 | 
-----------------------------
-----------------------------
root@namenode:/# 




6. Inserir os valores (null,'food vale') na tabela benefits

root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "insert into  benefits values(null,'food vale')"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 14:41:25 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/08 14:41:25 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/08 14:41:25 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Wed Sep 08 14:41:25 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
21/09/08 14:41:25 INFO tool.EvalSqlTool: 1 row(s) updated.
root@namenode:/# 








7. Pesquisar todos os registros da tabela benefits


root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "select * from benefits"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 14:42:10 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/08 14:42:10 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/08 14:42:10 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Wed Sep 08 14:42:10 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
-----------------------------
| cod | name                 | 
-----------------------------
| 1  | food vale            | 
-----------------------------
root@namenode:/# 







8. Clicar no botão de Enviar Tarefa, e enviar o texto: ok






########################################
EXERCICIOS - AULA 08 - Exercícios - Sqoop – Importação BD Employees
########################################


# acionar o container do cluster, para isso é necessario estar dentro da pasta ao qual estao alocados o arquivo docker

(base) heron@acerubuntu:~$ ls -ltr
total 68
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Videos
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Templates
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Public
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Music
drwxr-xr-x  2 heron heron 4096 dez 26  2020 Documents
drwxrwxr-x  3 heron heron 4096 fev 14  2021 opt
drwxrwxr-x  2 heron heron 4096 fev 14  2021 bin
-rw-rw-r--  1 heron heron   26 fev 15  2021 meu_arquivo.txt
-rw-rw-r--  1 heron heron    0 fev 19  2021 ameu_arquivo.txt
-rw-rw-r--  1 heron heron   76 fev 21  2021 vim_basico.txt
drwxrwxr-x 28 heron heron 4096 jun  1 14:03 anaconda3
drwxrwxr-x  3 heron heron 4096 jun  2 11:54 PycharmProjects
drwxr-xr-x  2 heron heron 4096 jun  2 12:29 Downloads
drwxr-xr-x  8 heron heron 4096 jun  5 13:12 snap
drwxrwxr-x  4 heron heron 4096 ago 29 09:58 DataEngineer
drwxr-xr-x  2 heron heron 4096 ago 29 11:01 Pictures
drwxrwxr-x  5 heron heron 4096 ago 30 21:21 docker-bigdata
drwxr-xr-x  3 heron heron 4096 ago 31 20:19 Desktop


(base) heron@acerubuntu:~$ cd docker-bigdata/
(base) heron@acerubuntu:~/docker-bigdata$


# verificar os containers ativos 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ 


para verificar todos os containers , status, utilize o comando abaixo 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED        STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   21 hours ago   Exited (137) 21 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   21 hours ago   Exited (143) 21 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   21 hours ago   Exited (0) 21 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   21 hours ago   Exited (137) 21 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   21 hours ago   Exited (137) 21 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   21 hours ago   Exited (137) 21 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   21 hours ago   Exited (0) 21 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ 

podemos verificar que todos os containers ( serviços ) estao em Exited.

nao existe containers ativos, com isso devemos ativar o cluster 

-- ativar o cluster bigdata utilizand o comando abaixo , utilizando o parametro -d para realizar em background a incializacao
   do contrario, vai ficar aparecendo um log enorme até o cluster estar ativo.

(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d


(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED      STATUS                        PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   6 days ago   Exited (137) 16 minutes ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   6 days ago   Exited (143) 16 minutes ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   6 days ago   Exited (0) 16 minutes ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   6 days ago   Exited (0) 2 hours ago                  hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   6 days ago   Exited (137) 15 minutes ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   6 days ago   Exited (137) 16 minutes ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   6 days ago   Exited (137) 16 minutes ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   6 days ago   Exited (0) 16 minutes ago               database


(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d
Starting namenode  ... done
Starting database     ... done
Starting spark        ... done
Starting zookeeper    ... done
Starting hbase-master ... done
Starting datanode     ... done
Starting hive-metastore-postgresql ... done
Starting hive_metastore            ... done
Starting hive-server               ... done
(base) heron@acerubuntu:~/docker-bigdata$ 



# o sqoop esta no container namenode 



# verificar versao do sqoop 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash

root@namenode:/# sqoop version
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 13:42:44 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
Sqoop 1.4.7
git commit id 2328971411f57f0cb683dfb79d19d4d19d185dd8
Compiled by maugli on Thu Dec 21 15:59:58 STD 2017
root@namenode:/# 


root@namenode:/# sqoop help   
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/08 13:44:25 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
usage: sqoop COMMAND [ARGS]

Available commands:
  codegen            Generate code to interact with database records
  create-hive-table  Import a table definition into Hive
  eval               Evaluate a SQL statement and display the results
  export             Export an HDFS directory to a database table
  help               List available commands
  import             Import a table from a database to HDFS
  import-all-tables  Import tables from a database to HDFS
  import-mainframe   Import datasets from a mainframe server to HDFS
  job                Work with saved jobs
  list-databases     List available databases on a server
  list-tables        List available tables in a database
  merge              Merge results of incremental imports
  metastore          Run a standalone Sqoop metastore
  version            Display version information

See 'sqoop help COMMAND' for information on a specific command.
root@namenode:/# 



Todos os comandos precisam ser executados pelo Sqoop.
  


Sqoop - Importação BD Employees

1. Pesquisar os 10 primeiros registros da tabela employees do banco de dados employees

# entrar no namenode para poder executar o sqoop 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash
root@namenode:/#


sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "select * from employees limit 10"

root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "select * from employees limit 10"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/09 10:46:48 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/09 10:46:48 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/09 10:46:48 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Thu Sep 09 10:46:49 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
---------------------------------------------------------------------------------
| emp_no      | birth_date | first_name     | last_name        | gender | hire_date  | 
---------------------------------------------------------------------------------
| 10001       | 1953-09-02 | Georgi         | Facello          | M | 1986-06-26 | 
| 10002       | 1964-06-02 | Bezalel        | Simmel           | F | 1985-11-21 | 
| 10003       | 1959-12-03 | Parto          | Bamford          | M | 1986-08-28 | 
| 10004       | 1954-05-01 | Chirstian      | Koblick          | M | 1986-12-01 | 
| 10005       | 1955-01-21 | Kyoichi        | Maliniak         | M | 1989-09-12 | 
| 10006       | 1953-04-20 | Anneke         | Preusig          | F | 1989-06-02 | 
| 10007       | 1957-05-23 | Tzvetan        | Zielinski        | F | 1989-02-10 | 
| 10008       | 1958-02-19 | Saniya         | Kalloufi         | M | 1994-09-15 | 
| 10009       | 1952-04-19 | Sumant         | Peac             | F | 1985-02-18 | 
| 10010       | 1963-06-01 | Duangkaew      | Piveteau         | F | 1989-08-24 | 
---------------------------------------------------------------------------------
root@namenode:/# 




2. Realizar as importações referentes a tabela employees e para validar cada questão,  é necessário visualizar no HDFS*




Importar a tabela employees, no warehouse  /user/hive/warehouse/db_test_a


root@namenode:/# 
root@namenode:/# sqoop import --table employees --connect jdbc:mysql://database/employees --username root --password secret --warehouse-dir /user/hive/warehouse/db_test_a


21/09/09 10:54:55 INFO mapreduce.Job: Job job_local1765342530_0001 completed successfully
21/09/09 10:54:55 INFO mapreduce.Job: Counters: 20
   File System Counters
      FILE: Number of bytes read=851136406
      FILE: Number of bytes written=859653708
      FILE: Number of read operations=0
      FILE: Number of large read operations=0
      FILE: Number of write operations=0
      HDFS: Number of bytes read=0
      HDFS: Number of bytes written=34653598
      HDFS: Number of read operations=34
      HDFS: Number of large read operations=0
      HDFS: Number of write operations=24
   Map-Reduce Framework
      Map input records=300024
      Map output records=300024
      Input split bytes=464
      Spilled Records=0
      Failed Shuffles=0
      Merged Map outputs=0
      GC time elapsed (ms)=18
      Total committed heap usage (bytes)=1329594368
   File Input Format Counters 
      Bytes Read=0
   File Output Format Counters 
      Bytes Written=13821993
21/09/09 10:54:55 INFO mapreduce.ImportJobBase: Transferred 33.0482 MB in 8.9013 seconds (3.7127 MB/sec)
21/09/09 10:54:55 INFO mapreduce.ImportJobBase: Retrieved 300024 records.
root@namenode:/# 


# validar se foi criado o arquivo no hdfs 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash
root@namenode:/# hdfs dfs -ls -R /user/hive/warehouse/
drwxr-xr-x   - root supergroup          0 2021-09-09 10:54 /user/hive/warehouse/db_test_a
drwxr-xr-x   - root supergroup          0 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees
-rw-r--r--   3 root supergroup          0 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees/_SUCCESS
-rw-r--r--   3 root supergroup    4548041 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees/part-m-00000
-rw-r--r--   3 root supergroup    2550561 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees/part-m-00001
-rw-r--r--   3 root supergroup    2086360 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees/part-m-00002
-rw-r--r--   3 root supergroup    4637031 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees/part-m-00003


root@namenode:/# hdfs dfs -cat /user/hive/warehouse/db_test_a/employees/part-m-00000 | head -n 4
10001,1953-09-02,Georgi,Facello,M,1986-06-26
10002,1964-06-02,Bezalel,Simmel,F,1985-11-21
10003,1959-12-03,Parto,Bamford,M,1986-08-28
10004,1954-05-01,Chirstian,Koblick,M,1986-12-01
cat: Unable to write to output stream.
root@namenode:/# 

# analisar o tamanho dos arqquivos/particoes de arquivos 

root@namenode:/# hdfs dfs -ls -h /user/hive/warehouse/db_test_a/employees/                        
Found 5 items
-rw-r--r--   3 root supergroup          0 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees/_SUCCESS
-rw-r--r--   3 root supergroup      4.3 M 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees/part-m-00000
-rw-r--r--   3 root supergroup      2.4 M 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees/part-m-00001
-rw-r--r--   3 root supergroup      2.0 M 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees/part-m-00002
-rw-r--r--   3 root supergroup      4.4 M 2021-09-09 10:54 /user/hive/warehouse/db_test_a/employees/part-m-00003
root@namenode:/# 


Importar todos os funcionários do gênero masculino, no warehouse  /user/hive/warehouse/db_test_b

root@namenode:/# 
root@namenode:/# sqoop import --table employees --connect jdbc:mysql://database/employees --username root --password secret --where "gender='M'" --warehouse-dir /user/hive/warehouse/db_test_b

21/09/09 11:09:46 INFO mapreduce.Job: Job job_local395345241_0001 completed successfully
21/09/09 11:09:46 INFO mapreduce.Job: Counters: 20
   File System Counters
      FILE: Number of bytes read=851136406
      FILE: Number of bytes written=859647708
      FILE: Number of read operations=0
      FILE: Number of large read operations=0
      FILE: Number of write operations=0
      HDFS: Number of bytes read=0
      HDFS: Number of bytes written=20777593
      HDFS: Number of read operations=34
      HDFS: Number of large read operations=0
      HDFS: Number of write operations=24
   Map-Reduce Framework
      Map input records=179973
      Map output records=179973
      Input split bytes=464
      Spilled Records=0
      Failed Shuffles=0
      Merged Map outputs=0
      GC time elapsed (ms)=12
      Total committed heap usage (bytes)=1504182272
   File Input Format Counters 
      Bytes Read=0
   File Output Format Counters 
      Bytes Written=8292472
21/09/09 11:09:46 INFO mapreduce.ImportJobBase: Transferred 19.8151 MB in 7.4262 seconds (2.6683 MB/sec)
21/09/09 11:09:46 INFO mapreduce.ImportJobBase: Retrieved 179973 records.
root@namenode:/# 



root@namenode:/# hdfs dfs -ls -h /user/hive/warehouse/db_test_b/employees/
Found 5 items
-rw-r--r--   3 root supergroup          0 2021-09-09 11:09 /user/hive/warehouse/db_test_b/employees/_SUCCESS
-rw-r--r--   3 root supergroup      2.6 M 2021-09-09 11:09 /user/hive/warehouse/db_test_b/employees/part-m-00000
-rw-r--r--   3 root supergroup      1.5 M 2021-09-09 11:09 /user/hive/warehouse/db_test_b/employees/part-m-00001
-rw-r--r--   3 root supergroup      1.2 M 2021-09-09 11:09 /user/hive/warehouse/db_test_b/employees/part-m-00002
-rw-r--r--   3 root supergroup      2.7 M 2021-09-09 11:09 /user/hive/warehouse/db_test_b/employees/part-m-00003
root@namenode:/# 



importar o primeiro e o último nome dos funcionários com os campos separados por tabulação, no warehouse  /user/hive/warehouse/db_test_c


root@namenode:/# sqoop import --table employees --connect jdbc:mysql://database/employees --username root --password secret --columns "first_name, last_name" --fields-terminated-by '\t' --warehouse-dir /user/hive/warehouse/db_test_c


21/09/09 11:16:50 INFO mapreduce.Job: Job job_local2074594606_0001 completed successfully
21/09/09 11:16:50 INFO mapreduce.Job: Counters: 20
   File System Counters
      FILE: Number of bytes read=851121726
      FILE: Number of bytes written=859638572
      FILE: Number of read operations=0
      FILE: Number of large read operations=0
      FILE: Number of write operations=0
      HDFS: Number of bytes read=0
      HDFS: Number of bytes written=11605587
      HDFS: Number of read operations=34
      HDFS: Number of large read operations=0
      HDFS: Number of write operations=24
   Map-Reduce Framework
      Map input records=300024
      Map output records=300024
      Input split bytes=464
      Spilled Records=0
      Failed Shuffles=0
      Merged Map outputs=0
      GC time elapsed (ms)=5
      Total committed heap usage (bytes)=1395654656
   File Input Format Counters 
      Bytes Read=0
   File Output Format Counters 
      Bytes Written=4611248
21/09/09 11:16:50 INFO mapreduce.ImportJobBase: Transferred 11.068 MB in 6.5583 seconds (1.6876 MB/sec)
21/09/09 11:16:50 INFO mapreduce.ImportJobBase: Retrieved 300024 records.
root@namenode:/# 


root@namenode:/# hdfs dfs -cat /user/hive/warehouse/db_test_c/employees/part-m-00000 | head -n 4
Georgi   Facello
Bezalel  Simmel
Parto Bamford
Chirstian   Koblick
cat: Unable to write to output stream.
root@namenode:/# 



Importar o primeiro e o último nome dos funcionários com as linhas separadas por “ : ” e salvar no mesmo diretório da questão 2.C

# como o diretorio ja existe se executar o comando abaixo , ira gerar erro , temos 2 opçoes utilizar append ou delete 
root@namenode:/# sqoop import --table employees --connect jdbc:mysql://database/employees --username root --password secret --columns "first_name, last_name" --lines-terminated-by ':' --warehouse-dir /user/hive/warehouse/db_test_c

root@namenode:/# sqoop import --table employees --connect jdbc:mysql://database/employees --username root --password secret --columns "first_name, last_name" --lines-terminated-by ':' --warehouse-dir /user/hive/warehouse/db_test_c -delete-target-dir

root@namenode:/# sqoop import --table employees --connect jdbc:mysql://database/employees --username root --password secret --columns "first_name, last_name" --lines-terminated-by ':' --warehouse-dir /user/hive/warehouse/db_test_c -append-target-dir

21/09/09 11:30:55 INFO mapreduce.Job: Job job_local2077277502_0001 completed successfully
21/09/09 11:30:55 INFO mapreduce.Job: Counters: 20
   File System Counters
      FILE: Number of bytes read=851121726
      FILE: Number of bytes written=859638572
      FILE: Number of read operations=0
      FILE: Number of large read operations=0
      FILE: Number of write operations=0
      HDFS: Number of bytes read=0
      HDFS: Number of bytes written=11605587
      HDFS: Number of read operations=38
      HDFS: Number of large read operations=0
      HDFS: Number of write operations=28
   Map-Reduce Framework
      Map input records=300024
      Map output records=300024
      Input split bytes=464
      Spilled Records=0
      Failed Shuffles=0
      Merged Map outputs=0
      GC time elapsed (ms)=6
      Total committed heap usage (bytes)=1438646272
   File Input Format Counters 
      Bytes Read=0
   File Output Format Counters 
      Bytes Written=4611248
21/09/09 11:30:55 INFO mapreduce.ImportJobBase: Transferred 11.068 MB in 7.7386 seconds (1.4302 MB/sec)
21/09/09 11:30:55 INFO mapreduce.ImportJobBase: Retrieved 300024 records.
root@namenode:/# 


root@namenode:/# hdfs dfs -cat /user/hive/warehouse/db_test_c/employees/part-m-00000 | head -n 4
Georgi,Facello:Bezalel,Simmel:Parto,Bamford:Chirstian,Koblick:Kyoichi,Maliniak:Anneke,Preusig:Tzvetan,Zielinski:Saniya,Kalloufi:Sumant,Peac:Duangkaew,Piveteau:Mary,Sluis:Patricio,Bridgland:Eberhardt,Terkki:Berni,Genin:Guoxiang,Nooteboom:Kazuhito,Cappelletti:Cristinel,Bouloucos:Kazuhide,Peha:Lillian,Haddadi:Mayuko,Warwick:Ramzi,Erde:Shahaf,Famili:Bojan,Montemayor:Suzette,Pettey:Prasadram,Heyers:Yongqiao,Berztiss:Divier,Reistad:Domenick,Tempesti:Otmar,Herbst:Elvis,Demeyer:Karsten,Joslin:Jeong,Reistad:


* Dica para visualizar no HDFS:



$ hdfs dfs -cat /.../db_test/nomeTabela/part-m-00000 | head -n 5





3. Clicar no botão de Enviar Tarefa, e enviar o texto: ok





########################################
EXERCICIOS - AULA 08 - Exercícios - Sqoop - Importação BD Employees- Otimização
########################################

Realizar com uso do MySQL

# acessar o container do banco mysql 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it database bash
root@database:/# 

# acessar o mysql

root@database:/# mysql -h localhost -u root -psecret
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 28
Server version: 5.7.29 MySQL Community Server (GPL)

Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> 



1. Criar a tabela cp_titles_date, contendo a cópia da tabela titles com os campos title e to_date

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| employees          |
| hue                |
| mysql              |
| performance_schema |
| sakila             |
| sys                |
+--------------------+
7 rows in set (0.03 sec)

mysql> use employees;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql> show tables;
+----------------------+
| Tables_in_employees  |
+----------------------+
| benefits             |
| current_dept_emp     |
| departments          |
| dept_emp             |
| dept_emp_latest_date |
| dept_manager         |
| employees            |
| employees_2          |
| titles               |
+----------------------+
9 rows in set (0.00 sec)

mysql> 

mysql> select * from titles limit 10;
+--------+-----------------+------------+------------+
| emp_no | title           | from_date  | to_date    |
+--------+-----------------+------------+------------+
|  10001 | Senior Engineer | 1986-06-26 | 9999-01-01 |
|  10002 | Staff           | 1996-08-03 | 9999-01-01 |
|  10003 | Senior Engineer | 1995-12-03 | 9999-01-01 |
|  10004 | Engineer        | 1986-12-01 | 1995-12-01 |
|  10004 | Senior Engineer | 1995-12-01 | 9999-01-01 |
|  10005 | Senior Staff    | 1996-09-12 | 9999-01-01 |
|  10005 | Staff           | 1989-09-12 | 1996-09-12 |
|  10006 | Senior Engineer | 1990-08-05 | 9999-01-01 |
|  10007 | Senior Staff    | 1996-02-11 | 9999-01-01 |
|  10007 | Staff           | 1989-02-10 | 1996-02-11 |
+--------+-----------------+------------+------------+
10 rows in set (0.01 sec)

mysql> 

mysql> 
mysql> create table cp_titles_date select title, to_date from titles;
Query OK, 443308 rows affected (7.18 sec)
Records: 443308  Duplicates: 0  Warnings: 0

mysql> 




2. Pesquisar os 15 primeiros registros da tabela cp_titles_date

mysql> select * from cp_titles_date limit 15;
+--------------------+------------+
| title              | to_date    |
+--------------------+------------+
| Senior Engineer    | 9999-01-01 |
| Staff              | 9999-01-01 |
| Senior Engineer    | 9999-01-01 |
| Engineer           | 1995-12-01 |
| Senior Engineer    | 9999-01-01 |
| Senior Staff       | 9999-01-01 |
| Staff              | 1996-09-12 |
| Senior Engineer    | 9999-01-01 |
| Senior Staff       | 9999-01-01 |
| Staff              | 1996-02-11 |
| Assistant Engineer | 2000-07-31 |
| Assistant Engineer | 1990-02-18 |
| Engineer           | 1995-02-18 |
| Senior Engineer    | 9999-01-01 |
| Engineer           | 9999-01-01 |
+--------------------+------------+
15 rows in set (0.00 sec)






3. Alterar os registros do campo to_date para null da tabela cp_titles_date, quando o título for igual a Staff


update cp_titles_date set to_date = null where title ='staff';

mysql> update cp_titles_date set to_date = null where title ='staff';
Query OK, 107391 rows affected (1.34 sec)
Rows matched: 107391  Changed: 107391  Warnings: 0

mysql> 

mysql> select * from cp_titles_date limit 15;
+--------------------+------------+
| title              | to_date    |
+--------------------+------------+
| Senior Engineer    | 9999-01-01 |
| Staff              | NULL       |
| Senior Engineer    | 9999-01-01 |
| Engineer           | 1995-12-01 |
| Senior Engineer    | 9999-01-01 |
| Senior Staff       | 9999-01-01 |
| Staff              | NULL       |
| Senior Engineer    | 9999-01-01 |
| Senior Staff       | 9999-01-01 |
| Staff              | NULL       |
| Assistant Engineer | 2000-07-31 |
| Assistant Engineer | 1990-02-18 |
| Engineer           | 1995-02-18 |
| Senior Engineer    | 9999-01-01 |
| Engineer           | 9999-01-01 |
+--------------------+------------+
15 rows in set (0.00 sec)

mysql> 





Realizar com uso do Sqoop - Importações no warehouse /user/hive/warehouse/db_test_<numero_questao> e visualizar no HDFS


# utilizar o namenode 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash
root@namenode:/# 





4. Importar a tabela titles com 8 mapeadores no formato parquet


sqoop import --table titles --connect jdbc:mysql://database/employees --username root --password secret -m 8 --as-parquetfile --warehouse-dir /user/hive/warehouse/db_test2_4

# verificando no hdfs 

root@namenode:/# hdfs dfs -ls -h /user/hive/warehouse/db_test2_4          
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-09-09 12:33 /user/hive/warehouse/db_test2_4/titles
root@namenode:/# hdfs dfs -ls -h /user/hive/warehouse/db_test2_4/titles
Found 8 items
drwxr-xr-x   - root supergroup          0 2021-09-09 12:33 /user/hive/warehouse/db_test2_4/titles/.metadata
drwxr-xr-x   - root supergroup          0 2021-09-09 12:33 /user/hive/warehouse/db_test2_4/titles/.signals
-rw-r--r--   3 root supergroup    429.3 K 2021-09-09 12:33 /user/hive/warehouse/db_test2_4/titles/1b5fa8d0-23bd-498b-8377-a0f1193d5874.parquet
-rw-r--r--   3 root supergroup    581.7 K 2021-09-09 12:33 /user/hive/warehouse/db_test2_4/titles/40b02733-0ce5-47df-9cd4-ef6fe279e628.parquet
-rw-r--r--   3 root supergroup    433.1 K 2021-09-09 12:33 /user/hive/warehouse/db_test2_4/titles/b801f6f8-7e46-4be7-b2c0-aa860d540318.parquet
-rw-r--r--   3 root supergroup    642.2 K 2021-09-09 12:33 /user/hive/warehouse/db_test2_4/titles/bfa30f00-6bf1-4dc1-a2fa-d030c4e18a17.parquet
-rw-r--r--   3 root supergroup    640.9 K 2021-09-09 12:33 /user/hive/warehouse/db_test2_4/titles/cc0eec75-8621-42a5-bdd9-0d35f5fff4cd.parquet
-rw-r--r--   3 root supergroup    491.0 K 2021-09-09 12:33 /user/hive/warehouse/db_test2_4/titles/fd1e619c-bbb5-4d7d-bfb3-d2c94baf4fad.parquet
root@namenode:/# 




5. Importar a tabela titles com 8 mapeadores no formato parquet e compressão snappy


sqoop import --table titles --connect jdbc:mysql://database/employees --username root --password secret -m 8 --as-parquetfile --warehouse-dir /user/hive/warehouse/db_test2_5 --compress --compression-codec org.apache.hadoop.io.compress.SnappyCodec


21/09/09 12:55:49 INFO mapreduce.Job: Job job_local271747639_0001 completed successfully
21/09/09 12:55:49 INFO mapreduce.Job: Counters: 20
   File System Counters
      FILE: Number of bytes read=1702282404
      FILE: Number of bytes written=1719303144
      FILE: Number of read operations=0
      FILE: Number of large read operations=0
      FILE: Number of write operations=0
      HDFS: Number of bytes read=283672
      HDFS: Number of bytes written=14980769
      HDFS: Number of read operations=2036
      HDFS: Number of large read operations=0
      HDFS: Number of write operations=422
   Map-Reduce Framework
      Map input records=443308
      Map output records=443308
      Input split bytes=926
      Spilled Records=0
      Failed Shuffles=0
      Merged Map outputs=0
      GC time elapsed (ms)=60
      Total committed heap usage (bytes)=2895118336
   File Input Format Counters 
      Bytes Read=0
   File Output Format Counters 
      Bytes Written=0
21/09/09 12:55:49 INFO mapreduce.ImportJobBase: Transferred 14.2868 MB in 16.9748 seconds (861.845 KB/sec)
21/09/09 12:55:49 INFO mapreduce.ImportJobBase: Retrieved 443308 records.


root@namenode:/# hdfs dfs -ls -h /user/hive/warehouse/db_test2_5/titles
Found 8 items
drwxr-xr-x   - root supergroup          0 2021-09-09 12:55 /user/hive/warehouse/db_test2_5/titles/.metadata
drwxr-xr-x   - root supergroup          0 2021-09-09 12:55 /user/hive/warehouse/db_test2_5/titles/.signals
-rw-r--r--   3 root supergroup    433.1 K 2021-09-09 12:55 /user/hive/warehouse/db_test2_5/titles/29772fb1-d2d9-4054-9a06-a7692567f33c.parquet
-rw-r--r--   3 root supergroup    642.2 K 2021-09-09 12:55 /user/hive/warehouse/db_test2_5/titles/4d851f9c-9988-47c8-8188-6c05f4455932.parquet
-rw-r--r--   3 root supergroup    640.9 K 2021-09-09 12:55 /user/hive/warehouse/db_test2_5/titles/643f9a4a-0480-49b2-bf76-f8ecced1ec84.parquet
-rw-r--r--   3 root supergroup    581.7 K 2021-09-09 12:55 /user/hive/warehouse/db_test2_5/titles/6b2e346c-e608-4d6d-8613-d0e4934455a5.parquet
-rw-r--r--   3 root supergroup    429.3 K 2021-09-09 12:55 /user/hive/warehouse/db_test2_5/titles/6f9b43fe-5e9b-40c6-94a2-9d4f7a72af47.parquet
-rw-r--r--   3 root supergroup    491.0 K 2021-09-09 12:55 /user/hive/warehouse/db_test2_5/titles/f62c9a63-fd7d-45a2-91ff-652036f7994b.parquet
root@namenode:/# 




6. Importar a tabela cp_titles_date com 4 mapeadores (erro)

root@namenode:/# sqoop import --table cp_titles_date --connect jdbc:mysql://database/employees --username root --password secret -m 4 --warehouse-dir /user/hive/warehouse/db_test2_6

21/09/09 13:06:48 ERROR tool.ImportTool: Import failed: No primary key could be found for table cp_titles_date. Please specify one with --split-by or perform a sequential import with '-m 1'.
root@namenode:/# 




a. Importar a tabela cp_titles_date com 4 mapeadores divididos pelo campo título no warehouse /user/hive/warehouse/db_test2_title

sqoop import --table cp_titles_date --connect jdbc:mysql://database/employees --username root --password secret -m 4 --warehouse-dir /user/hive/warehouse/db_test2_title --split-by title


Caused by: Generating splits for a textual index column allowed only in case of "-Dorg.apache.sqoop.splitter.allow_text_splitter=true" property passed as a parameter
   at org.apache.sqoop.mapreduce.db.TextSplitter.split(TextSplitter.java:67)
   at org.apache.sqoop.mapreduce.db.DataDrivenDBInputFormat.getSplits(DataDrivenDBInputFormat.java:201)
   ... 23 more

sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --table cp_titles_date --connect jdbc:mysql://database/employees --username root --password secret -m 4 --warehouse-dir /user/hive/warehouse/db_test2_title --split-by title

21/09/09 14:04:05 INFO mapreduce.Job: Job job_local1448928381_0001 completed successfully
21/09/09 14:04:05 INFO mapreduce.Job: Counters: 20
   File System Counters
      FILE: Number of bytes read=1276693572
      FILE: Number of bytes written=1289464782
      FILE: Number of read operations=0
      FILE: Number of large read operations=0
      FILE: Number of write operations=0
      HDFS: Number of bytes read=0
      HDFS: Number of bytes written=23993306
      HDFS: Number of read operations=69
      HDFS: Number of large read operations=0
      HDFS: Number of write operations=48
   Map-Reduce Framework
      Map input records=443308
      Map output records=443308
      Input split bytes=807
      Spilled Records=0
      Failed Shuffles=0
      Merged Map outputs=0
      GC time elapsed (ms)=13
      Total committed heap usage (bytes)=2121269248
   File Input Format Counters 
      Bytes Read=0
   File Output Format Counters 
      Bytes Written=9227831
21/09/09 14:04:05 INFO mapreduce.ImportJobBase: Transferred 22.8818 MB in 8.209 seconds (2.7874 MB/sec)
21/09/09 14:04:05 INFO mapreduce.ImportJobBase: Retrieved 443308 records.


b. Importar a tabela cp_titles_date com 4 mapeadores divididos pelo campo data no warehouse /user/hive/warehouse/db_test2_date


root@namenode:/# sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --table cp_titles_date --connect jdbc:mysql://database/employees --username root --password secret -m 4 --warehouse-dir /user/hive/warehouse/db_test2_date --split-by to_date 


21/09/09 14:10:05 INFO mapreduce.Job: Job job_local1923034547_0001 completed successfully
21/09/09 14:10:05 INFO mapreduce.Job: Counters: 20
   File System Counters
      FILE: Number of bytes read=851123852
      FILE: Number of bytes written=859642012
      FILE: Number of read operations=0
      FILE: Number of large read operations=0
      FILE: Number of write operations=0
      HDFS: Number of bytes read=0
      HDFS: Number of bytes written=16124300
      HDFS: Number of read operations=34
      HDFS: Number of large read operations=0
      HDFS: Number of write operations=24
   Map-Reduce Framework
      Map input records=335917
      Map output records=335917
      Input split bytes=521
      Spilled Records=0
      Failed Shuffles=0
      Merged Map outputs=0
      GC time elapsed (ms)=13
      Total committed heap usage (bytes)=1448607744
   File Input Format Counters 
      Bytes Read=0
   File Output Format Counters 
      Bytes Written=8046530
21/09/09 14:10:05 INFO mapreduce.ImportJobBase: Transferred 15.3773 MB in 8.0425 seconds (1.912 MB/sec)
21/09/09 14:10:05 INFO mapreduce.ImportJobBase: Retrieved 335917 records.
root@namenode:/# 







Qual a diferença dos registros nulos entre as duas importações?

# split feito pelo campo to_date que contem valores null

# ignorou na importacao, todos os registros com to_date null ao qual title=staff

root@namenode:/# hdfs dfs -count -h /user/hive/warehouse/db_test2_date
           2            5              7.7 M /user/hive/warehouse/db_test2_date


root@namenode:/# hdfs dfs -ls -h /user/hive/warehouse/db_test2_date    
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-09-09 14:10 /user/hive/warehouse/db_test2_date/cp_titles_date
root@namenode:/# hdfs dfs -ls -h -R /user/hive/warehouse/db_test2_date
drwxr-xr-x   - root supergroup          0 2021-09-09 14:10 /user/hive/warehouse/db_test2_date/cp_titles_date
-rw-r--r--   3 root supergroup          0 2021-09-09 14:10 /user/hive/warehouse/db_test2_date/cp_titles_date/_SUCCESS
-rw-r--r--   3 root supergroup      2.6 M 2021-09-09 14:10 /user/hive/warehouse/db_test2_date/cp_titles_date/part-m-00000
-rw-r--r--   3 root supergroup          0 2021-09-09 14:10 /user/hive/warehouse/db_test2_date/cp_titles_date/part-m-00001
-rw-r--r--   3 root supergroup          0 2021-09-09 14:10 /user/hive/warehouse/db_test2_date/cp_titles_date/part-m-00002
-rw-r--r--   3 root supergroup      5.1 M 2021-09-09 14:10 /user/hive/warehouse/db_test2_date/cp_titles_date/part-m-00003
root@namenode:/# 


# split feito pelo campo title 

root@namenode:/# hdfs dfs -count -h /user/hive/warehouse/db_test2_title
           2            7              8.8 M /user/hive/warehouse/db_test2_title


root@namenode:/# hdfs dfs -ls -h -R /user/hive/warehouse/db_test2_title
drwxr-xr-x   - root supergroup          0 2021-09-09 14:04 /user/hive/warehouse/db_test2_title/cp_titles_date
-rw-r--r--   3 root supergroup          0 2021-09-09 14:04 /user/hive/warehouse/db_test2_title/cp_titles_date/_SUCCESS
-rw-r--r--   3 root supergroup          0 2021-09-09 14:04 /user/hive/warehouse/db_test2_title/cp_titles_date/part-m-00000
-rw-r--r--   3 root supergroup    443.2 K 2021-09-09 14:04 /user/hive/warehouse/db_test2_title/cp_titles_date/part-m-00001
-rw-r--r--   3 root supergroup      2.2 M 2021-09-09 14:04 /user/hive/warehouse/db_test2_title/cp_titles_date/part-m-00002
-rw-r--r--   3 root supergroup        456 2021-09-09 14:04 /user/hive/warehouse/db_test2_title/cp_titles_date/part-m-00003
-rw-r--r--   3 root supergroup      5.8 M 2021-09-09 14:04 /user/hive/warehouse/db_test2_title/cp_titles_date/part-m-00004
-rw-r--r--   3 root supergroup    414.5 K 2021-09-09 14:04 /user/hive/warehouse/db_test2_title/cp_titles_date/part-m-00005
root@namenode:/# 





7. Clicar no botão de Enviar Tarefa, e enviar o texto: ok



########################################
EXERCICIOS - AULA 09 - Exercícios - Sqoop –Importação BD Sakila – Carga Incremental
########################################




Sqoop - Importação BD Sakila – Carga Incremental

Realizar com uso do MySQL

1. Criar a tabela cp_rental_append, contendo a cópia da tabela rental com os campos rental_id e rental_date

# entrar no container relacionado ao serviço de banco de dados e conectar ao mysql 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it database bash

root@database:/# mysql -h localhost -u root -psecret
mysql: [Warning] Using a password on the command line interface can be insecure.
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 70
Server version: 5.7.29 MySQL Community Server (GPL)

Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.

mysql> 

mysql> show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| employees          |
| hue                |
| mysql              |
| performance_schema |
| sakila             |
| sys                |
+--------------------+
7 rows in set (0.00 sec)

mysql> use sakila;
Reading table information for completion of table and column names
You can turn off this feature to get a quicker startup with -A

Database changed
mysql> show tables;
+----------------------------+
| Tables_in_sakila           |
+----------------------------+
| actor                      |
| actor_info                 |
| address                    |
| category                   |
| city                       |
| country                    |
| customer                   |
| customer_list              |
| film                       |
| film_actor                 |
| film_category              |
| film_list                  |
| film_text                  |
| inventory                  |
| language                   |
| nicer_but_slower_film_list |
| payment                    |
| rental                     |
| sales_by_film_category     |
| sales_by_store             |
| staff                      |
| staff_list                 |
| store                      |
+----------------------------+
23 rows in set (0.00 sec)

mysql> 

mysql> select * from rental limit 5;
+-----------+---------------------+--------------+-------------+---------------------+----------+---------------------+
| rental_id | rental_date         | inventory_id | customer_id | return_date         | staff_id | last_update         |
+-----------+---------------------+--------------+-------------+---------------------+----------+---------------------+
|         1 | 2005-05-24 22:53:30 |          367 |         130 | 2005-05-26 22:04:30 |        1 | 2006-02-15 21:30:53 |
|         2 | 2005-05-24 22:54:33 |         1525 |         459 | 2005-05-28 19:40:33 |        1 | 2006-02-15 21:30:53 |
|         3 | 2005-05-24 23:03:39 |         1711 |         408 | 2005-06-01 22:12:39 |        1 | 2006-02-15 21:30:53 |
|         4 | 2005-05-24 23:04:41 |         2452 |         333 | 2005-06-03 01:43:41 |        2 | 2006-02-15 21:30:53 |
|         5 | 2005-05-24 23:05:21 |         2079 |         222 | 2005-06-02 04:33:21 |        1 | 2006-02-15 21:30:53 |
+-----------+---------------------+--------------+-------------+---------------------+----------+---------------------+
5 rows in set (0.00 sec)


mysql> create table cp_rental_append select rental_id, rental_date from rental;
Query OK, 16044 rows affected (3.38 sec)
Records: 16044  Duplicates: 0  Warnings: 0


mysql> select * from cp_rental_append limit 5;
+-----------+---------------------+
| rental_id | rental_date         |
+-----------+---------------------+
|         1 | 2005-05-24 22:53:30 |
|         2 | 2005-05-24 22:54:33 |
|         3 | 2005-05-24 23:03:39 |
|         4 | 2005-05-24 23:04:41 |
|         5 | 2005-05-24 23:05:21 |
+-----------+---------------------+
5 rows in set (0.00 sec)

mysql> 





2 .Criar a tabela cp_rental_id e cp_rental_date, contendo a cópia da tabela cp_rental_append

 

 mysql> create table cp_rental_id select rental_id, rental_date from rental;
Query OK, 16044 rows affected (3.50 sec)
Records: 16044  Duplicates: 0  Warnings: 0

mysql> create table cp_rental_date select rental_id, rental_date from rental;
Query OK, 16044 rows affected (3.67 sec)
Records: 16044  Duplicates: 0  Warnings: 0

mysql> 

mysql> select * from cp_rental_id limit 5;
+-----------+---------------------+
| rental_id | rental_date         |
+-----------+---------------------+
|         1 | 2005-05-24 22:53:30 |
|         2 | 2005-05-24 22:54:33 |
|         3 | 2005-05-24 23:03:39 |
|         4 | 2005-05-24 23:04:41 |
|         5 | 2005-05-24 23:05:21 |
+-----------+---------------------+
5 rows in set (0.00 sec)

mysql> select * from cp_rental_date limit 5;
+-----------+---------------------+
| rental_id | rental_date         |
+-----------+---------------------+
|         1 | 2005-05-24 22:53:30 |
|         2 | 2005-05-24 22:54:33 |
|         3 | 2005-05-24 23:03:39 |
|         4 | 2005-05-24 23:04:41 |
|         5 | 2005-05-24 23:05:21 |
+-----------+---------------------+
5 rows in set (0.00 sec)

mysql> 



Realizar com uso do Sqoop - Importações no warehouse /user/hive/warehouse/db_test3 e visualizar no HDFS

3. Importar as tabelas cp_rental_append, cp_rental_id e cp_rental_date com 1 mapeador




# como estamos utilizando o parametro --warehouse-dir , ele ira criar uma pasta para cada tabela importada dentro  do hdfs

root@namenode:/# sqoop import --connect jdbc:mysql://database/sakila --username root --password secret --warehouse-dir /user/hive/warehouse/db_test3 -m 1 --table cp_rental_append


root@namenode:/# sqoop import --connect jdbc:mysql://database/sakila --username root --password secret --warehouse-dir /user/hive/warehouse/db_test3 -m 1 --table cp_rental_id


root@namenode:/# sqoop import --connect jdbc:mysql://database/sakila --username root --password secret --warehouse-dir /user/hive/warehouse/db_test3 -m 1 --table cp_rental_date



# verificar no hdfs , container namenode

root@namenode:/# hdfs dfs -ls -h -R /user/hive/warehouse/db_test3      
drwxr-xr-x   - root supergroup          0 2021-09-09 18:28 /user/hive/warehouse/db_test3/cp_rental_append
-rw-r--r--   3 root supergroup          0 2021-09-09 18:28 /user/hive/warehouse/db_test3/cp_rental_append/_SUCCESS
-rw-r--r--   3 root supergroup    427.9 K 2021-09-09 18:28 /user/hive/warehouse/db_test3/cp_rental_append/part-m-00000
drwxr-xr-x   - root supergroup          0 2021-09-09 18:35 /user/hive/warehouse/db_test3/cp_rental_date
-rw-r--r--   3 root supergroup          0 2021-09-09 18:35 /user/hive/warehouse/db_test3/cp_rental_date/_SUCCESS
-rw-r--r--   3 root supergroup    427.9 K 2021-09-09 18:35 /user/hive/warehouse/db_test3/cp_rental_date/part-m-00000
drwxr-xr-x   - root supergroup          0 2021-09-09 18:34 /user/hive/warehouse/db_test3/cp_rental_id
-rw-r--r--   3 root supergroup          0 2021-09-09 18:34 /user/hive/warehouse/db_test3/cp_rental_id/_SUCCESS
-rw-r--r--   3 root supergroup    427.9 K 2021-09-09 18:34 /user/hive/warehouse/db_test3/cp_rental_id/part-m-00000
root@namenode:/# 



 
Realizar com uso do MySQL


4. Executar o sql /db-sql/sakila/insert_rental.sql no container do database


$ docker exec -it database bash


(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it database bash
root@database:/# ls -ltr
total 80
drwxr-xr-x   2 root root 4096 Feb  1  2020 home
drwxr-xr-x   2 root root 4096 Feb  1  2020 boot
drwxr-xr-x   1 root root 4096 Feb 24  2020 var
drwxr-xr-x   1 root root 4096 Feb 24  2020 usr
drwxr-xr-x   2 root root 4096 Feb 24  2020 srv
drwxr-xr-x   2 root root 4096 Feb 24  2020 sbin
drwxr-xr-x   2 root root 4096 Feb 24  2020 opt
drwxr-xr-x   2 root root 4096 Feb 24  2020 mnt
drwxr-xr-x   2 root root 4096 Feb 24  2020 media
drwxr-xr-x   2 root root 4096 Feb 24  2020 lib64
drwxr-xr-x   1 root root 4096 Mar  4  2020 lib
drwxr-xr-x   2 root root 4096 Mar  4  2020 docker-entrypoint-initdb.d
drwxr-xr-x   1 root root 4096 Mar  4  2020 bin
drwxr-xr-x   1 root root 4096 Mar  4  2020 run
lrwxrwxrwx   1 root root   34 Mar  4  2020 entrypoint.sh -> usr/local/bin/docker-entrypoint.sh
drwxr-xr-x   1 root root 4096 Aug 31 00:21 etc
drwxr-xr-x   3 root root 4096 Aug 31 00:21 data
drwxr-xr-x   4 root root 4096 Aug 31 23:38 db-sql
dr-xr-xr-x  13 root root    0 Sep  9 10:37 sys
dr-xr-xr-x 553 root root    0 Sep  9 10:37 proc
drwxr-xr-x   5 root root  340 Sep  9 10:37 dev
drwxrwxrwt   1 root root 4096 Sep  9 10:37 tmp
drwx------   1 root root 4096 Sep  9 18:19 root
root@database:/# 


$ cd /db-sql/sakila

$ mysql -psecret < insert_rental.sql

root@database:/# cd /db-sql/sakila
root@database:/db-sql/sakila# ls -ltr
total 3308
-rw-r--r-- 1 root root   23471 Aug 31 23:38 sakila-mv-schema.sql
-rw-r--r-- 1 root root 3351835 Aug 31 23:38 sakila-mv-data.sql
-rw-r--r-- 1 root root    1416 Aug 31 23:38 insert_rental.sql
-rw-r--r-- 1 root root     333 Aug 31 23:38 README.md
root@database:/db-sql/sakila# 


root@database:/db-sql/sakila# cat insert_rental.sql 
use sakila;
DROP TABLE IF EXISTS cp_rental_append, cp_rental_date, cp_rental_id;
create table cp_rental_append select rental_id, rental_date from rental;
create table cp_rental_date select * from cp_rental_append;
create table cp_rental_id select * from cp_rental_date;

insert into cp_rental_date values(16048,'2005-08-23 22:30:00');
insert into cp_rental_date values(16049,'2005-08-23 22:40:00');
insert into cp_rental_date values(16050,'2005-08-23 22:52:50');
insert into cp_rental_date values(16051,'2005-08-23 22:54:30');
insert into cp_rental_date values(16052,'2005-08-23 22:55:20');
insert into cp_rental_date values(16054,'2005-08-23 22:57:40');
insert into cp_rental_date values(16053,'2005-08-23 22:56:10');
insert into cp_rental_date values(16055,'2005-08-23 22:59:20');

insert into cp_rental_id values(16048,'2005-08-23 22:30:00');
insert into cp_rental_id values(16049,'2005-08-23 22:40:00');
insert into cp_rental_id values(16050,'2005-08-23 22:52:50');
insert into cp_rental_id values(16051,'2005-08-23 22:54:30');
insert into cp_rental_id values(16052,'2005-08-23 22:55:20');
insert into cp_rental_id values(16054,'2005-08-23 22:57:40');
insert into cp_rental_id values(16053,'2005-08-23 22:56:10');
insert into cp_rental_id values(16055,'2005-08-23 22:59:20');

select * from cp_rental_date ORDER By cp_rental_date DESC limit 10;

select * from cp_rental_id ORDER By cp_rental_date DESC limit 10;
root@database:/db-sql/sakila# 


# vai berar erro qdo executar o arquivo acima devido os campos nos 2 ultimos selects nao existirem.
# realizar um update dos pacotes e instalar um editor de textos 

root@database:/db-sql/sakila# apt-get update
Get:1 http://deb.debian.org/debian buster InRelease [122 kB]
Get:2 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]
Get:3 http://deb.debian.org/debian buster-updates InRelease [51.9 kB]                 
Get:4 http://repo.mysql.com/apt/debian buster InRelease [21.5 kB]
Get:5 http://security.debian.org/debian-security buster/updates/main amd64 Packages [303 kB]
Get:6 http://deb.debian.org/debian buster/main amd64 Packages [7907 kB]
Get:7 http://deb.debian.org/debian buster-updates/main amd64 Packages [15.2 kB]
Get:8 http://repo.mysql.com/apt/debian buster/mysql-5.7 amd64 Packages [5686 B]   
Fetched 8491 kB in 2s (5430 kB/s)                         
Reading package lists... Done
root@database:/db-sql/sakila# apt-get install apt-file

# chama o editor vi e edita o arquivo insert_rental.sql, os 2 selects abaixo mudando os campos 

select * from cp_rental_date ORDER By rental_date DESC limit 10;

select * from cp_rental_id ORDER By rental_id DESC limit 10;

root@database:/db-sql/sakila# vi insert_rental.sql 
root@database:/db-sql/sakila# vi insert_rental.sql 
root@database:/db-sql/sakila# 
root@database:/db-sql/sakila# 
root@database:/db-sql/sakila# 
root@database:/db-sql/sakila# mysql -h localhost -u root -psecret < insert_rental.sql 
mysql: [Warning] Using a password on the command line interface can be insecure.
rental_id   rental_date
15458 2006-02-14 15:16:03
13421 2006-02-14 15:16:03
15542 2006-02-14 15:16:03
15294 2006-02-14 15:16:03
13428 2006-02-14 15:16:03
12988 2006-02-14 15:16:03
12786 2006-02-14 15:16:03
13952 2006-02-14 15:16:03
12574 2006-02-14 15:16:03
14915 2006-02-14 15:16:03
rental_id   rental_date
16055 2005-08-23 22:59:20
16054 2005-08-23 22:57:40
16053 2005-08-23 22:56:10
16052 2005-08-23 22:55:20
16051 2005-08-23 22:54:30
16050 2005-08-23 22:52:50
16049 2005-08-23 22:40:00
16049 2005-08-23 22:50:12
16048 2005-08-23 22:30:00
16048 2005-08-23 22:43:07
root@database:/db-sql/sakila# 



 

Realizar com uso do Sqoop - Importações no warehouse /user/hive/warehouse/db_test3 e visualizar no HDFS

5. Atualizar a tabela cp_rental_append no HDFS anexando os novos arquivos

root@namenode:/# sqoop import --table cp_rental_append --connect jdbc:mysql://database/sakila --username root --password secret -m 1 --warehouse-dir /user/hive/warehouse/db_test3 --append  

21/09/09 19:39:47 INFO mapreduce.Job: Job job_local48590149_0001 completed successfully
21/09/09 19:39:47 INFO mapreduce.Job: Counters: 20
   File System Counters
      FILE: Number of bytes read=212779830
      FILE: Number of bytes written=214905804
      FILE: Number of read operations=0
      FILE: Number of large read operations=0
      FILE: Number of write operations=0
      HDFS: Number of bytes read=0
      HDFS: Number of bytes written=438131
      HDFS: Number of read operations=4
      HDFS: Number of large read operations=0
      HDFS: Number of write operations=3
   Map-Reduce Framework
      Map input records=16044
      Map output records=16044
      Input split bytes=87
      Spilled Records=0
      Failed Shuffles=0
      Merged Map outputs=0
      GC time elapsed (ms)=0
      Total committed heap usage (bytes)=359661568
   File Input Format Counters 
      Bytes Read=0
   File Output Format Counters 
      Bytes Written=438131
21/09/09 19:39:47 INFO mapreduce.ImportJobBase: Transferred 427.8623 KB in 6.4612 seconds (66.22 KB/sec)
21/09/09 19:39:47 INFO mapreduce.ImportJobBase: Retrieved 16044 records.
21/09/09 19:39:47 INFO util.AppendUtils: Appending to directory cp_rental_append
21/09/09 19:39:47 INFO util.AppendUtils: Using found partition 1
root@namenode:/# 







6. Atualizar a tabela cp_rental_id no HDFS de acordo com o último registro de rental_id, adicionando apenas os novos dados.

# verficar o ultimo id da tabela para realizar a carga incremental 

root@namenode:/# sqoop list-tables --connect jdbc:mysql://database/sakila --username root --password secret
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/09 21:14:27 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/09 21:14:27 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/09 21:14:27 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Thu Sep 09 21:14:27 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
actor
actor_info
address
category
city
country
cp_rental_append
cp_rental_date
cp_rental_id
customer
customer_list
film
film_actor
film_category
film_list
film_text
inventory
language
nicer_but_slower_film_list
payment
rental
sales_by_film_category
sales_by_store
staff
staff_list
store
root@namenode:/# 



root@namenode:/# sqoop eval -connect jdbc:mysql://database/sakila --username root --password secret --query "select * from cp_rental_append order by rental_id desc limit 5"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/09 21:17:20 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/09 21:17:20 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/09 21:17:20 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Thu Sep 09 21:17:20 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
-------------------------------------
| rental_id   | rental_date         | 
-------------------------------------
| 16049       | 2005-08-23 22:50:12.0 | 
| 16048       | 2005-08-23 22:43:07.0 | 
| 16047       | 2005-08-23 22:42:48.0 | 
| 16046       | 2005-08-23 22:26:47.0 | 
| 16045       | 2005-08-23 22:25:26.0 | 
-------------------------------------
root@namenode:/# 


# outra forma de pegar o ultimo valor do campo, utilizar a função max 

root@namenode:/# sqoop eval -connect jdbc:mysql://database/sakila --username root --password secret --query "select max(rental_id) from cp_rental_append"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/09 21:18:37 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/09 21:18:37 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/09 21:18:37 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Thu Sep 09 21:18:38 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
---------------
| max(rental_id) | 
---------------
| 16049       | 
---------------
root@namenode:/# 


root@namenode:/# sqoop import --table cp_rental_id --connect jdbc:mysql://database/sakila --username root --password secret -m 1 --warehouse-dir /user/hive/warehouse/db_test3 --incremental append --check-column rental_id --last-value 16049


21/09/09 21:25:55 INFO mapreduce.Job: Job job_local526470522_0001 completed successfully
21/09/09 21:25:55 INFO mapreduce.Job: Counters: 20
   File System Counters
      FILE: Number of bytes read=212779793
      FILE: Number of bytes written=214908029
      FILE: Number of read operations=0
      FILE: Number of large read operations=0
      FILE: Number of write operations=0
      HDFS: Number of bytes read=0
      HDFS: Number of bytes written=168
      HDFS: Number of read operations=4
      HDFS: Number of large read operations=0
      HDFS: Number of write operations=3
   Map-Reduce Framework
      Map input records=6
      Map output records=6
      Input split bytes=87
      Spilled Records=0
      Failed Shuffles=0
      Merged Map outputs=0
      GC time elapsed (ms)=3
      Total committed heap usage (bytes)=365953024
   File Input Format Counters 
      Bytes Read=0
   File Output Format Counters 
      Bytes Written=168
21/09/09 21:25:55 INFO mapreduce.ImportJobBase: Transferred 168 bytes in 6.4767 seconds (25.9391 bytes/sec)
21/09/09 21:25:55 INFO mapreduce.ImportJobBase: Retrieved 6 records.
21/09/09 21:25:55 INFO util.AppendUtils: Appending to directory cp_rental_id
21/09/09 21:25:55 INFO util.AppendUtils: Using found partition 1
21/09/09 21:25:55 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:
21/09/09 21:25:55 INFO tool.ImportTool:  --incremental append
21/09/09 21:25:55 INFO tool.ImportTool:   --check-column rental_id
21/09/09 21:25:55 INFO tool.ImportTool:   --last-value 16055
21/09/09 21:25:55 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')
root@namenode:/# 





7. Atualizar a tabela cp_rental_date no HDFS de acordo com o último registro de rental_date, atualizando os registros a partir desta data.

#verficar a maxima data 

root@namenode:/# sqoop eval -connect jdbc:mysql://database/sakila --username root --password secret --query "select max(rental_date) from cp_rental_append"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/09 21:21:31 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/09 21:21:31 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/09 21:21:31 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Thu Sep 09 21:21:31 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
-----------------------
| max(rental_date)    | 
-----------------------
| 2006-02-14 15:16:03.0 | 
-----------------------
root@namenode:/# 


root@namenode:/# sqoop import --table cp_rental_date --connect jdbc:mysql://database/sakila --username root --password secret -m 1 --warehouse-dir /user/hive/warehouse/db_test3 --incremental lastmodified --merge-key rental_id --check-column rental_date --last-value '2005-08-23 22:50:12.0'


21/09/09 21:49:50 INFO mapreduce.Job: Job job_local1704654889_0002 completed successfully
21/09/09 21:49:50 INFO mapreduce.Job: Counters: 35
   File System Counters
      FILE: Number of bytes read=1278021713
      FILE: Number of bytes written=1292135382
      FILE: Number of read operations=0
      FILE: Number of large read operations=0
      FILE: Number of write operations=0
      HDFS: Number of bytes read=1324986
      HDFS: Number of bytes written=454175
      HDFS: Number of read operations=67
      HDFS: Number of large read operations=0
      HDFS: Number of write operations=23
   Map-Reduce Framework
      Map input records=16233
      Map output records=16233
      Map output bytes=638219
      Map output materialized bytes=670697
      Input split bytes=305
      Combine input records=0
      Combine output records=0
      Reduce input groups=16050
      Reduce shuffle bytes=670697
      Reduce input records=16233
      Reduce output records=16050
      Spilled Records=32466
      Shuffled Maps =2
      Failed Shuffles=0
      Merged Map outputs=2
      GC time elapsed (ms)=41
      Total committed heap usage (bytes)=1289748480
   Shuffle Errors
      BAD_ID=0
      CONNECTION=0
      IO_ERROR=0
      WRONG_LENGTH=0
      WRONG_MAP=0
      WRONG_REDUCE=0
   File Input Format Counters 
      Bytes Read=443423
   File Output Format Counters 
      Bytes Written=438299
21/09/09 21:49:51 INFO tool.ImportTool: Incremental import complete! To run another incremental import of all data following this import, supply the following arguments:
21/09/09 21:49:51 INFO tool.ImportTool:  --incremental lastmodified
21/09/09 21:49:51 INFO tool.ImportTool:   --check-column rental_date
21/09/09 21:49:51 INFO tool.ImportTool:   --last-value 2021-09-09 21:49:37.0
21/09/09 21:49:51 INFO tool.ImportTool: (Consider saving this with 'sqoop job --create')
root@namenode:/# 



root@namenode:/# hdfs dfs -ls -h -R /user/hive/warehouse/db_test3
drwxr-xr-x   - root supergroup          0 2021-09-09 19:39 /user/hive/warehouse/db_test3/cp_rental_append
-rw-r--r--   3 root supergroup          0 2021-09-09 18:28 /user/hive/warehouse/db_test3/cp_rental_append/_SUCCESS
-rw-r--r--   3 root supergroup    427.9 K 2021-09-09 18:28 /user/hive/warehouse/db_test3/cp_rental_append/part-m-00000
-rw-r--r--   3 root supergroup    427.9 K 2021-09-09 19:39 /user/hive/warehouse/db_test3/cp_rental_append/part-m-00001
drwxr-xr-x   - root supergroup          0 2021-09-09 21:49 /user/hive/warehouse/db_test3/cp_rental_date
-rw-r--r--   3 root supergroup          0 2021-09-09 21:49 /user/hive/warehouse/db_test3/cp_rental_date/_SUCCESS
-rw-r--r--   3 root supergroup    428.0 K 2021-09-09 21:49 /user/hive/warehouse/db_test3/cp_rental_date/part-r-00000
drwxr-xr-x   - root supergroup          0 2021-09-09 21:25 /user/hive/warehouse/db_test3/cp_rental_id
-rw-r--r--   3 root supergroup          0 2021-09-09 18:34 /user/hive/warehouse/db_test3/cp_rental_id/_SUCCESS
-rw-r--r--   3 root supergroup    427.9 K 2021-09-09 18:34 /user/hive/warehouse/db_test3/cp_rental_id/part-m-00000
-rw-r--r--   3 root supergroup        168 2021-09-09 21:25 /user/hive/warehouse/db_test3/cp_rental_id/part-m-00001
root@namenode:/# 




8. Clicar no botão de Enviar Tarefa, e enviar o texto: ok





########################################
EXERCICIOS - AULA 09 - Exercícios - Sqoop –Importação para o Hive e Exportação - BD Employees
########################################


Sqoop - Importação para o Hive e Exportação - BD Employees

 

1. Importar a tabela employees.titles do MySQL para o diretório /user/aluno/<nome>/data com 1 mapeador.


root@namenode:/# sqoop import --table titles --connect jdbc:mysql://database/employees --username root --password secret -m 1 --warehouse-dir /user/aluno/heron/data



root@namenode:/# hdfs dfs -ls -h -R /user/aluno/heron/data/titles
-rw-r--r--   3 root supergroup          0 2021-09-09 22:04 /user/aluno/heron/data/titles/_SUCCESS
-rw-r--r--   3 root supergroup     16.9 M 2021-09-09 22:04 /user/aluno/heron/data/titles/part-m-00000
root@namenode:/# 





2. Importar a tabela employees.titles do MySQL para uma tabela Hive no banco de dados seu nome com 1 mapeador.


root@namenode:/# sqoop import --table titles --connect jdbc:mysql://database/employees --username root --password secret -m 1 --hive-import --hive-table heron.titles  


root@namenode:/# hdfs dfs -ls -h -R /user/hive/warehouse/heron.db
drwxrwxr-x   - root supergroup          0 2021-09-03 00:02 /user/hive/warehouse/heron.db/pop
-rwxrwxr-x   3 root supergroup     11.9 K 2021-09-03 00:02 /user/hive/warehouse/heron.db/pop/populacaoLA.csv
drwxrwxr-x   - root supergroup          0 2021-09-07 22:49 /user/hive/warehouse/heron.db/pop_parquet
-rwxrwxr-x   3 root supergroup      9.3 K 2021-09-07 22:49 /user/hive/warehouse/heron.db/pop_parquet/000000_0
drwxrwxr-x   - root supergroup          0 2021-09-07 22:57 /user/hive/warehouse/heron.db/pop_parquet_snappy
-rwxrwxr-x   3 root supergroup      9.3 K 2021-09-07 22:57 /user/hive/warehouse/heron.db/pop_parquet_snappy/000000_0
drwxrwxr-x   - root supergroup          0 2021-09-09 22:12 /user/hive/warehouse/heron.db/titles
-rwxrwxr-x   3 root supergroup     16.9 M 2021-09-09 22:12 /user/hive/warehouse/heron.db/titles/part-m-00000
root@namenode:/# 






3. Selecionar os 10 primeiros registros da tabela titles no Hive.

# analisando pelo hdfs 

root@namenode:/# hdfs dfs -cat /user/hive/warehouse/heron.db/titles/part-m-00000 | head -n 10
10001Senior Engineer1986-06-269999-01-01
10002Staff1996-08-039999-01-01
10003Senior Engineer1995-12-039999-01-01
10004Engineer1986-12-011995-12-01
10004Senior Engineer1995-12-019999-01-01
10005Senior Staff1996-09-129999-01-01
10005Staff1989-09-121996-09-12
10006Senior Engineer1990-08-059999-01-01
10007Senior Staff1996-02-119999-01-01
10007Staff1989-02-101996-02-11
cat: Unable to write to output stream.
root@namenode:/# 


# acessando o container do hive e beeline 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it hive-server bash
root@hive_server:/opt# beeline -u jdbc:hive2://localhost:10000
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hive/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Connecting to jdbc:hive2://localhost:10000
Connected to: Apache Hive (version 2.3.2)
Driver: Hive JDBC (version 2.3.2)
Transaction isolation: TRANSACTION_REPEATABLE_READ
Beeline version 2.3.2 by Apache Hive
0: jdbc:hive2://localhost:10000> 


0: jdbc:hive2://localhost:10000> show databases;
+----------------+
| database_name  |
+----------------+
| default        |
| heron          |
+----------------+
2 rows selected (0.764 seconds)
0: jdbc:hive2://localhost:10000> 


# utilizando o banco heron 

0: jdbc:hive2://localhost:10000> use heron;
No rows affected (0.027 seconds)
0: jdbc:hive2://localhost:10000> show tables;
+---------------------+
|      tab_name       |
+---------------------+
| nascimento          |
| pop                 |
| pop_parquet         |
| pop_parquet_snappy  |
| titles              |
+---------------------+
5 rows selected (0.035 seconds)
0: jdbc:hive2://localhost:10000> 



0: jdbc:hive2://localhost:10000> select * from titles limit 10;
+----------------+------------------+-------------------+-----------------+
| titles.emp_no  |   titles.title   | titles.from_date  | titles.to_date  |
+----------------+------------------+-------------------+-----------------+
| 10001          | Senior Engineer  | 1986-06-26        | 9999-01-01      |
| 10002          | Staff            | 1996-08-03        | 9999-01-01      |
| 10003          | Senior Engineer  | 1995-12-03        | 9999-01-01      |
| 10004          | Engineer         | 1986-12-01        | 1995-12-01      |
| 10004          | Senior Engineer  | 1995-12-01        | 9999-01-01      |
| 10005          | Senior Staff     | 1996-09-12        | 9999-01-01      |
| 10005          | Staff            | 1989-09-12        | 1996-09-12      |
| 10006          | Senior Engineer  | 1990-08-05        | 9999-01-01      |
| 10007          | Senior Staff     | 1996-02-11        | 9999-01-01      |
| 10007          | Staff            | 1989-02-10        | 1996-02-11      |
+----------------+------------------+-------------------+-----------------+
10 rows selected (1.034 seconds)
0: jdbc:hive2://localhost:10000> 



4. Deletar os registros da tabela employees.titles do MySQL e verificar se foram apagados, através do Sqoop



root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "select * from titles limit 10"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/09 22:24:16 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/09 22:24:16 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/09 22:24:16 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Thu Sep 09 22:24:17 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
----------------------------------------------------------------
| emp_no      | title                | from_date  | to_date    | 
----------------------------------------------------------------
| 10001       | Senior Engineer      | 1986-06-26 | 9999-01-01 | 
| 10002       | Staff                | 1996-08-03 | 9999-01-01 | 
| 10003       | Senior Engineer      | 1995-12-03 | 9999-01-01 | 
| 10004       | Engineer             | 1986-12-01 | 1995-12-01 | 
| 10004       | Senior Engineer      | 1995-12-01 | 9999-01-01 | 
| 10005       | Senior Staff         | 1996-09-12 | 9999-01-01 | 
| 10005       | Staff                | 1989-09-12 | 1996-09-12 | 
| 10006       | Senior Engineer      | 1990-08-05 | 9999-01-01 | 
| 10007       | Senior Staff         | 1996-02-11 | 9999-01-01 | 
| 10007       | Staff                | 1989-02-10 | 1996-02-11 | 
----------------------------------------------------------------
root@namenode:/# 


root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "truncate table titles"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/09 22:25:20 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/09 22:25:20 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/09 22:25:20 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Thu Sep 09 22:25:20 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
21/09/09 22:25:20 INFO tool.EvalSqlTool: 0 row(s) updated.
root@namenode:/# 


root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "select * from titles limit 10"
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/09 22:26:35 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/09 22:26:35 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/09 22:26:35 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Thu Sep 09 22:26:35 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
----------------------------------------------------------------
| emp_no      | title                | from_date  | to_date    | 
----------------------------------------------------------------
----------------------------------------------------------------
root@namenode:/# 




5. Exportar os dados do diretório /user/hive/warehouse/<nome>.db/data/titles para a tabela do MySQL  employees.titles.


root@namenode:/# sqoop export --table titles --connect jdbc:mysql://database/employees --username root --password secret -m 1 --export-dir /user/aluno/heron/data/titles






6. Selecionar os 10 primeiros registros registros da tabela employees.titles do MySQL.


root@namenode:/# sqoop eval -connect jdbc:mysql://database/employees --username root --password secret --query "select * from titles limit 10"                             
Warning: /usr/lib/sqoop/../hbase does not exist! HBase imports will fail.
Please set $HBASE_HOME to the root of your HBase installation.
Warning: /usr/lib/sqoop/../hcatalog does not exist! HCatalog jobs will fail.
Please set $HCAT_HOME to the root of your HCatalog installation.
Warning: /usr/lib/sqoop/../accumulo does not exist! Accumulo imports will fail.
Please set $ACCUMULO_HOME to the root of your Accumulo installation.
Warning: /usr/lib/sqoop/../zookeeper does not exist! Accumulo imports will fail.
Please set $ZOOKEEPER_HOME to the root of your Zookeeper installation.
21/09/09 22:35:23 INFO sqoop.Sqoop: Running Sqoop version: 1.4.7
21/09/09 22:35:23 WARN tool.BaseSqoopTool: Setting your password on the command-line is insecure. Consider using -P instead.
21/09/09 22:35:24 INFO manager.MySQLManager: Preparing to use a MySQL streaming resultset.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/hadoop-2.7.4/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/lib/sqoop/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Thu Sep 09 22:35:24 UTC 2021 WARN: Establishing SSL connection without server's identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn't set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to 'false'. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification.
----------------------------------------------------------------
| emp_no      | title                | from_date  | to_date    | 
----------------------------------------------------------------
| 10001       | Senior Engineer      | 1986-06-26 | 9999-01-01 | 
| 10002       | Staff                | 1996-08-03 | 9999-01-01 | 
| 10003       | Senior Engineer      | 1995-12-03 | 9999-01-01 | 
| 10004       | Engineer             | 1986-12-01 | 1995-12-01 | 
| 10004       | Senior Engineer      | 1995-12-01 | 9999-01-01 | 
| 10005       | Senior Staff         | 1996-09-12 | 9999-01-01 | 
| 10005       | Staff                | 1989-09-12 | 1996-09-12 | 
| 10006       | Senior Engineer      | 1990-08-05 | 9999-01-01 | 
| 10007       | Senior Staff         | 1996-02-11 | 9999-01-01 | 
| 10007       | Staff                | 1989-02-10 | 1996-02-11 | 
----------------------------------------------------------------
root@namenode:/# 







7. Clicar no botão de Enviar Tarefa, e enviar o texto: ok





########################################
EXERCICIOS - AULA 10 - Exercícios - Sqoop –Importação para o Hive e Exportação - BD Employees
########################################




HBase - Exercícios

1. Criar a tabela ‘controle’ com os dados:

Chave: id
Família de Coluna: produto e fornecedor


id                            produto                                                  fornecedor

                     nome                 qtd                              nome                       estado

1                    ram                  100                              TI Comp                    SP

2                    hd                    50                              Peças PC                   MG

3                    mouse                150                              Inf Tec                    SP



# verficar o ambiente, containers ativos e entrar no container do HBase 

(base) heron@acerubuntu:~/docker-bigdata$ docker ps
CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES
(base) heron@acerubuntu:~/docker-bigdata$ docker ps -a
CONTAINER ID   IMAGE                    COMMAND                  CREATED       STATUS                      PORTS     NAMES
0e9c37d80dae   fjardim/hive             "entrypoint.sh /bin/…"   10 days ago   Exited (137) 13 hours ago             hive-server
7a202a46b3a5   fjardim/hive             "entrypoint.sh /opt/…"   10 days ago   Exited (143) 13 hours ago             hive_metastore
cd23241c12c5   fjardim/hive-metastore   "/docker-entrypoint.…"   10 days ago   Exited (0) 13 hours ago               hive-metastore-postgresql
4949d45d9b31   fjardim/datanode         "/entrypoint.sh /run…"   10 days ago   Exited (137) 13 hours ago             datanode
fe530609cf74   fjardim/hbase-master     "/entrypoint.sh /run…"   10 days ago   Exited (137) 13 hours ago             hbase-master
3accbde01373   fjardim/namenode_sqoop   "/entrypoint.sh /run…"   10 days ago   Exited (137) 13 hours ago             namenode
aefe08a8404b   fjardim/zookeeper        "/bin/sh -c '/usr/sb…"   10 days ago   Exited (137) 13 hours ago             zookeeper
5c45bd491957   fjardim/jupyter-spark    "/opt/docker/bin/ent…"   10 days ago   Exited (137) 13 hours ago             spark
13b81112cc67   fjardim/mysql            "docker-entrypoint.s…"   10 days ago   Exited (0) 13 hours ago               database
(base) heron@acerubuntu:~/docker-bigdata$ docker-compose up -d
Starting namenode  ... done
Starting zookeeper    ... done
Starting spark        ... done
Starting database     ... done
Starting hbase-master ... done
Starting datanode     ... done
Starting hive-metastore-postgresql ... done
Starting hive_metastore            ... done
Starting hive-server               ... done
(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it hbase-master bash
root@hbase-master:/# 

# Entrar no HBase shell

root@hbase-master:/# hbase shell
2021-09-10 12:19:43,408 WARN  [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
HBase Shell; enter 'help<RETURN>' for list of supported commands.
Type "exit<RETURN>" to leave the HBase Shell
Version 1.2.6, rUnknown, Mon May 29 02:25:32 CDT 2017

hbase(main):001:0> 


# criar a tabela 

hbase(main):001:0> create 'controle', {NAME=>'produto'},{NAME=>'fornecedor'}
0 row(s) in 4.9090 seconds

=> Hbase::Table - controle
hbase(main):002:0> 




put 'controle','1','produto:nome','ram'
put 'controle','2','produto:nome','hd'
put 'controle','3','produto:nome','mouse'
put 'controle','1','produto:qtd','100'
put 'controle','2','produto:qtd','50'
put 'controle','3','produto:qtd','150'


put 'controle','1','fornecedor:nome','TI Comp'
put 'controle','2','fornecedor:nome','Peças PC'
put 'controle','3','fornecedor:nome','Inf Tec'
put 'controle','1','fornecedor:estado','SP'
put 'controle','2','fornecedor:estado','MG'
put 'controle','3','fornecedor:estado','SP'


hbase(main):002:0> put 'controle','1','produto:nome','ram'
0 row(s) in 0.1210 seconds

hbase(main):003:0> put 'controle','2','produto:nome','hd'
0 row(s) in 0.0090 seconds

hbase(main):004:0> put 'controle','3','produto:nome','mouse'
0 row(s) in 0.0110 seconds

hbase(main):005:0> put 'controle','1','produto:qtd','100'
0 row(s) in 0.0070 seconds

hbase(main):006:0> put 'controle','2','produto:qtd','50'
0 row(s) in 0.0080 seconds

hbase(main):007:0> put 'controle','3','produto:qtd','150'
0 row(s) in 0.0100 seconds

hbase(main):008:0> 
hbase(main):009:0* 
hbase(main):010:0* 
hbase(main):011:0* 
hbase(main):012:0* put 'controle','1','produto:qtd','100'
0 row(s) in 0.0170 seconds

hbase(main):013:0> put 'controle','2','produto:qtd','50'
0 row(s) in 0.0100 seconds

hbase(main):014:0> put 'controle','3','produto:qtd','150'
0 row(s) in 0.0100 seconds

hbase(main):015:0> put 'controle','1','fornecedor:nome','TI Comp'
0 row(s) in 0.0110 seconds

hbase(main):016:0> put 'controle','2','fornecedor:nome','Peças PC'
0 row(s) in 0.0080 seconds

hbase(main):017:0> put 'controle','3','fornecedor:nome','Inf Tec'
0 row(s) in 0.0120 seconds

hbase(main):018:0> put 'controle','1','fornecedor:estado','SP'
0 row(s) in 0.0060 seconds

hbase(main):019:0> put 'controle','2','fornecedor:estado','MG'
0 row(s) in 0.0140 seconds

hbase(main):020:0> put 'controle','3','fornecedor:estado','SP'
0 row(s) in 0.0070 seconds

hbase(main):021:0> 



# desabilitar tabela 

hbase(main):022:0> disable 'controle'
0 row(s) in 4.4690 seconds


# dropar tabela 

hbase(main):001:0> drop 'controle'



# Verficar a tabela 

hbase(main):017:0> scan 'controle'
ROW                                                                   COLUMN+CELL                                                                                                                                                                                               
 1                                                                    column=fornecedor:estado, timestamp=1631279822234, value=SP                                                                                                                                               
 1                                                                    column=fornecedor:nome, timestamp=1631279759189, value=TI Comp                                                                                                                                            
 1                                                                    column=produto:nome, timestamp=1631279603768, value=ram                                                                                                                                                   
 1                                                                    column=produto:qtd, timestamp=1631279664596, value=100                                                                                                                                                    
 2                                                                    column=fornecedor:estado, timestamp=1631279843861, value=MG                                                                                                                                               
 2                                                                    column=fornecedor:nome, timestamp=1631279774812, value=Pe\xC3\xA7as PC                                                                                                                                    
 2                                                                    column=produto:nome, timestamp=1631279622647, value=hd                                                                                                                                                    
 2                                                                    column=produto:qtd, timestamp=1631279680795, value=50                                                                                                                                                     
 3                                                                    column=fornecedor:estado, timestamp=1631279860158, value=SP                                                                                                                                               
 3                                                                    column=fornecedor:nome, timestamp=1631279803102, value=Inf Tec                                                                                                                                            
 3                                                                    column=produto:nome, timestamp=1631279644233, value=mouse                                                                                                                                                 
 3                                                                    column=produto:qtd, timestamp=1631279697678, value=150                                                                                                                                                    
3 row(s) in 0.0390 seconds

hbase(main):018:0> 




2. Listar as tabelas e verificar a estrutura da tabela ‘controle’


hbase(main):018:0> list
TABLE                                                                                                                                                                                                                                                                           
controle                                                                                                                                                                                                                                                                        
1 row(s) in 0.0220 seconds

=> ["controle"]
hbase(main):019:0> 

#verificar a estrutura atraves do comando describe

hbase(main):019:0> describe 'controle'
Table controle is ENABLED                                                                                                                                                                                                                                                       
controle                                                                                                                                                                                                                                                                        
COLUMN FAMILIES DESCRIPTION                                                                                                                                                                                                                                                     
{NAME => 'fornecedor', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE =>
 '0'}                                                                                                                                                                                                                                                                           
{NAME => 'produto', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0
'}                                                                                                                                                                                                                                                                              
2 row(s) in 0.0330 seconds

hbase(main):020:0> 





3. Contar o número de registros da tabela ‘controle’


hbase(main):020:0> count 'controle'
3 row(s) in 0.0280 seconds

=> 3
hbase(main):021:0> root@hbase-master:/# 





4. Alterar  a família de coluna produto para 3 versões

hbase(main):001:0> 
hbase(main):002:0* 
hbase(main):003:0* alter 'controle',{NAME=>'produto',VERSIONS=>3}
Updating all regions with the new schema...
0/1 regions updated.
1/1 regions updated.
Done.
0 row(s) in 4.1010 seconds

hbase(main):004:0> 


hbase(main):005:0> describe 'controle'
Table controle is ENABLED                                                                                                                                                                                                                                                       
controle                                                                                                                                                                                                                                                                        
COLUMN FAMILIES DESCRIPTION                                                                                                                                                                                                                                                     
{NAME => 'fornecedor', BLOOMFILTER => 'ROW', VERSIONS => '1', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE =>
 '0'}                                                                                                                                                                                                                                                                           
{NAME => 'produto', BLOOMFILTER => 'ROW', VERSIONS => '3', IN_MEMORY => 'false', KEEP_DELETED_CELLS => 'FALSE', DATA_BLOCK_ENCODING => 'NONE', TTL => 'FOREVER', COMPRESSION => 'NONE', MIN_VERSIONS => '0', BLOCKCACHE => 'true', BLOCKSIZE => '65536', REPLICATION_SCOPE => '0
'}                                                                                                                                                                                                                                                                              
2 row(s) in 0.0180 seconds

hbase(main):006:0> 




5. Alterar a quantidade para 200 do id 2


hbase(main):006:0> put 'controle','2','produto:qtd','200'
0 row(s) in 0.0580 seconds

hbase(main):007:0> 


hbase(main):007:0> scan 'controle'
ROW                                                                   COLUMN+CELL                                                                                                                                                                                               
 1                                                                    column=fornecedor:estado, timestamp=1631279822234, value=SP                                                                                                                                               
 1                                                                    column=fornecedor:nome, timestamp=1631279759189, value=TI Comp                                                                                                                                            
 1                                                                    column=produto:nome, timestamp=1631279603768, value=ram                                                                                                                                                   
 1                                                                    column=produto:qtd, timestamp=1631279664596, value=100                                                                                                                                                    
 2                                                                    column=fornecedor:estado, timestamp=1631279843861, value=MG                                                                                                                                               
 2                                                                    column=fornecedor:nome, timestamp=1631279774812, value=Pe\xC3\xA7as PC                                                                                                                                    
 2                                                                    column=produto:nome, timestamp=1631279622647, value=hd                                                                                                                                                    
 2                                                                    column=produto:qtd, timestamp=1631281614086, value=200                                                                                                                                                    
 3                                                                    column=fornecedor:estado, timestamp=1631279860158, value=SP                                                                                                                                               
 3                                                                    column=fornecedor:nome, timestamp=1631279803102, value=Inf Tec                                                                                                                                            
 3                                                                    column=produto:nome, timestamp=1631279644233, value=mouse                                                                                                                                                 
 3                                                                    column=produto:qtd, timestamp=1631279697678, value=150                                                                                                                                                    
3 row(s) in 0.0250 seconds

hbase(main):008:0> 



6. Pesquisar as versões do id 2  da coluna quantidade

  hbase> get 'ns1:t1', 'r1'
  hbase> get 't1', 'r1'
  hbase> get 't1', 'r1', {TIMERANGE => [ts1, ts2]}
  hbase> get 't1', 'r1', {COLUMN => 'c1'}
  hbase> get 't1', 'r1', {COLUMN => ['c1', 'c2', 'c3']}
  hbase> get 't1', 'r1', {COLUMN => 'c1', TIMESTAMP => ts1}
  hbase> get 't1', 'r1', {COLUMN => 'c1', TIMERANGE => [ts1, ts2], VERSIONS => 4}
  hbase> get 't1', 'r1', {COLUMN => 'c1', TIMESTAMP => ts1, VERSIONS => 4}
  hbase> get 't1', 'r1', {FILTER => "ValueFilter(=, 'binary:abc')"}
  hbase> get 't1', 'r1', 'c1'
  hbase> get 't1', 'r1', 'c1', 'c2'
  hbase> get 't1', 'r1', ['c1', 'c2']
  hbase> get 't1', 'r1', {COLUMN => 'c1', ATTRIBUTES => {'mykey'=>'myvalue'}}
  hbase> get 't1', 'r1', {COLUMN => 'c1', AUTHORIZATIONS => ['PRIVATE','SECRET']}
  hbase> get 't1', 'r1', {CONSISTENCY => 'TIMELINE'}
  hbase> get 't1', 'r1', {CONSISTENCY => 'TIMELINE', REGION_REPLICA_ID => 1}


  hbase(main):009:0> get 'controle' ,'2',{COLUMNS=>'produto',VERSIONS=>2}
COLUMN                                                                CELL                                                                                                                                                                                                      
 produto:nome                                                         timestamp=1631279622647, value=hd                                                                                                                                                          
 produto:qtd                                                          timestamp=1631281614086, value=200                                                                                                                                                                        
 produto:qtd                                                          timestamp=1631279680795, value=50                                                                                                                                                                         
3 row(s) in 0.0190 seconds

hbase(main):010:0> 



hbase(main):010:0> get 'controle' ,'2',{COLUMNS=>'produto:qtd',VERSIONS=>2}
COLUMN                                                                CELL                                                                                                                                                                                                      
 produto:qtd                                                          timestamp=1631281614086, value=200                                                                                                                                                                        
 produto:qtd                                                          timestamp=1631279680795, value=50                                                                                                                                                                         
2 row(s) in 0.0820 seconds

hbase(main):011:0> 


hbase(main):002:0> get 'controle' ,'2',{COLUMNS=>['produto:qtd','fornecedor:nome'], VERSIONS=>2}
COLUMN                                                                CELL                                                                                                                                                                                                      
 fornecedor:nome                                                      timestamp=1631279774812, value=Pe\xC3\xA7as PC                                                                                                                                                            
 produto:qtd                                                          timestamp=1631281614086, value=200                                                                                                                                                                        
 produto:qtd                                                          timestamp=1631279680795, value=50                                                                                                                                                                         
3 row(s) in 0.0240 seconds

hbase(main):003:0> 






7. Excluir os id do estado de SP


hbase(main):003:0> scan 'controle',{COLUMNS=>'fornecedor:estado'}
ROW                                                                   COLUMN+CELL                                                                                                                                                                                               
 1                                                                    column=fornecedor:estado, timestamp=1631279822234, value=SP                                                                                                                                               
 2                                                                    column=fornecedor:estado, timestamp=1631279843861, value=MG                                                                                                                                               
 3                                                                    column=fornecedor:estado, timestamp=1631279860158, value=SP                                                                                                                                               
3 row(s) in 0.0200 seconds

hbase(main):004:0> 


hbase(main):004:0> scan 'controle',{COLUMNS=>'fornecedor:estado', LIMIT=>2}
ROW                                                                   COLUMN+CELL                                                                                                                                                                                               
 1                                                                    column=fornecedor:estado, timestamp=1631279822234, value=SP                                                                                                                                               
 2                                                                    column=fornecedor:estado, timestamp=1631279843861, value=MG                                                                                                                                               
2 row(s) in 0.0100 seconds

hbase(main):005:0> 


hbase(main):005:0> scan 'controle',{COLUMNS=>'fornecedor:estado', LIMIT=>5, FILTER=>"ValueFilter(=, 'binary:SP')"}
ROW                                                                   COLUMN+CELL                                                                                                                                                                                               
 1                                                                    column=fornecedor:estado, timestamp=1631279822234, value=SP                                                                                                                                               
 3                                                                    column=fornecedor:estado, timestamp=1631279860158, value=SP                                                                                                                                               
2 row(s) in 0.0480 seconds

hbase(main):006:0> 


hbase(main):006:0> deleteall 'controle','1'
0 row(s) in 0.0560 seconds

hbase(main):007:0> deleteall 'controle','3'
0 row(s) in 0.0060 seconds

hbase(main):008:0> scan 'controle'
ROW                                                                   COLUMN+CELL                                                                                                                                                                                               
 2                                                                    column=fornecedor:estado, timestamp=1631279843861, value=MG                                                                                                                                               
 2                                                                    column=fornecedor:nome, timestamp=1631279774812, value=Pe\xC3\xA7as PC                                                                                                                                    
 2                                                                    column=produto:nome, timestamp=1631279622647, value=hd                                                                                                                                                    
 2                                                                    column=produto:qtd, timestamp=1631281614086, value=200                                                                                                                                                    
1 row(s) in 0.0140 seconds

hbase(main):009:0> 



8. Deletar a coluna estado da chave 2

hbase(main):009:0> delete 'controle','2','fornecedor:estado'
0 row(s) in 0.0080 seconds

hbase(main):010:0> 







9. Pesquisar toda a tabela controle

hbase(main):010:0> scan 'controle'
ROW                                                                   COLUMN+CELL                                                                                                                                                                                               
 2                                                                    column=fornecedor:nome, timestamp=1631279774812, value=Pe\xC3\xA7as PC                                                                                                                                    
 2                                                                    column=produto:nome, timestamp=1631279622647, value=hd                                                                                                                                                    
 2                                                                    column=produto:qtd, timestamp=1631281614086, value=200                                                                                                                                                    
1 row(s) in 0.0100 seconds

hbase(main):011:0> 




10. Clicar no botão de Enviar Tarefa, e enviar o texto: ok





########################################
EXERCICIOS - AULA 11 - Exercícios - Spark - Exercícios de DataFrame
########################################


# entrar no container do spark 

docker exec -it spark bash 

spark-shell


#dataframe 
 val <nomedataframe> = spark.read.format("<formato>").load("<arquivo>")



1. Enviar o diretório local “/input/exercises-data/juros_selic” para o HDFS em “/user/aluno/<nome>/data”


# entrar no container do namenode - hdfs 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it namenode bash
root@namenode:/# ls -ltr
total 232
drwxr-xr-x   2 root root  4096 Nov 19  2017 home
drwxr-xr-x   2 root root  4096 Nov 19  2017 boot
drwxr-xr-x   2 root root  4096 Dec 10  2017 srv
drwxr-xr-x   3 root root  4096 Dec 10  2017 run
drwxr-xr-x   2 root root  4096 Dec 10  2017 mnt
drwxr-xr-x   2 root root  4096 Dec 10  2017 media
drwxr-xr-x   2 root root  4096 Dec 10  2017 lib64
-rwxr-xr-x   1 root root  4145 Feb  5  2018 entrypoint.sh
drwxr-xr-x   1 root root  4096 Feb  5  2018 lib
drwxr-xr-x   1 root root  4096 Feb  5  2018 var
drwxr-xr-x   1 root root  4096 Feb  5  2018 usr
drwxr-xr-x   1 root root  4096 Feb  5  2018 sbin
drwxr-xr-x   1 root root  4096 Feb  5  2018 bin
drwxr-xr-x   1 root root  4096 Feb  5  2018 opt
drwxr-xr-x   2 root root  4096 Feb  5  2018 hadoop-data
-rwxr-xr-x   1 root root   499 Oct  5  2018 run.sh
drwxr-xr-x   3 root root  4096 Oct  5  2018 hadoop
-rw-r--r--   1 root root 20895 Mar 19  2020 employees.java
drwx------   1 root root  4096 Mar 19  2020 root
-rw-r--r--   1 root root 24060 Mar 19  2020 derby.log
drwxr-xr-x   5 root root  4096 Mar 19  2020 metastore_db
drwxr-xr-x   1 root root  4096 Aug 31 00:21 etc
drwxr-xr-x   3 root root  4096 Aug 31 23:38 input
-rw-r--r--   1 root root 16278 Sep  9 12:33 codegen_titles.java
-rw-r--r--   1 root root 11483 Sep  9 13:06 cp_titles_date.java
-rw-r--r--   1 root root 12217 Sep  9 18:27 cp_rental_append.java
-rw-r--r--   1 root root 12153 Sep  9 18:34 cp_rental_id.java
-rw-r--r--   1 root root 12185 Sep  9 18:35 cp_rental_date.java
-rw-r--r--   1 root root 16126 Sep  9 22:03 titles.java
dr-xr-xr-x  13 root root     0 Sep 10 11:47 sys
dr-xr-xr-x 557 root root     0 Sep 10 11:47 proc
drwxr-xr-x   5 root root   340 Sep 10 11:47 dev
drwxrwxrwt   1 root root  4096 Sep 10 11:47 tmp


root@namenode:/# ls -ltr /input/exercises-data/
total 72
-rw-r--r-- 1 root root 2089 Aug 31 23:38 WordCount.java
-rw-r--r-- 1 root root   46 Aug 31 23:38 README.md
drwxr-xr-x 2 root root 4096 Aug 31 23:38 beneficio
drwxr-xr-x 2 root root 4096 Aug 31 23:38 economicFitness
drwxr-xr-x 4 root root 4096 Aug 31 23:38 db-sql
drwxr-xr-x 2 root root 4096 Aug 31 23:38 empreendimento
-rw-r--r-- 1 root root   42 Aug 31 23:38 entrada2.txt
-rw-r--r-- 1 root root   54 Aug 31 23:38 entrada1.txt
drwxr-xr-x 2 root root 4096 Aug 31 23:38 escola
-rw-r--r-- 1 root root  161 Aug 31 23:38 map.py
drwxr-xr-x 2 root root 4096 Aug 31 23:38 juros_selic
drwxr-xr-x 2 root root 4096 Aug 31 23:38 iris
drwxr-xr-x 2 root root 4096 Aug 31 23:38 hnpStats
drwxr-xr-x 2 root root 4096 Aug 31 23:38 names
drwxr-xr-x 2 root root 4096 Aug 31 23:38 populacaoLA
drwxr-xr-x 2 root root 4096 Aug 31 23:38 ouvidoria
drwxr-xr-x 2 root root 4096 Aug 31 23:38 namesbystate
-rw-r--r-- 1 root root  511 Aug 31 23:38 reduce.py
root@namenode:/# 


# feito a copia da pasta local para a pasta dentro do hdfs 


root@namenode:/# hdfs dfs -put /input/exercises-data/juros_selic/ /user/aluno/heron/data
root@namenode:/# hdfs dfs -ls -R /user/aluno/heron/data/juros_selic                     
-rw-r--r--   3 root supergroup       7954 2021-09-10 21:30 /user/aluno/heron/data/juros_selic/juros_selic
-rw-r--r--   3 root supergroup      14621 2021-09-10 21:30 /user/aluno/heron/data/juros_selic/juros_selic.json
-rw-r--r--   3 root supergroup      12900 2021-09-10 21:30 /user/aluno/heron/data/juros_selic/juros_selic.wsdl
root@namenode:/# 



2. Criar o DataFrame jurosDF para ler o arquivo no HDFS “/user/aluno/<nome>/data/juros_selic/juros_selic.json”



# entrar no container do spark 

(base) heron@acerubuntu:~/docker-bigdata$ docker exec -it spark bash
root@spark:/# 


#executar o spark-shell 

root@spark:/# spark-shell
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
21/09/10 21:35:54 WARN spark.SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
Spark context Web UI available at http://spark:4040
Spark context available as 'sc' (master = local[*], app id = local-1631309755287).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 2.4.1
      /_/
         
Using Scala version 2.11.12 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_201)
Type in expressions to have them evaluated.
Type :help for more information.

scala> 


scala> val jurosDF = spark.
baseRelationToDataFrame   close   createDataFrame   emptyDataFrame   experimental   listenerManager   range   readStream     sharedState    sql          stop      table   udf       
catalog                   conf    createDataset     emptyDataset     implicits      newSession        read    sessionState   sparkContext   sqlContext   streams   time    version   

scala> val jurosDF = spark.read.
csv   format   jdbc   json   load   option   options   orc   parquet   schema   table   text   textFile

scala> val jurosDF = spark.read.json


“/user/aluno/heron/data/juros_selic/juros_selic.json”


scala> val jurosDF = spark.read.json("/user/aluno/heron/data/juros_selic/juros_selic.json")
jurosDF: org.apache.spark.sql.DataFrame = [data: string, valor: string]




3. Visualizar o Schema do jurosDF

scala> jurosDF.printSchema
root
 |-- data: string (nullable = true)
 |-- valor: string (nullable = true)


scala> jurosDF.printSchema()
root
 |-- data: string (nullable = true)
 |-- valor: string (nullable = true)


scala> 





4. Mostrar os 5 primeiros registros do jutosDF


scala> jurosDF.show(5)
+----------+-----+
|      data|valor|
+----------+-----+
|01/06/1986| 1.27|
|01/07/1986| 1.95|
|01/08/1986| 2.57|
|01/09/1986| 2.94|
|01/10/1986| 1.96|
+----------+-----+
only showing top 5 rows


scala> jurosDF.show
+----------+-----+
|      data|valor|
+----------+-----+
|01/06/1986| 1.27|
|01/07/1986| 1.95|
|01/08/1986| 2.57|
|01/09/1986| 2.94|
|01/10/1986| 1.96|
|01/11/1986| 2.37|
|01/12/1986| 5.47|
|01/01/1987|11.00|
|01/02/1987|19.61|
|01/03/1987|11.95|
|01/04/1987|15.30|
|01/05/1987|24.63|
|01/06/1987|18.02|
|01/07/1987| 8.91|
|01/08/1987| 8.09|
|01/09/1987| 7.99|
|01/10/1987| 9.45|
|01/11/1987|12.92|
|01/12/1987|14.38|
|01/01/1988|16.78|
+----------+-----+
only showing top 20 rows


scala> 



# o parametro false, mostra toda o conteudo por extenso

scala> jurosDF.show(5,false)
+----------+-----+
|data      |valor|
+----------+-----+
|01/06/1986|1.27 |
|01/07/1986|1.95 |
|01/08/1986|2.57 |
|01/09/1986|2.94 |
|01/10/1986|1.96 |
+----------+-----+
only showing top 5 rows


scala> 


show sao ações



5. Contar a quantidade de registros do jurosDF


scala> jurosDF.count()
res5: Long = 393

scala> 



6. Criar o DataFrame jurosDF10 para filtrar apenas os registros com o campo “valor” maior que 10


scala> val jurosDF10 = jurosDF.where("valor >10")
jurosDF10: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [data: string, valor: string]





7. Salvar o DataFrame jurosDF10  como tabela Hive “<nome>.tab_juros_selic”


# vamos visualizar as 5 primerios 

scala> jurosDF10.show(5)
+----------+-----+
|      data|valor|
+----------+-----+
|01/01/1987|11.00|
|01/02/1987|19.61|
|01/03/1987|11.95|
|01/04/1987|15.30|
|01/05/1987|24.63|
+----------+-----+
only showing top 5 rows


scala> 


# saveAsTable , salva em Hive

scala> jurosDF10.write.saveAsTable("heron.tab_juros_selic")

scala> 


# salva no Hive e armazena os arquivos na pasta do hdfs /user/hive/warehouse/heron.db/tab_juros_selic


root@namenode:/# hdfs dfs -ls -R /user/hive/warehouse/heron.db/tab_juros_selic
-rw-r--r--   2 root supergroup          0 2021-09-10 22:19 /user/hive/warehouse/heron.db/tab_juros_selic/_SUCCESS
-rw-r--r--   2 root supergroup       1419 2021-09-10 22:19 /user/hive/warehouse/heron.db/tab_juros_selic/part-00000-3faced5f-a834-4267-a6e7-e81c83bb51bc-c000.snappy.parquet
root@namenode:/# 


# pode verificar se a tabela foi criada no HIVE diretamente do ambiente spark 




8. Criar o DataFrame jurosHiveDF para ler a tabela “<nome>.tab_juros_selic”


scala> val jurosHiveDF = spark.read.table("heron.tab_juros_selic")
jurosHiveDF: org.apache.spark.sql.DataFrame = [data: string, valor: string]

scala> 

9. Visualizar o Schema do jurosHiveDF

scala> jurosHiveDF.printSchema()
root
 |-- data: string (nullable = true)
 |-- valor: string (nullable = true)


scala> 


10. Mostrar os 5 primeiros registros do jurosHiveDF


scala> jurosHiveDF.show(5)
+----------+-----+
|      data|valor|
+----------+-----+
|01/01/1987|11.00|
|01/02/1987|19.61|
|01/03/1987|11.95|
|01/04/1987|15.30|
|01/05/1987|24.63|
+----------+-----+
only showing top 5 rows


scala> 


11. Salvar o DataFrame jurosHiveDF no HDFS no diretório “/user/aluno/nome/data/save_juros” no formato parquet


#pode salvar como parquet pois é o default ou utilizar o save

#.save salva no formato parquet

jurosHiveDF.write.parquet

scala> jurosHiveDF.write.save("/user/aluno/heron/data/save_juros")

scala> 


12. Visualizar o save_juros no HDFS


# entrar no container namenode , hdfs dfs 


#por padrao ele salva o arquivo com compressao snappy


root@namenode:/# hdfs dfs -ls -R /user/aluno/heron/data/save_juros            
-rw-r--r--   2 root supergroup          0 2021-09-10 22:44 /user/aluno/heron/data/save_juros/_SUCCESS
-rw-r--r--   2 root supergroup       1419 2021-09-10 22:44 /user/aluno/heron/data/save_juros/part-00000-f0a4221e-aaa2-4aa7-a4a0-47596e5acb8d-c000.snappy.parquet
root@namenode:/# 



13. Criar o DataFrame jurosHDFS para ler o diretório do “save_juros” da questão 8


# vai ler um arquivo que foi salvo como parquet 

scala> val jurosHDFS = spark.read.load("/user/aluno/heron/data/save_juros")
jurosHDFS: org.apache.spark.sql.DataFrame = [data: string, valor: string]

scala> 



14. Visualizar o Schema do jurosHDFS


scala> jurosHDFS.printSchema
root
 |-- data: string (nullable = true)
 |-- valor: string (nullable = true)


scala> 


15. Mostrar os 5 primeiros registros do jurosHDFS


scala> jurosHDFS.show(5)
+----------+-----+
|      data|valor|
+----------+-----+
|01/01/1987|11.00|
|01/02/1987|19.61|
|01/03/1987|11.95|
|01/04/1987|15.30|
|01/05/1987|24.63|
+----------+-----+
only showing top 5 rows


scala> 




16. Clicar no botão de Enviar Tarefa, e enviar o texto: ok






########################################
EXERCICIOS - AULA 12 - Exercícios 
########################################





